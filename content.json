{"meta":{"title":"欢迎来到匡盟盟的博客！","subtitle":"Colyn 崛起正当时！","description":"Mengmeng Kuang's Blog!","author":"匡盟盟","url":"http://meng.uno"},"pages":[{"title":"关于我","date":"2018-02-11T06:17:40.354Z","updated":"2018-02-11T06:17:40.334Z","comments":true,"path":"about/index.html","permalink":"http://meng.uno/about/index.html","excerpt":"","text":""},{"title":"分类","date":"2018-02-11T06:17:12.750Z","updated":"2018-02-11T06:17:12.723Z","comments":true,"path":"categories/index.html","permalink":"http://meng.uno/categories/index.html","excerpt":"","text":""},{"title":"留言板","date":"2018-02-11T06:17:58.309Z","updated":"2018-02-11T06:17:58.301Z","comments":true,"path":"comments/index.html","permalink":"http://meng.uno/comments/index.html","excerpt":"","text":""},{"title":"标签云","date":"2018-02-11T06:17:27.163Z","updated":"2018-02-11T06:17:27.143Z","comments":true,"path":"tags/index.html","permalink":"http://meng.uno/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"关于比特币（Bitcoin）","slug":"bitcoins","date":"2018-02-14T11:47:44.000Z","updated":"2018-02-14T12:14:20.810Z","comments":true,"path":"posts/7bfe1542/","link":"","permalink":"http://meng.uno/posts/7bfe1542/","excerpt":"","text":"比特币术语 ¶比特币 首字母大写的Bitcoin用来表示比特币的概念或整个比特币网络本身。例如：“今天我学了些有关Bitcoin协议的内容。” 而没有大写的bitcoin则表示一个记账单位。例如：“我今天转出了10个bitcoin。”该单位通常也简写为BTC或XBT。 ¶比特币地址 比特币地址就像一个物理地址或者电子邮件地址。这是别人付给你比特币时你唯一需要提供的信息。然而一个重要的区别是，每个地址应该只用于单笔交易。 ¶对等式网络 对等式网络是指，通过允许单个节点与其他节点直接交互，从而实现整个系统像有组织的集体一样运作的系统 。对于比特币来说，比特币网络以这样一种方式构建——每个用户都在传播其他用户的交易。而且重要的是，不需要银行作为第三方。 ¶哈希率 哈希率是衡量比特币网络处理能力的测量单位。为保证安全，比特币网络必须进行大量的数学运算。当网络达到10Th/秒的哈希率时，就意味着它能够进行每秒10万亿次的计算。 ¶交易确认 交易确认意味着一笔交易已经被网络处理且不太可能被撤销。当交易被包含进一个块时会收到一个确认，后续的每一个块都对应一个确认。对于小金额交易单个确认便可视为安全，然而对于比如1000美元的大金额交易，等待6个以上的确认比较合理。每一个确认都成指数级地降低交易撤销的风险。 ¶块链 块链是一个按时间顺序排列的比特币交易公共记录。块链由所有比特币用户共享。它被用来验证比特币交易的永久性并防止双重消费。 ¶密码学 密码学是数学的一个分支，它让我们创造出可以提供很高安全性的数学证明。电子商务和网上银行也用到了密码学。对于比特币来说，密码学用来保证任何人都不可能使用他人钱包里的资金，或者破坏块链。密码学也用来给钱包加密，这样没有密码就用不了钱包。 ¶签名 密码学签名是一个让人可以证明所有权的数学机制。对于比特币来说，一个比特币钱包和它的私钥通过一些数学魔法关联到一起。当你的比特币软件用对应的私钥为一笔交易签名，整个网络都能知道这个签名和已花费的比特币相匹配。但是，世界上没有人可以猜到你的私钥来窃取你辛苦赚来的比特币。 ¶钱包 比特币钱包大致实体钱包在比特币网络中的等同物。钱包中实际上包含了你的私钥，可以让你消费块链中分配给钱包的比特币。和真正的钱包一样，每个比特币钱包都可以显示它所控制的所有比特币的总余额，并允许你将一定金额的比特币付给某人。这与商家进行扣款的信用卡不同。 ¶区块 一个块是块链中的一条记录，包含并确认待处理的交易。平均约每10分钟就有一个包含交易的新块通过挖矿的方式添加到块链中。 ¶双重消费 如果一个不怀好意的用户试图将比特币同时支付给两个不同的收款人，就被称为双重消费。比特币挖矿和块链将就两比交易中那笔获得确认并被视为有效在网络上达成一致。 ¶私钥 私钥是一个证明你有权从一个特定的钱包消费比特币的保密数据块，是通过一个密码学签名来实现的 。如果你使用的是钱包软件，你的私钥就存储在你的计算机内；如果使用的是在线钱包，你的私钥就存储在远程服务器上。千万不能泄露私钥，因为它们可以让你消费对应比特币钱包里的比特币。 ¶挖矿 比特币挖矿是利用计算机硬件为比特币网络做数学计算进行交易确认和提高安全性的过程。作为对他们服务的奖励，矿工可以得到他们所确认的交易中包含的手续费，以及新创建的比特币。挖矿是一个专业的、竞争激烈的市场，奖金按照完成的计算量分割。并非所有的比特币用户都挖矿，挖矿赚钱也并不容易。 ¶Bit Bit是标明一个比特币的次级单位的常用单位 -1,000,000 bit 等于1 比特币 (BTC 或 B⃦).，这个单位对于标示小费、商品和服务价格更方便。 ¶BTC BTC 是用于标示一个比特币 (B⃦). 的常用单位。 比特币账户 我们可以在bitcoin.org上选择自己的钱包。我在这里向大家展示使用一个浏览器插件GreenAddress，下载链接是：https://chrome.google.com/webstore/detail/greenaddress/dgbimgjoijjemhdamicmljbncacfndmp/related ¶注册 打开安装好的GreenAddress，没有账户点击右上角，开始注册。 打码的位置请保存下来，应该需要用它来登录 接着是验证你保存没保存（想的还很周到）。 再就是添加两步验证，这个比较常见了，我只选了“邮件”验证，推荐是选两个，要不然总是有warning。 ¶使用 接着就进入主界面了，有很多配置需要大家自己去查看，主界面显示了你的“Bitcoin URI”，分享这个，别人就可以向你转钱了，应该。 最后强调一下，我的比特币地址是：3CEzyZnpij4WnrAsHhhcaoD1Kf5JqSAEGj","categories":[],"tags":[{"name":"比特币","slug":"比特币","permalink":"http://meng.uno/tags/比特币/"},{"name":"Bitcoin","slug":"Bitcoin","permalink":"http://meng.uno/tags/Bitcoin/"}]},{"title":"简单的Python3爬虫","slug":"crawl-py","date":"2018-02-12T12:18:15.000Z","updated":"2018-02-13T14:08:54.149Z","comments":true,"path":"posts/51d32f19/","link":"","permalink":"http://meng.uno/posts/51d32f19/","excerpt":"","text":"我们先从分析原理入手，然后再使用Python提供的基本的库urllib。 注意，我全程使用的是Python3，如果你必须使用不同版本，请自行百度某些库及函数的转换，需要使用的库不一定你的电脑上预装了，所以请自行百度安装。 原理 网络爬虫，也叫网络蜘蛛(Web Spider)，如果把互联网比喻成一个蜘蛛网，Spider就是一只在网上爬来爬去的蜘蛛。网络爬虫就是根据网页的地址来寻找网页的，也就是URL。 ¶URL URL就是统一资源定位符(Uniform Resource Locator)，它的一般格式如下(带方括号[]的为可选项)： protocol ://hostname[:port]/path/[;parameters][?query]#fragment 可见，一个URL包含三个部分： protocol：协议，例如https，http等； hostname[:port]：主机名(端口号为可选参数)，一般网站默认的端口号为80，例如我的博客域名www.meng.uno，可以作为主机名使用; path：第三部分就是主机资源的具体地址，如目录和文件名等。 爬虫就是向URL发送请求，然后得到响应，基本就实现了爬取网页的功能。 URI可以分为URL,URN或同时具备locators 和names特性的一个东西。URN作用就好像一个人的名字，URL就像一个人的地址。换句话说：URN确定了东西的身份，URL提供了找到它的方式。 ¶从浏览器发送和接收数据看起 进入我的首页www.meng.uno，打开浏览器的“检查”功能，选项卡选到“Network”，然后点击所有文章，随便选择一条，我们可以发现如下截图的&quot;Headers&quot; 我们可以发现最明显的有两个区域（我已经圈出来了）：“request”和“response”。从字面意思上来看，我们就知道分别是（发送的）请求和（收到的）回复。 接收的信息是我们请求的网页给的，不用我们管，但是“请求的网页”是我们需要提前设定的，当然最简单的方式就是什么都不设置。爬虫会增加网站的负荷，所以很多网站希望大家通过API的方式使用其开放的资源而禁止爬虫，其中的一个做法就是判断你的请求内容（不全的基本都是爬虫）。于是，为了做到一个完整的可用的爬虫，我们需要模拟真实用户的请求，这就要求我们伪造“User Agent”。 常见的“User Agent”列举如下： Android Mozilla/5.0 (Linux; Android 4.1.1; Nexus 7 Build/JRO03D) AppleWebKit/535.19 (KHTML, like Gecko) Chrome/18.0.1025.166 Safari/535.19 Mozilla/5.0 (Linux; U; Android 4.0.4; en-gb; GT-I9300 Build/IMM76D) AppleWebKit/534.30 (KHTML, like Gecko) Version/4.0 Mobile Safari/534.30 Mozilla/5.0 (Linux; U; Android 2.2; en-gb; GT-P1000 Build/FROYO) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1 Firefox Mozilla/5.0 (Windows NT 6.2; WOW64; rv:21.0) Gecko/20100101 Firefox/21.0 Mozilla/5.0 (Android; Mobile; rv:14.0) Gecko/14.0 Firefox/14.0 Google Chrome Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.94 Safari/537.36 Mozilla/5.0 (Linux; Android 4.0.4; Galaxy Nexus Build/IMM76B) AppleWebKit/535.19 (KHTML, like Gecko) Chrome/18.0.1025.133 Mobile Safari/535.19 iOS Mozilla/5.0 (iPad; CPU OS 5_0 like Mac OS X) AppleWebKit/534.46 (KHTML, like Gecko) Version/5.1 Mobile/9A334 Safari/7534.48.3 Mozilla/5.0 (iPod; U; CPU like Mac OS X; en) AppleWebKit/420.1 (KHTML, like Gecko) Version/3.0 Mobile/3A101a Safari/419.3 User Agent已经设置好了，但是还应该考虑一个问题，程序的运行速度是很快的，如果我们利用一个爬虫程序在网站爬取东西，一个固定IP的访问频率就会很高，这不符合人为操作的标准，因为人操作不可能在几ms内，进行如此频繁的访问。所以一些网站会设置一个IP访问频率的阈值，如果一个IP访问频率超过这个阈值，说明这个不是人在访问，而是一个爬虫程序。 一个很简单的解决办法就是设置延时，但是这显然不符合爬虫快速爬取信息的目的，所以另一种更好的方法就是使用IP代理。使用代理的步骤： 调用urlib.request.ProxyHandler()，proxies参数为一个字典； 创建Opener(类似于urlopen，这个代开方式是我们自己定制的)； 安装Opener； 这个网站提供了很多代理主机：http://www.xicidaili.com/ ¶正则表达式 我直接以表格的形式呈现好了： 元字符 说明 . 代表任意字符 [ ] 匹配内部的任一字符或子表达式 [^] 对字符集和取非 - 定义一个区间 \\ 对下一字符取非（通常是普通变特殊，特殊变普通） * 匹配前面的字符或者子表达式0次或多次 *? 惰性匹配上一个 + 匹配前一个字符或子表达式一次或多次 +? 惰性匹配上一个 ? 匹配前一个字符或子表达式0次或1次重复 {n} 匹配前一个字符或子表达式 {m,n} 匹配前一个字符或子表达式至少m次至多n次 {n,} 匹配前一个字符或者子表达式至少n次 {n,}? 前一个的惰性匹配 ^ 匹配字符串的开头 \\A 匹配字符串开头 $ 匹配字符串结束 [\\b] 退格字符 \\c 匹配一个控制字符 \\d 匹配任意数字 \\D 匹配数字以外的字符 \\t 匹配制表符 \\w 匹配任意数字字母下划线 \\W 不匹配数字字母下划线 代码 ¶简单带错误信息的获取网页内所有URL的爬虫 1234567891011121314151617181920212223242526272829303132333435363738 #获取URL的包import urllib#获取字符集编码方式import chardet#正则表达式import re#Request 对象req = urllib.request.Request(\"http://meng.uno/\")data = Nonetry: #得到Response response = urllib.request.urlopen(req,data) #读出response == 请求文件的全部字符 html = response.read() #获取这个response的编码方式 charset = chardet.detect(html) print(\"编码方式：\",charset) #以这种编码方式解码打印 html = html.decode(charset.get(\"encoding\")) print(html) urls = re.findall('href=\\\"https*://w*\\.*meng\\.uno/.*?\\\"', html,re.S) uris = re.findall('href=\\\"/[^/].*?[^\\.]\\\"',html, re.S) for item in urls: print(item[6:-1]) for item in uris: if \".html\" in item: print(\"http://www.meng.uno\"+item[6:-1]) elif '.' in item: continue else: print(\"http://www.meng.uno\"+item[6:-1])except urllib.error.HTTPError as e: if hasattr(e, 'code'): print(\"HTTPError\") print(e.code) elif hasattr(e, 'reason'): print(\"URLError\") print(e.reason) ¶模拟真实环境的爬虫 12345678910111213141516171819 import urllib #访问网址url = 'http://www.whatismyip.com.tw/'#这是代理IPproxy = &#123;'https':'110.73.48.189:8123'&#125;#创建ProxyHandlerproxy_support = urllib.request.ProxyHandler(proxy)#创建Openeropener = urllib.request.build_opener(proxy_support)#添加User Angentopener.addheaders = [('User-Agent','Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36')]#安装OPenerurllib.request.install_opener(opener)#使用自己安装好的Openerresponse = urllib.request.urlopen(url)#读取相应信息并解码html = response.read().decode(\"utf-8\")#打印信息print(html) ¶通过队列获取网站所有URL的爬虫 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 #python系统关于队列的包import queue#获取URL的包import urllib#获取字符集编码方式import chardet#正则表达式import reinitial_page = \"http://www.meng.uno\"url_queue = queue.Queue()seen = set()seen.add(initial_page)url_queue.put(initial_page)def extract_urls(url): req = urllib.request.Request(url) #得到Response response = urllib.request.urlopen(req) #读出response == 请求文件的全部字符 html = response.read() #获取这个response的编码方式 charset = chardet.detect(html) #以这种编码方式解码打印 html = html.decode(charset.get(\"encoding\")) urls = re.findall('href=\\\"https*://w*\\.*meng\\.uno/.*?\\\"', html,re.S) uris = re.findall('href=\\\"/[^/].*?[^\\.]\\\"',html, re.S) tempseen = set() for item in urls: tempseen.add(item[6:-1]) for item in uris: if \".html\" in item: tempseen.add(\"http://www.meng.uno\"+item[6:-1]) elif '.' in item: continue else: tempseen.add(\"http://www.meng.uno\"+item[6:-1]) return tempseen while(True): #一直进行直到海枯石烂 if url_queue.qsize()&gt;0: current_url = url_queue.get() #拿出队例中第一个的url print(current_url) #把这个url代表的网页存储好 for next_url in extract_urls(current_url): #提取把这个url里链向的url if next_url not in seen: seen.add(next_url) url_queue.put(next_url) else: break 这里先简单解释，以后有实际项目会再补充！","categories":[{"name":"Python","slug":"Python","permalink":"http://meng.uno/categories/Python/"},{"name":"爬虫","slug":"Python/爬虫","permalink":"http://meng.uno/categories/Python/爬虫/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://meng.uno/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://meng.uno/tags/爬虫/"}]},{"title":"CPAchecker","slug":"cpachecker","date":"2018-02-11T14:08:59.000Z","updated":"2018-02-11T14:15:48.025Z","comments":true,"path":"posts/c5d9877c/","link":"","permalink":"http://meng.uno/posts/c5d9877c/","excerpt":"","text":"CPAchecker is a tool for configurable software verification which means expressing different program analysis and model checking approaches in one single formalism. The main algorithm is configurable to perform a reachability analysis on arbitrary combinations of existing configurable program analysis (CPA). One application of CPAchecker is the verification of Linux device drivers. CPA provides a conceptual basis for expressing different verification approaches in the same formal setting. The CPA formalism provides an interface for the definition of program analyses, which includes the abstract domain, the post operator, the merge operator, and the stop operator. Consequently, the corresponding tool implementation CPAchecker provides an implementation framework that allows the seamless integration of program analyses that are expressed in the CPA framework. The comparison of different approaches in the same experimental setting becomes easy and the experimental results will be more meaningful. ¶Architecture The above picture is the overview of CPAchecker’s architecture. The central data structure is a set of control-flow automata (CFA), which consist of control-flow locations and control-flow edges. A location represents a program-counter value, and an edge represents a program operation, which is either an assume operation, an assignment block, a function call, or a function return. Before a program analysis starts, the input program is transformed into a syntax tree, and further into CFAs. The framework provides interfaces to SMT solvers and interpolation procedures, such that the CPA operators can be written in a concise and convenient way. From the picture, we know that they use MathSAT as an SMT solver, and CSIsat and MathSAT as interpolation procedures. They also use JavaBDD as a BDD package, and provide an interface to an Octagon Library as well. The CPA Algorithm is the center of this project and the detailed design is shown as follows. The CPA algorithm (shown at the top in the above figure) takes as input a set of control-flow automata (CFA) representing the program, and a CPA, which is in most cases a Composite CPA. The interfaces correspond one-to-one to the formal framework. The elements in the gray box (top right) represent the abstract interfaces of the CPA and the CPA operations. The two gray boxes at the bottom of the figure show two implementations of the interface CPA, one is a Composite CPA that can combine several other CPAs, and the other is a Leaf CPA. ¶Build and Test Owing to the long development history, this project is very prefect which means you could use its binary directly, build from the source and even use their jar-ball in Java applications. To experience it, I will build it from the source and use it in the command-line. We need to install “jdk”, “ant”, “svn” and “subversion” before we build it. Then enter the root directory and run “ant”. Wait a moment and this is the result. To test this project, we need to write a C/C++ code without “#include ”. I choose a simple one (QuickSort) shown in the attachment. The result contains a log file, a statistics file and a report which is in “html” format.","categories":[{"name":"Software Verification","slug":"Software-Verification","permalink":"http://meng.uno/categories/Software-Verification/"},{"name":"CPA","slug":"Software-Verification/CPA","permalink":"http://meng.uno/categories/Software-Verification/CPA/"},{"name":"CPAchecker","slug":"Software-Verification/CPA/CPAchecker","permalink":"http://meng.uno/categories/Software-Verification/CPA/CPAchecker/"}],"tags":[{"name":"CPA","slug":"CPA","permalink":"http://meng.uno/tags/CPA/"},{"name":"CPAchecker","slug":"CPAchecker","permalink":"http://meng.uno/tags/CPAchecker/"}]},{"title":"Linux Test Project","slug":"ltp","date":"2018-02-11T13:29:33.000Z","updated":"2018-02-11T14:04:49.151Z","comments":true,"path":"posts/bfb74f68/","link":"","permalink":"http://meng.uno/posts/bfb74f68/","excerpt":"","text":"I found this project from the references of other papers, and I thought it was good, so I plan to run it. As we can see from its name, Linux Test Project (LTP) has a goal to deliver test suites to the open source community that validate the reliability, robustness, and stability of Linux. This project wants to support Linux development by making unit testing more complete and minimizing user impact by building a barrier to keep bugs from making it to the user. There are two important testing techniques which are supported by giving developers an ever growing set of tools to help identify any operational problems in their code: Design and Code Inspections. I knew that Yggdrasil and Hyperkernel which I have run successfully belong to the last category. LTP doesn’t have a benchmark which means they don’t compare different kernel of Linux. In LTP, we need to know: Test case: A single action and verification which has a result PASS/FAIL. Test suite: Containing one or more test cases. Test tags: Pairing a unique identifier with a test program and a set of command line options. We also need to know the ways of reporting the results of a test case. There are two main ways which are contained in LTP: Exit status: If a test program encounters unexpected or incorrect results, exit the test program with a non-zero exit status, i.e. exit(1). Conversely, if a program completes as expected, return a zero exit status, i.e. exit(0). Standard output: Tools can be used to analyze the results, if they are written in a standard way. ¶Build and Run To build this project, we need to run the following executions: 123456 $ git clone https://github.com/linux-test-project/ltp.git$ cd ltp$ make autotools$ ./configure$ make$ make install Before these, we need to ensure “git, autoconf, automake, m4” are installed. If not, we can use “apt-get” to get them. The output of “make” is shown as following. After building this project, let’s run it personally. If we want to run all the test suites, we just need run “./runltp” in the “opt/ltp/” directory. However, I will run a single test suite to verify this project only with “./runltp -f syscalls” execution. The picture above is the output of “abort01” test case. From it we can see that the test method is “Exit status test” and it passes all the situations. If a test case needs datafiles to work, these would be put in a subdirectory named datafilesand installed in the testcases/data/$TCID directory ¶Analyze Test Cases We could find LTP in “/opt/ltp” and the test suites are installed in the “/opt/ltp/runtest/” directory. The following picture is a screenshot of it. In a single file, such as “syscalls” file, there exist many single test cases which are like the follows. From this picture, those words, like “abort01”, represent different test cases which are laid in “/opt/ltp/testcases/bin/” directory. Each test case is a binary written either in portable Shell or C such as “abort01” which is from “abort01.c” which lays in the “ltp/testcases/kernel/syscalls/abort” directory. The test gets a configuration via environment variables and/or command line parameters, it prints additional information into the stdout and reports overall success/failure via the exit value. ¶Write A Test Suite To make things simple, I will use LTP standard interface, not add custom reporting functions and use LTP build system. The following are my steps (These steps are very simple, so I didn’t list any screenshot): Add a new file “meng” to “ltp/runtest/” directory; Write some test cases’ names, such as “abort01 accept01”; Run “make” and “make install”; Enter “/opt/ltp/” directory; Run “./runltp -f meng”; Get the result as the picture. (You can also find the full logs from “meng_output.txt” file in the attachment) ¶Write A Test Case As I said before, we can use C language or Shell to write a test case, however, in this section, I will just use C language to write a simple one which may make me have a deep understanding of this project. I used the “man-pages” to find the untested system calls, however, my linux version maybe a little old (2015 release, version 16.04), so that I can’t find a untested one which is excluded by the newest LTP. I will write a test for verifying system call “file rename”. First, I create a new file “meng.c” in the “ltp/testcases/kernel/syscalls/meng/” directory. Then I need to write the codes. The next thing I need to do is to include “tst_test.h” (There are also another headers, however, this one is basic). We need to write “main(), setup(), clean()” functions and the detailed realizations are in the “meng.c” which is in the attachment (I give some notes of the code in the “meng.c” file as well). What’s more, we need to create a “Makefile” in the same directory and write the compiling information. The compiled file is like this. Last, I will add this test case to the “meng” test suite and see the result (You can find the full output in “meng_syscall_output.txt” in the attachment). From the above picture, we can see that the verification is “pass” which means that not only the “rename” system call is correct, but also my code is right.","categories":[{"name":"Linux","slug":"Linux","permalink":"http://meng.uno/categories/Linux/"},{"name":"Linux Test","slug":"Linux/Linux-Test","permalink":"http://meng.uno/categories/Linux/Linux-Test/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://meng.uno/tags/Linux/"},{"name":"Linux Test","slug":"Linux-Test","permalink":"http://meng.uno/tags/Linux-Test/"}]},{"title":"A Melody Composer for both Tonal and Non-Tonal Languages","slug":"paperreport-hkust-dm","date":"2018-02-11T04:03:24.000Z","updated":"2018-02-11T04:39:53.403Z","comments":true,"path":"posts/2251dcee/","link":"","permalink":"http://meng.uno/posts/2251dcee/","excerpt":"","text":"Summary ¶Abstract This paper contains some improvements on an algorithmic melody composer called “T-music”. “T-music” is an algorithm which can compose a melody for users’ input lyrics by mining the relationship between the melodies and lyrics. These relationships are known as frequent patterns (FPS) . The ameliorations are two ways to enhance the methods of mining frequent patterns form instrumental compositions and an optimal way of using FPS mined from songs in one language to compose a melody for the input things in another language. ¶Propse The propose is to get an algorithm which take lyrics as input and a good melody as outcome in order to help those people who have little music background to compose songs. In view of the fact that there is already a pretty well method, T-music, the authors’ tasks are making some improvements on the basis of the original algorithm. ¶Deficiencies of original algorithm At the first place, I need to borrow a figure from the paper as follows to express my understanding of the original T-music method. As the picture shows that the system architecture of T-music can be divided as two phases which are “Frequent Pattern Mining” and “Melody Composition”. I will report this method following the flow of the algorithm. Mining the FPS from “Song Database” and storing them in the “Frequent Pattern Database”: Obtaining tone sequences from “Song Database” by reading the “Language Dictionary”; Generating s-sequence from a melody, a pitch sequence and a duration sequence; Mining the FPS from s-sequence; Storing the FPS to “Frequent Pattern Database”. Composing a melody for the “Lyrics” based on FPS in the “Frequent Pattern Database”: Obtaining the tone sequence of the lyrics by reading the “Language Dictionary”; Adding some “Music Parameters” such as some music rules; Generating “Melody” by the process “Melody Composition” using FPS. There are some deficiencies of the original T-music algorithm as follows. It can only mine FPS from songs in which lyrics must be present. What’s more, the original one can’t use the FPS mined from a language to compose melody in another language. However, we can’t always get the ideal songs data which have lyrics embedded easily. What we can get from the Internet are those instrumental compositions in which lyrics are absent. Also, we want to achieve that composing melody in a language with the FPS mined from another language which can make the algorithm more efficient. ¶Improvements What the authors have done provided two ways to mine Frequent Patterns from instrumental compositions and an optimal mapping method for composing a melody using FPS in different language with the input lyrics. The first way is “Method emphasizing the original FPS”. I will use the following picture to express my comprehension. Firstly, mining the FPS from songs and storing them in “FP database (General)”. Secondly, mining the frequent pitch trends from “Instrumental compositions with style database” and storing them in “Frequent pitch trends (Style)” and then using it as a selector to select those FPS storing the matches in “FP database (Style)”. The second way is “Method emphasizing the newly mined frequent pitch trends”. I will also introduce it using the screenshot from the paper. The FPS based on those of the first way was subdivided. The frequent pitch trends are mined as usually. The most difference is that one pitch trend may match a set of several tone trends. The optimal mapping method is shown as follows. Firstly, using the same method gets a “FP database” in one language. Then, generating several tone sequences for each tone trend in this “FP database”. There are some lemmas proofed on the paper to decide the specific number of the mapping. Improvements In this section, I will analysis some excellent algorithms, important thoughts or some key points. Some of them may look small or nothing special, but each has its function. ¶Using the “Trend” representation If I were doing this job, I could have chosen the simple “absolute” representation, just because this is the most intuitive frequent pattern we can get from songs. After careful consideration, just as the author explains that same melodies which start at different pitches may sound similar to us. Then, I understand that it is a big wisdom to use the “trend” representation which uses a FP to extract the general rules of a set of FPS with different pitches, simplifying a large number of calculations and making the result more obvious. ¶Using “Frequent pitch trends (Style)” as a selector Though we know that “T-music” uses “the FPS between the tone port and the pitch part” and agree the mining method used on mining the frequent pattern which contains a tone trend and a pitch trend, there must be some correlation between “Tone trend” and “Pitch trend”. Since the instrumental compositions don’t contain lyrics, we couldn’t mine a whole frequent pattern from them. However, we can also mine part of the frequent pattern from them which is “Pitch trend”. For we have so much instrumental compositions which means we can get enough “Pitch trend” and we already know the correlation between “Tone trend” and “Pitch trend”, we can estimate the frequency of the original frequent pattern and eliminate part of them which have a zero frequency. ¶Using the subsequences of original frequent pattern According to the Apriori property that all nonempty subsets of frequent item set must also be frequent, the authors artfully break the original FPS into smaller form and then making them combine more FPS which can be selected from the original FP database. By doing this, we can get more frequent patterns from the identical data which means our mining algorithm is more efficient. ¶Using multi-map as a data structure This data structure allows the task of retrieving a value by a key quickly and returns more than one frequent pattern with a support. From it, we can get a tuple in top-k tuples with some selection strategies and ensure that a pattern with a very large support isn’t always selected because it doesn’t mean that it is always the best choice. ¶Employing the divide and conquer idea Considering to compose a melody of a very long lyric, we may need to divide the original tone trend into several shorter tone trends, apply the same procedure on them and then return the concatenation of the results of the sub-problems. It is a simple idea of solving such problem, but we can’t resist its correctness and effectiveness. Limitations I just list some areas that I think need improvements or I think it can be added slightly on the basis of the original research. ¶Applying word segmentation Though the paper has mentioned the use of word segmentation, there is just a word and no detailed explanation. I think I should express my own idea here. Firstly, the word segmentation here isn’t the same of those applied in the fields of natural language processing (NLP). As we all known, the latter has so many strict norms to follow, however, in the lyrics, the norms aren’t very same. Why we do this in the input lyrics is because we want to determine the length of durations between every two words, which is different from the propose in the NLP which just wants to add pause at the same length of time between words and words. ¶Handling the tone trend with a length of 1 In this paper, the authors just simply set the pitch trend to be the input tone trend where, I think, may need improvement. Firstly, we all know that “the tone trend with a length of 1” couldn’t appear individually. It is usually because we matched the tone sequences before it or after it. I think if we consider dividing the original sequence into overlapping parts using the similar idea of divide and conquer idea, the question may disappear. ¶Mining the relationship between “tone trend” and “pitch trend” The authors just determine the relationship based on statistics in whether the original T-music method or the improved edition, store the regulars on a multi-map and when using the frequent pattern, the method just randomly selects a tuple from top-k tuples from the multi-map. Therefore, no matter which one we choose, it is just the original sequence in the FP-database. If there is a very large database which contains a large number of every frequent pattern, it may have a remarkable effect without complex computations. However, we can’t ensure it or we just want to improve our algorithm with little support of so many records. Let’s look at the following samples which has the form as same as those in the multi-map and assume that the same tone trend only has the three tuples. 123 &lt;1,1,2,2,1,0&gt; —&gt; (&lt;1,1,2,0,-1,-2&gt;, 10)&lt;1,1,2,2,1,0&gt; —&gt; (&lt;1,1,2,0,-2,-1&gt;, 9) &lt;1,1,2,2,1,0&gt; —&gt; (&lt;1,0,2,0,-2,-1&gt;, 5) As we can see, they have the same tone trend and different pitch trends with different values of a support. If we just use the method described in the paper, we may get the result of the 1st, the 2nd, or the 3rd. However, is it the best one? Maybe not, I think. I mean maybe &lt;1,1,2,0,-2,-1&gt; is better. I think we need to add some correlation analyses to the pitch trends which have the same tone trends. Expanding Research After reading this paper, I have some ideas for further research and some of them are listed as follows. ¶Adding location variables I mean, as we all known, a same lyric may have different melodies when it is at the beginning or at the end of a song. Of course, if we just want to use a simple sentence as its input, this consideration is rather superfluous. However, if the input lyric is long enough, it is very important then. ¶Generating a melody with a longer note This thought is mentioned in the end of the paper as well. We may have noticed that the normal notes will be longer than the syllables of lyrics, at least at the end of each sentence. We may need to modify the match method to add the frequent pattern which contains group of pitch trends sequences and its corresponding longer tone trends sequences. ¶Applying syntactic analysis The following is my exploratory opinion of the original T-music. If I have many songs with lyrics, I will mine the frequent patterns of syntactic analysis and add them to the “s-sequence” mentioned in this paper. Thus I will reform the original multi-map as follows. 1 (&lt;pitch trend pattern&gt;, &lt;syntax pattern&gt;) —&gt; (&lt;tone trend pattern&gt;, support) When we match the input lyrics, we need to not only match the “pitch trend pattern” from the FP-database but also contrast the “syntax pattern” and then make the best decision. ¶Expanding to speech recognization I have a simple idea of speech recognization using the same method mentioned in this paper. If I could collect enough voice information spoken by the same person, I would mine the frequent patterns of his intonation habit from the voice data and then using them to judge whether another voice is his or not. ¶Expanding to password security In order to prevent the password being stolen, all websites are making efforts on password diversity. I think the method of mining frequent pattern can be applied to protect users’ password as well. For the same string of ciphers, different people may type it out in different speeds with different intermission on every two letters. I, for example, usually use the combination of my name and birthday as a password and when I type it out there is a longer break between the last letter of my name and the first number of my birthday. If we use the same way to mine the frequent patterns form enough times records of someone, we may use the frequent patterns to judge whether it is the right person or not who is typing the password. ¶Generating “good problems” I often encounter some tricky programming problems and as we all known, “StackOverflow” is the biggest website which can offer you relevant solutions when you ask a question on it. However, we all want to get the best answer as soon as possible so we may need to put forward “good questions”. I think the thought of this paper can be applied to this question. We can first collect enough “good questions” from the website and then mine the syntactic frequent patterns of each question by categories. Finally, we can generate such “good questions” by adding the knowledge of sentence construction and providing some keywords needed. Related Research This paper is about mining frequent patterns which is a subfield of data mining. I will express my understanding mixing information retrieved from the Internet in this field. With the rise of big data, so many research topics about data is more and more frequent such as forecasting passenger flow and passenger flow directions during the Spring Festival and predicting the composition of Chinese college entrance examination this year. Data mining means the process of extracting valuable information and patterns from large amounts of data and these new discovery rules, patterns, information and concepts have potential value. It usually contains the association rules, classification, estimation, clustering and so on. As for association analysis, its propose is to discover interesting links hidden in large data sets and the patterns discovered are usually represented in association rules or frequent item sets just as this paper shown. There are several efficient and scalable frequent item set mining methods such as Apriori algorithm and FP-growth which needs to construct FP-tree. As for classification and prediction, I think it is a more stirring area. Think of this, a marketing manager needs data analysis to help guess whether or not a customer with a given profile will buy a new computer and then the marketing manager would like to predict how much a given customer will spend during a sale, what an attractive job!","categories":[{"name":"Paper Report","slug":"Paper-Report","permalink":"http://meng.uno/categories/Paper-Report/"},{"name":"Data mining","slug":"Paper-Report/Data-mining","permalink":"http://meng.uno/categories/Paper-Report/Data-mining/"}],"tags":[{"name":"Paper Report","slug":"Paper-Report","permalink":"http://meng.uno/tags/Paper-Report/"},{"name":"Data Mining","slug":"Data-Mining","permalink":"http://meng.uno/tags/Data-Mining/"}]},{"title":".length与length()的区别","slug":"2length","date":"2018-02-10T13:58:04.000Z","updated":"2018-02-10T14:52:50.489Z","comments":true,"path":"posts/61c2f1f1/","link":"","permalink":"http://meng.uno/posts/61c2f1f1/","excerpt":"","text":"当我们需要使用数组或者字符串长度时，习惯了使用IDE自动补全的我们是否知道.length与length()的区别喻原因呢？ 上面问题的答案是： 数组使用.length属性 字符串使用length()方法 下面我来回答原因。 ¶为什么数组有.length属性？ 在Java中，数组是容器对象，其中包含了固定数量的同一类型的值，一旦数组创建，其长度就是固定的了，于是，其长度可以作为一个属性。 ¶为什么字符串需要length()方法？ Java中的String，实际上是一个char类型数组，而char[]已经有了.length属性，所以在实现String时就没必要再定义重复的属性了，于是需要定义一个方法来返回其长度。","categories":[{"name":"Java开发Tips","slug":"Java开发Tips","permalink":"http://meng.uno/categories/Java开发Tips/"},{"name":"String","slug":"Java开发Tips/String","permalink":"http://meng.uno/categories/Java开发Tips/String/"},{"name":"Object","slug":"Java开发Tips/String/Object","permalink":"http://meng.uno/categories/Java开发Tips/String/Object/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://meng.uno/tags/Java/"}]},{"title":"Java异常结构层次图","slug":"java-exceptions-hierarchy","date":"2018-02-09T14:11:15.000Z","updated":"2018-02-10T14:51:35.021Z","comments":true,"path":"posts/1164dab2/","link":"","permalink":"http://meng.uno/posts/1164dab2/","excerpt":"","text":"在Java中，异常分为checked与unchecked，他们都在一个分类层次中，如下图。 其中，红色的异常是checked异常，意味着在一个方法中，他们throw后必须catch或者declare。 另一种颜色的为unchecked异常，他们的异常不需要被recover。","categories":[{"name":"Java开发Tips","slug":"Java开发Tips","permalink":"http://meng.uno/categories/Java开发Tips/"},{"name":"Exception","slug":"Java开发Tips/Exception","permalink":"http://meng.uno/categories/Java开发Tips/Exception/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://meng.uno/tags/Java/"},{"name":"Exception","slug":"Exception","permalink":"http://meng.uno/tags/Exception/"}]},{"title":"二分查找的效率","slug":"binsearch","date":"2018-02-08T09:20:00.000Z","updated":"2018-02-10T13:05:27.172Z","comments":true,"path":"posts/fff444e8/","link":"","permalink":"http://meng.uno/posts/fff444e8/","excerpt":"","text":"查找是比较常见的工作，今天我通过对比几种在数组中查找一个确定的值的例子来向大家展示二分查找的魅力。 ¶数组查找元素的几种方法 ¶使用List 123 public static boolean useList(String[] arr, String targetValue) &#123; return Arrays.asList(arr).contains(targetValue);&#125; ¶使用Set 1234 public static boolean useSet(String[] arr, String targetValue) &#123; Set&lt;String&gt; set = new HashSet&lt;String&gt;(Arrays.asList(arr)); return set.contains(targetValue);&#125; ¶使用for-loop 1234567 public static boolean useLoop(String[] arr, String targetValue) &#123; for(String s: arr)&#123; if(s.equals(targetValue)) return true; &#125; return false;&#125; ¶使用二分 1234567 public static boolean useArraysBinarySearch(String[] arr, String targetValue) &#123; int a = Arrays.binarySearch(arr, targetValue); if(a &gt; 0) return true; else return false;&#125; ¶时间复杂性 ¶代码 使用如下代码来验证不同数据规模（5，1k，10k）的查找任务下四种方法的时间复杂性。（二分查找需要对数据排序，排序时间未计算在内。） 123456789101112131415161718192021222324252627282930 public static void main(String[] args) &#123; String[] arr = new String[] &#123; \"CD\", \"BC\", \"EF\", \"DE\", \"AB\"&#125;; //use list long startTime = System.nanoTime(); for (int i = 0; i &lt; 100000; i++) &#123; useList(arr, \"A\"); &#125; long endTime = System.nanoTime(); long duration = endTime - startTime; System.out.println(\"useList: \" + duration / 1000000); //use set startTime = System.nanoTime(); for (int i = 0; i &lt; 100000; i++) &#123; useSet(arr, \"A\"); &#125; endTime = System.nanoTime(); duration = endTime - startTime; System.out.println(\"useSet: \" + duration / 1000000); //use loop startTime = System.nanoTime(); for (int i = 0; i &lt; 100000; i++) &#123; useLoop(arr, \"A\"); &#125; endTime = System.nanoTime(); duration = endTime - startTime; System.out.println(\"useLoop: \" + duration / 1000000);&#125; ¶&quot;5&quot;结果 123 useList: 13useSet: 72useLoop: 5 ¶&quot;1k&quot;结果 ¶随机生成数据 123456 String[] arr = new String[1000]; Random s = new Random();for(int i=0; i&lt; 1000; i++)&#123; arr[i] = String.valueOf(s.nextInt());&#125; ¶结果 1234 useList: 112useSet: 2055useLoop: 99useArrayBinary: 12 ¶&quot;10k&quot;结果 1234 useList: 1590useSet: 23819useLoop: 1526useArrayBinary: 12 ¶结论 通过以上结果，我们可以发现二分搜索确实很高效，而且当数据量变大时，其时间增长幅度还比较小。 以后，我们就可以使用Arrays.binarySearch()来高效查找某元素了。","categories":[{"name":"Java开发Tips","slug":"Java开发Tips","permalink":"http://meng.uno/categories/Java开发Tips/"},{"name":"Search","slug":"Java开发Tips/Search","permalink":"http://meng.uno/categories/Java开发Tips/Search/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://meng.uno/tags/Java/"},{"name":"算法复杂性","slug":"算法复杂性","permalink":"http://meng.uno/tags/算法复杂性/"},{"name":"二分查找","slug":"二分查找","permalink":"http://meng.uno/tags/二分查找/"}]},{"title":"Java Substring() 的实现","slug":"substring","date":"2018-02-08T07:43:08.000Z","updated":"2018-02-09T10:46:20.937Z","comments":true,"path":"posts/f3057e6c/","link":"","permalink":"http://meng.uno/posts/f3057e6c/","excerpt":"","text":"写过Java的人应该都用过substring(int bedinIndex, int endIndex)方法。我发现这个简单的方法在实现上居然经过了一次大的变革。 ¶substring()的用途 代码: 123 String origin = \"asdfg\"; origin = origin.substring(1,3);System.out.println(origin); 输出: 1 sd 我们发现它能将原始字符串中从下标为beginIndex到endIndex-1之间的子串取出。那它是怎么实现的呢？ ¶substring()的实现 Java中的字符串有三个域：char value[], int offset以及int count，它们分别存储字符串的值，起始下标与长度。 ¶JDK6版本 在这个版本中，每次执行substring()方法时并不会新建新的string，仅仅只是将上述三个域中的offset，count做必要的修改。返回对象仍指向原来的数据。 这样一来，缺点就比较明显：当原始字符串比较长，而截取的子串比较短时，在后续的使用中就会浪费大量的空间。 ¶JDK7+版本 在上一个版本基础上，这个方法进行了改进，每次使用这个方法都会新建一个string对象，并将其返回。","categories":[{"name":"Java开发Tips","slug":"Java开发Tips","permalink":"http://meng.uno/categories/Java开发Tips/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://meng.uno/tags/Java/"}]},{"title":"Java异常处理","slug":"java-exceptions-work","date":"2018-02-01T14:21:52.000Z","updated":"2018-02-10T14:51:35.019Z","comments":true,"path":"posts/7526d370/","link":"","permalink":"http://meng.uno/posts/7526d370/","excerpt":"","text":"在Java中，调用某方法，就必须处理被调用方法抛出的异常，同时超类也可以用来捕获或者处理子类异常。 ¶调用方法必须处理被调用方法抛出的异常 下面是一个处理异常的程序。我们可以测试一下，如果在一个方法中抛出一个异常，不仅是该方法，而且所有调用该方法的方法都必须声明或抛出异常。 123456789101112131415 public class exceptionTest &#123; private static Exception exception; public static void main(String[] args) throws Exception &#123; callDoOne(); &#125; public static void doOne() throws Exception &#123; throw exception; &#125; public static void callDoOne() throws Exception &#123; doOne(); &#125;&#125; ¶超类可以用来捕获或处理子类异常 可以使用如下代码验证。 123456789101112131415161718192021 class myException extends Exception&#123; &#125; public class exceptionTest &#123; private static Exception exception; private static myException myexception; public static void main(String[] args) throws Exception &#123; callDoOne(); &#125; public static void doOne() throws myException &#123; throw myexception; &#125; public static void callDoOne() throws Exception &#123; doOne(); throw exception; &#125;&#125; 这也就是为什么catch子句只有一个父类在语法上安全的原因。","categories":[{"name":"Java开发Tips","slug":"Java开发Tips","permalink":"http://meng.uno/categories/Java开发Tips/"},{"name":"Exception","slug":"Java开发Tips/Exception","permalink":"http://meng.uno/categories/Java开发Tips/Exception/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://meng.uno/tags/Java/"},{"name":"Exception","slug":"Exception","permalink":"http://meng.uno/tags/Exception/"}]},{"title":"Analysis For Hyperkernel","slug":"hv6","date":"2018-01-29T13:43:03.000Z","updated":"2018-02-10T14:56:55.140Z","comments":true,"path":"posts/55c9299d/","link":"","permalink":"http://meng.uno/posts/55c9299d/","excerpt":"","text":"Homepage: https://locore.cs.washington.edu/hyperkernel/ Code: https://github.com/locore/hv6 ¶State-machine Specification State-machine specification means the system function will first verify the old procedure until the procedure is runnable and then return a new procedure and write to the system image. All of these must run in the user level. This specification consists of two parts: a definition of abstract kernel state, and a definition of trap handlers (e.g., system calls) in terms of abstract state transitions. They use fully automated technique to find bugs and this method is full functional verification if program is free of loops and state is finite. The “hv6/hv6/spec/kernel/spec/specs.py” file contains the system calls which use this kind of specification. From the picture, we can see that they use Z3 to prove the correction of the “old” procedure and if it can transfer to a new state or it is runnable, it will return the new procedure so that it can be proved true. ¶Declarative Specification The authors also provide a declarative specification of the high level properties that the state-machine specification should satisfy. The verifier will check that these high level properties are indeed satisfied, helping increase the programmer’s confidence in the correctness of the state-machine specification. To improve confidence in its correctness, there is a higher-level declarative specification to better capture programmer intuition about kernel behavior, in the form of a conjunction of crosscutting properties that hold across all trap handlers.","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://meng.uno/categories/操作系统/"},{"name":"系统验证","slug":"操作系统/系统验证","permalink":"http://meng.uno/categories/操作系统/系统验证/"}],"tags":[{"name":"System","slug":"System","permalink":"http://meng.uno/tags/System/"},{"name":"Verification","slug":"Verification","permalink":"http://meng.uno/tags/Verification/"}]},{"title":"怎么处理噪声","slug":"handle-noise","date":"2018-01-27T14:35:33.000Z","updated":"2018-02-17T02:10:40.282Z","comments":true,"path":"posts/a12d1477/","link":"","permalink":"http://meng.uno/posts/a12d1477/","excerpt":"","text":"处理噪声是一个在机器学习学习过程中，总会被问到的问题。噪声可以出现在输入X，亦可以出现在输出Y中。 ¶X中缺失值 使用来自所有可用数据的特征的平均值 忽略实例 使用来自类似项目的平均值 使用另一个机器学习算法来预测值 Bagging 或者 Boosting","categories":[{"name":"AI","slug":"AI","permalink":"http://meng.uno/categories/AI/"},{"name":"机器学习","slug":"AI/机器学习","permalink":"http://meng.uno/categories/AI/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://meng.uno/tags/机器学习/"},{"name":"噪声","slug":"噪声","permalink":"http://meng.uno/tags/噪声/"}]},{"title":"Analysis for Yggdrasil","slug":"yggdrasil","date":"2018-01-16T14:31:00.000Z","updated":"2018-02-11T14:48:52.840Z","comments":true,"path":"posts/5ed9f695/","link":"","permalink":"http://meng.uno/posts/5ed9f695/","excerpt":"","text":"Yggdrasil is a toolkit for verifying file system with push-button verification via crash refinement. As for push-button verification, it means that Yggdrasil needs no manual annotations or proofs. As for crash refinement, it is amenable to fully automated SMT reasoning. The whole verification is something like the State-Machine Specification in the project “Hyperkernel”. The whole system architecture is shown as follows. From this picture, we know that Yggdrasil needs three inputs: a specification of the expected behavior, an implementation and consistency invariants which indicate whether a file system image is in a consistent state or not. For better run-time performance, Yggdrasil optionally performs optimizations. If there is a bug, Yggdrasil produces a counterexample to help identify and fix the cause. It requires no manual annotations or proofs about the implementation code. Once the verification passes, Yggdrasil emits C code, which is then compiled and linked using a C compiler to produce an executable file system, as well as a “fsck” checker. The above is the entire overall content of this project. The authors also introduced every part of this project. I will analyze it by following the paper. ¶Single-level File System (YminLFS) In this project, every file system must contain three parts: an abstract data structure, a set of operations and a state equivalence predicate which defines whether a given implementation satisfies the specification. So the authors first defines a file system which contains these features. Then it runs the verification. Yggdrasil uses the Z3 solver to prove a two-part crash refinement. The first part deals with crash-free executions which requires the implementation and specification are similar in the absence of crashes, which means if both YminLFS and FSSpec start in equivalent and consistent states, they end up in equivalent and consistent states (just like state-machine). This project defines equivalence using the equivalent predicate and defines consistency using the consistency invariants as the above pictures show. The second part deals with crash executions which requires the implementation to exist no more crash states than the specification, which means each possible state of the YminLFS implementation must be equivalent to some crash state of FSSpec. What’s more, Yggdrasil provides a greedy optimizer that tries to remove every disk flush and re-verify the code. ¶Multi-level File System (Yxv6) We could directly prove crash refinement between the entire file system specification and implementation in a single-level file system, however, we couldn’t use the same method in a complex multi-level file system. First, let’s look at the structure of Yxv6 journaling file system. This is the 5 layers of abstraction and every layer contains a specification and a implementation. The authors use this project to prove crash refinement for each layer and upper layers then use the specifications of lower layers. The lowest layer of the stack is a specification of an asynchronous disk. This specification comprises the asynchronous disk model which is to implement YminLFS. ¶Application-level (“Ycp”) Ycp has a formal specification which means if the copy operation succeeds, the result is the same as “cp”, however, if it fails, the file system is unchanged. To achieve this propose, the implementation of Ycp is something similar to Yxv6 file system specification. There are 3 atomicity patterns which are “create a temporary file”, “write the source data to it” and “rename it to atomically create the target file”. After doing such an analogy, verifying this operation is similar to verify the single-level file system.","categories":[{"name":"System Verification","slug":"System-Verification","permalink":"http://meng.uno/categories/System-Verification/"},{"name":"Yggdrasil","slug":"System-Verification/Yggdrasil","permalink":"http://meng.uno/categories/System-Verification/Yggdrasil/"}],"tags":[{"name":"Yggdrasil","slug":"Yggdrasil","permalink":"http://meng.uno/tags/Yggdrasil/"},{"name":"System Verification","slug":"System-Verification","permalink":"http://meng.uno/tags/System-Verification/"}]},{"title":"KVM Unit Tests","slug":"kvm-unit-test","date":"2018-01-15T14:19:40.000Z","updated":"2018-02-11T14:48:52.840Z","comments":true,"path":"posts/50351d5d/","link":"","permalink":"http://meng.uno/posts/50351d5d/","excerpt":"","text":"Kernel-based Virtual Machine (KVM) is a virtualization infrastructure for the Linux kernel that turns it into a hypervisor. KVM requires a processor with hardware virtualization extensions. This project, as its name suggests, is to provide unit tests for KVM. The unit tests are tiny guest operating systems that generally execute only tens of lines of C and assembler test code in order to obtain its PASS/FAIL/SKIP result. Unit tests provide KVM and virtual hardware functional testing by targeting the features through minimal implementations of their use per the hardware specification. The simplicity of unit tests make them easy to verify they are correct, easy to maintain, and easy to use in timing measurements. Unit tests are also often used for quick and dirty bug reproducers. ¶Build and Run Building this project is very easy, we just need to enter the directory and run “./configure; make”. If there isn’t any mistake, it means this project is successfully built. As can be seen from its name, it is a testing program so running it means running some tests on KVM. In addition, as other verification systems, it also has some single test cases and a whole test suite. What has to be aware is we need to install “kvm” or “qemu-kvm” before testing, otherwise, the tests will just “SKIP” because it is just for testing KVM. First, I will run a single test case which is in the “x86/” directory named “syscall.flat”. The result is as follows. Then, I will run a test suite. The following picture is part of the result. I found that there are 3 status of the test results which are PASS, FAIL and SKIP. From the picture, we can see that not all tests are PASS, which means this version of KVM may have many points to be improved. ¶Analyze the Test To write a test case/suite, we first need to analyze an example. From the file “run_tests.sh”, we could find that it runs each test in “x86/unittests.cfg”. This is a section of this file. From it, we could know that when the test suite runs to here, it will find test case “apic.flat” and run it in the x86_64 architecture within 30 seconds. The result of every test case is printed to the screen by the “runtime.bash” script. What’s more, we could find the detailed information of every test case from “logs/” directory. After analyzing a test suite, let’s look at a single test case. I will choose the “syscall.flat” as an example. Let’s see the main function. There are two subfunctions which is consistent with the first screenshot. Now I will focus on a single function as the following picture shows. It just tests some single function calls and report the results. ¶Write A Test Because I can’t know about KVM clearly for such a short period of time, here I just write a simple test, in order to experience how to write a test case. After compiling and running it, we could get this expected output. Now I could put my test case to the test suite, adding such code to the “unittests.cfg” file. Also, it must be PASS as expected. ¶Analyze the Framework In the beginning, let’s analyze the directory structure. ./api/: there are three API categories 1) libc, 2) functions typical of kernel code, and 3) kvm-unit-tests specific. ./lib/: general architecture neutral services for the tests. ./x86/: the sources of the tests and the created images of X86 architecture. ./logs/: the output information. ./scripts/: helper scripts for building and running tests. others: configure script, top-level Makefile, and run_tests.sh. The framework has the following components: Test building support Shared code for test setup and API Test running support Test building is done through makefiles and some supporting bash scripts. Test setup code includes, for example, early system init, MMU enablement, and UART init. The API provides some common libc functions, as well as some low-level helper functions commonly seen in kernel code and some kvm-unit-tests specific APIs. Test running is provided with a few bash scripts, using a unit tests configuration file as input. Generally tests are run from within the source root directory using the supporting scripts, but tests may optionally be built as standalone tests as well.","categories":[{"name":"KVM","slug":"KVM","permalink":"http://meng.uno/categories/KVM/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"http://meng.uno/tags/KVM/"}]},{"title":"Analysis for DynamoRIO","slug":"rio","date":"2018-01-13T13:57:16.000Z","updated":"2018-02-11T14:04:49.152Z","comments":true,"path":"posts/a331aaad/","link":"","permalink":"http://meng.uno/posts/a331aaad/","excerpt":"","text":"DynamoRIO is a dynamic binary piling/translation platform. Through it, you can manipulate the running code of a program, that is, it can simulate running a program and allow you to transform and control any place of the running code. It is used for dynamic analysis, optimization and translation of programs. DynamoRIO is a cooperation project between HP and MIT. Dynamo comes from HP’s laboratory, RIO (Runtime Introspection and Optimization) comes from MIT’s computer science laboratory. The history is shown as follows. ¶Architecture DynamoRIO’s architecture is like this. It is between the operating system and the application so that it can get the system calls and the applications’ code easily. This picture is the Toolchain Control Points. The process flow is as follows. The original program goes through the “basic block builder”, “trace selector”, “basic block cache” and “trace cache” to get the emulation propose. ¶Efficiency DynamoRIO is separated from the code of applications by the “context switch” as shown in the picture above. The applications’ code is copied to the instruction cache. The code in these caches will execute as native code. Until a jump instruction is encountered, the applications’ “machine state” will be saved, and the control will turn back to DynamoRIO to find the basic block where the jump instruction is located. DynamoRIO is much faster than pure emulations by “code cache”. There are several improvements in this project. The picture above is the first one — Basic Block Cache. If you copy each basic block into a code cache and run it natively, it greatly reduces the overhead of interpreting, however, we still need to explain each jump instruction, and then return to DynamoRIO to find the target instruction. If a target instruction already exists in the code cache and is referred to by a direct jump instruction, DynamoRIO can directly jump to the target instruction in the code cache to avoid the overhead of the context switch, which is called “Linking Direct Branches”. The next improvement is “Linking Indirect Branches” since a conditional branch instruction can not be linked like a direct jump instruction because it has more than one goal and needs to make decisions and find the list’s jump target. Some basic blocks, which are often executed sequentially, are combined into one execution stream to reduce the number of branches and increase the locality of the program. It reduces some overhead of indirect branch search, because it has put indirect brach in this trace as well. This is also the last improvement — Trace Building. ¶Transparency It has three transparency principles which are “As few changes as possible”, “Hide necessary changes” and “Separate resources”. Changes in these areas are few: application code, stored addresses, threads and application data. Changes in these fields are hidden: application addresses, address space, error transparency and code cache consistency. This picture shows the principle 3 well. DynamoRIO’s own code also uses share libraries when loading applications, which may cause some conflicts if the application also uses the same library. The solution is that, DynamoRIO doesn’t use the library directly, calling system call on Linux and calling system call via windows win32 API profile. The heap memory allocated by DynamoRIO itself is distinguished from the heap memory requested by the application. In addition, DynamoRIO uses its own I/O routines for input and output to avoid conflicts with the applications’ I/O buffers. What’s more, since the use of shared locks can also cause conflicts between DynamoRIO and applications, it also has synchronization transparency. To avoid conflicts with applications, DynamoRIO doesn’t create its own thread, instead spawns threads in the application process to distinguish between its own status and applications’ status via a “Context Switch” as the first picture shows. Further more, it chooses to leave the stack of application processes intact, creating a private stack of each thread. ¶Comprehensive All data streams must go through handlers generated by the dispatcher. The data flow is like this. ¶Customization DynamoRIO has developed some event driven APIs that allow developers to customize instrument instructions. Using it, you can achieve some proposes such as: memory checking, performance testing, system call tracking, code coverage calculation.","categories":[{"name":"RIO","slug":"RIO","permalink":"http://meng.uno/categories/RIO/"},{"name":"DynamoRIO","slug":"RIO/DynamoRIO","permalink":"http://meng.uno/categories/RIO/DynamoRIO/"}],"tags":[{"name":"DynamoRIO","slug":"DynamoRIO","permalink":"http://meng.uno/tags/DynamoRIO/"},{"name":"RIO","slug":"RIO","permalink":"http://meng.uno/tags/RIO/"}]},{"title":"Zsh","slug":"zsh","date":"2018-01-11T02:22:44.000Z","updated":"2018-02-11T03:08:26.198Z","comments":true,"path":"posts/d911b12b/","link":"","permalink":"http://meng.uno/posts/d911b12b/","excerpt":"","text":"不少程序员都觉得Mac的一大优势就是其Shell，也有很多人觉得Mac与Linux在Shell上很相似。不错，但是Mac还是略胜一筹或者说高一个量级。今天，我将向大家介绍一个Mac特有的Shell（Linux也可以安装，但是不是系统自带。）—— Zsh。 ¶切换到Zsh 使用cat /etc/shells指令，我们可以看看自己的系统有哪些Shells，下面是我的Mac的结果： 1234567 /bin/bash/bin/csh/bin/ksh/bin/sh/bin/tcsh/bin/zsh/usr/local/bin/fish 使用这个指令切换到Zsh：chsh -s /bin/zsh。（想使用其他Shell也是同样的指令哦。） 这是，我们的Shell配置文件就为.zshrc了。 我觉得从这里我们应该可以知道，为什么之前的Shell配置文件要以.bash_profile命名了吧。因为Mac默认Shell是Bash。 ¶迁移Bash配置 我使用Bash有好几年了，那些配置都是一些环境变量啊什么的，如果在Zsh的配置里再写一遍，无疑是一件很费时又低效的事。那有没有什么快捷的方式呢？当然有！ 通过如下指令：source ~/.bash_profile就可以将.bash_profile里的配置全部引入到.zshrc中了。同理，如果你想自己写配置，也可以通过这种方式引入。（后文你将看到一个第三方工具就是这么做的。） ¶安装oh my zsh 通过wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh指令安装。 这时我们发现在.zshrc文件中，多了两行： 12 export ZSH=/Users/NAME/.oh-my-zshsource $ZSH/oh-my-zsh.sh ¶自定义Shell主题 使用oh my zsh主要的原因是使用其提供的漂亮的主题，主题目录在.oh-my-zsh/themes/下，选择主题ZSH_THEME=&quot;robbyrussell&quot;。这时我的Shell主题就是robbyrussell了。 打开robbyrussell.zsh-theme文件，我们可以看见几条配置。 我将其中的PROMPT修改为： PROMPT='${ret_status} %{$fg[cyan]%}%d %{$reset_color%} $(git_prompt_info)%{$fg_bold[red]%}&gt;%{$fg_bold[yellow]%}&gt;%{$fg_bold[green]%}&gt; ' 这时我的Shell就变成了这样： 可以发现我的定制有：显示绝对路径，&gt;&gt;&gt;等。 还有很多主题与配置，大家可以自己尝试。 ¶定制Shell Zsh还有个功能就是“别名”。不知道大家有没有这样的经历，需要打开.plist这样的文件，如果用普通编辑器打开会非常界面不友好，而用Xcode打开则完美可观。那怎么在控制台直接用Xcode打开文件呢？（其他软件同理） 我在.zshrc中添加：alias xcode=&quot;/Applications/Xcode.app/Contents/MacOS/Xcode&quot;，之后我就可以使用xcode X来用Xcode打开X文件了。 我们也可以为某种类型文件设置默认打开方式：alias -s html=atom（当我们键入.html文件时，会自动用Atom打开）。 ¶安装插件 oh my zsh为Zsh提供了100+插件，如果我们需要安装某插件，只需要在.zshrc文件中的plugins=()中添加，用空格隔开，只需要填插件名字，默认添加了git。 在这里我向大家介绍几种网上很常见的插件： git当你处于一个 git 受控的目录下时，Shell 会明确显示 「git」和 branch，如上图所示，另外对 git 很多命令进行了简化，例如 gco=’git checkout’、gd=’git diff’、gst=’git status’、g=’git’等等，熟练使用可以大大减少 git 的命令长度，命令内容可以参考~/.oh-my-zsh/plugins/git/git.plugin.zsh。 osxtab 增强，quick-look filename 可以直接预览文件，man-preview grep 可以生成 grep手册 的pdf 版本等。 autojump像他的名字一样，提供自动补全等很多功能，大家自己去尝试吧。 注意：安装autojump建议使用Homebrew brew install autojump 然后按照提示将一句类似这个 [ -f /usr/local/etc/profile.d/autojump.sh ] &amp;&amp; . /usr/local/etc/profile.d/autojump.sh 的句子插入到.zshrc文件中即可。","categories":[{"name":"Shells","slug":"Shells","permalink":"http://meng.uno/categories/Shells/"}],"tags":[{"name":"Zsh","slug":"Zsh","permalink":"http://meng.uno/tags/Zsh/"}]},{"title":"Deep Learning上手工具","slug":"tools4DP","date":"2018-01-10T14:43:43.000Z","updated":"2018-02-17T02:11:39.642Z","comments":true,"path":"posts/99be2c50/","link":"","permalink":"http://meng.uno/posts/99be2c50/","excerpt":"","text":"现在Deep Learning太火了，以至于没有任何计算机基础的人都想使用它，那么对于新手，甚至连Python代码都写不好的DL爱好者，有什么上手工具么？选择合适的工具可以帮助学习更快，很巧的是，有很多不同的工具可供选择，下图列出了常用的工具。 谷歌开发的Tensorflow，微软的CNTK以及Theano都是为深度学习而开发的库，它们促进了使用GPU计算。他们并不难，但与Keras相比，他们仍然非常复杂。Keras只是使用底层深度学习库的界面。使用Keras就像玩乐高一样简单。我建议初学者从Keras开始，因为我们可以快速了解深度学习可以做些什么，并积极进行一些有趣的项目。","categories":[{"name":"AI","slug":"AI","permalink":"http://meng.uno/categories/AI/"},{"name":"Deep Learning","slug":"AI/Deep-Learning","permalink":"http://meng.uno/categories/AI/Deep-Learning/"}],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://meng.uno/tags/Deep-Learning/"}]},{"title":"CryptoMinisat","slug":"CryptoMinisat","date":"2018-01-10T13:50:36.000Z","updated":"2018-02-11T14:04:49.150Z","comments":true,"path":"posts/7d26fe8/","link":"","permalink":"http://meng.uno/posts/7d26fe8/","excerpt":"","text":"Inspired by other verification system projects, I want to further explore the means of verification they used such as SMT solver, SAT solver, Coq and so on. I’ll start with this report from an advanced SAT solver — CryptoMinisat. (I have written a report about STP which is a SMT solver.) The Boolean Satisfiability Problem (SAT for short) is the problem of determining if there exists an interpretation that satisfies a given boolean formula. In other words, it asks whether the variables of a given boolean formula can be consistently replaced by the values TRUE or FALSE in such a way that the formula evaluates to TRUE. If this is the case, the formula is called satisfiable. Otherwise, the formula is unsatisfiable. SAT solvers have recently been enjoying a boom in the application front: more and more applications can and do make use of SAT solvers to accomplish tasks ranging from the fairly trivial to the very complex. The benefit of the incredible improvements in the design of efficient SAT solvers those recent years is now reaching our lives: The Intel Core7 processor for instance has been designed with the help of SAT technology, while the device drivers of Windows 7 are being certified thanks to an SMT solver (based on a SAT solver). ¶Build and Test This is the 5th version of CryptoMinisat which means the install instruction is very prefect now. To build and test this project, all we have to do is following the instruction. Firstly, we need to install many dependencies. Then, it is very simple to build by “make”. The following is part of the output. Testing this project is very easy by the script written by the authors. Typing “make test” and waiting for a moment, we will get this output which means the tests are correct. ¶Run This Project This is a very mature project which can be run from the terminal or used as a C++/Python library. In this report, I just choose the first way. As I said before, this project is a SAT solver which means it could find out the situations which fulfill the input or return error. The grammar is very simple just like this. The first line means this input has 2 variables and 4 clauses. Every line is a clause which is ended by “0”. Using the third line as an example, it says that 2 is TRUE and 3 is FALSE. I use this file as an input and run it in the terminal. The result is shown as follows. It means 1 is TRUE, 2 and 3 are FALSE is the only solution to this problem. This is another example and the result. It means there isn’t a solution to this problem. ¶How It Works There are many improvements and techniques included in this project. It uses “Minisat” as its core and uses Gaussian Elimination on top-level. This is another part of its techniques. Variable elimination and replacement, strengthening and subsumption; Gate-based clause shortening and removal; No time or memory-outs on weird CNFs; Variable renumbering and variable number hiding. due to this, XOR clauses are cut and the added variables are always consistently displayed; Temporary results are stored in SQLite which supports high speed update; XOR recovery.","categories":[{"name":"solver","slug":"solver","permalink":"http://meng.uno/categories/solver/"},{"name":"SAT","slug":"solver/SAT","permalink":"http://meng.uno/categories/solver/SAT/"}],"tags":[{"name":"CryptoMinisat","slug":"CryptoMinisat","permalink":"http://meng.uno/tags/CryptoMinisat/"},{"name":"SAT","slug":"SAT","permalink":"http://meng.uno/tags/SAT/"},{"name":"solver","slug":"solver","permalink":"http://meng.uno/tags/solver/"}]},{"title":"Trinity","slug":"trinity","date":"2018-01-05T14:37:53.000Z","updated":"2018-02-11T14:48:52.839Z","comments":true,"path":"posts/664baed9/","link":"","permalink":"http://meng.uno/posts/664baed9/","excerpt":"","text":"As we all known, system call testing is very important to a system. System call fuzzers aren’t a particularly new idea. A few projects began from the mid-2000s with the aim of bringing more sophistication to the fuzz-testing process. One of them, Scrashme, was started in 2006. Work on that project languished for a few years, and only picked up momentum starting in late 2010, when the authors began to devote significantly more time to its development. In December 2010, Scrashme was renamed to Trinity which is this project. Trinity is an intelligent system call fuzzer since it incorporates specific knowledge about each system call which is tested. Its thought is to reduce the time spent running “useless” tests, so reaching deeper into the tested code and increasing the chances of testing a more interesting case that may result in an unexpected error. ¶Build and Run We can get the source code from GitHub, compile the code and invoke Trinity with a command line as simple as “./trinity”. Building this project is very simple, we just need to enter the directory and “./configure; make”. It’s so simple that the authors didn’t write it out. The result of a successful “make” is like this: Now let’s run it. I will test a system call “madvise” as an example. From the above picture, we can see that there are 384 32 bits system calls and 333 64 bits system calls tested in this project (not all in this test case). The log information of the main test process and its children processes are stored separately like this. This project also has many other test modes which I didn’t test here. Trinity has been rather successful at finding bugs if we fully test it. It said that the authors of this project had sometimes left systems running for hours or days in order to discover failures. ¶Analyze the Test Here is the segment of the code of system call “madvise”. This is a structure definition, from which we can see Trinity has some understanding of the arguments for each system call. This is why it brings intelligence to its tests. The “.num_args” means that this system call need 3 parameters. These parameters are “arg1, arg2, arg3” whose names and types are defined as the picture shows. I found the architecture of Trinity from its website. From this picture, we know that the “trinity-main” process kicks off a number of child processes (It is 4 in this picture) that perform the system call tests. There is a shared memory region used to record various pieces of global information, such as open file descriptor numbers, total system calls performed, and number of system calls that succeeded and failed. The shared memory region also records various information about each of the child processes as the picture shown in the “Build and Run” section. The “trinity-watchdog” process ensures that the test system is still working correctly which is similar to the function of “Zookeeper” to “Hadoop”, I think. ¶Write A Test First, we need to select a system call for testing. I choose “getcpu” system call here from “syscalls.h” file. (We need to delete the original test file because all system call listed in “syscalls.h” are tested.) Then I write a new file to “/trinity/syscalls/” directory named “meng.c” and the contents are as follows. The type of parameters can be found at “syscall.h” as follows. After compiling the file and running, here is part of the result. In the future, I may add some system calls which it didn’t test till now to this project. However, you can see that it is very difficult for us to really test a system call which we used everyday using this project because Trinity randomly invokes system calls currently and real programs demonstrate common patterns for making system calls.","categories":[{"name":"Fuzzer","slug":"Fuzzer","permalink":"http://meng.uno/categories/Fuzzer/"}],"tags":[{"name":"Trinity","slug":"Trinity","permalink":"http://meng.uno/tags/Trinity/"},{"name":"Fuzzer","slug":"Fuzzer","permalink":"http://meng.uno/tags/Fuzzer/"}]},{"title":"Boogie","slug":"boogie","date":"2018-01-03T14:43:12.000Z","updated":"2018-02-11T14:48:52.838Z","comments":true,"path":"posts/4f0a9591/","link":"","permalink":"http://meng.uno/posts/4f0a9591/","excerpt":"","text":"Boogie is an intermediate verification language (IVL), intended as a layer on which to build program verifiers for other languages. It is also the name of the verification tool that takes Boogie programs as input. It can accept the input of a Boogie program and generate verification conditions that are passed to an SMT solver such as Z3 used by my test. ¶Build and Run Building this project is very simple, however, we may need to install many other tools such as “Mono” (I use a MacBook to build this project) and “NuGet”. The information of successfully building is like this. There are two kinds of verifications said by the authors: Driver tests and Unit tests, however, I couldn’t find the python script for the latter, so I just run the driver tests. ¶Driver Tests In this kind of tests, we need to use “lit” and “OutputCheck”. We could run all the tests by “lit .”. The result is shown as follows. We also could run a single test by giving “lit” a specific folder or file. The picture is a test of a folder. ¶Analyze the Test The picture is a function written by Boogie, from which we can see that the Boogie language is something like C language. In addition, in every Boogie file, every function is separated. If there are some errors occurred, there will be a “.expect” file outputted like this to tell us why they are wrong. ¶Write A Test We can write a new file or just add our function to a existed file. The following is my test: This is the result: I plan to analyze this project deeply, however, its code is very old so it maybe a little difficult for me to do this. I just do these tests on this projects now. Maybe I will analyze the whole project some day. From this project, I can learn what is an intermediate verification language (IVL) and how it works. I found that there were many tools adapting this strategy, including the VCC and HAVOC verifiers for C and the verifiers for Dafny, Chalice, and Spec#.","categories":[{"name":"Language","slug":"Language","permalink":"http://meng.uno/categories/Language/"}],"tags":[{"name":"Boogie","slug":"Boogie","permalink":"http://meng.uno/tags/Boogie/"},{"name":"Language","slug":"Language","permalink":"http://meng.uno/tags/Language/"}]},{"title":"Simple Theorem Prover SMT solver","slug":"stp","date":"2018-01-03T13:42:58.000Z","updated":"2018-02-11T14:04:49.153Z","comments":true,"path":"posts/cd3afb7d/","link":"","permalink":"http://meng.uno/posts/cd3afb7d/","excerpt":"","text":"I found it could be generated as program analysis tools, theorem provers, automated bug finders and so on which means it is a very crucial research. STP is a constraint solver aimed at solving constraints of bit vectors and arrays. It can read CVC, SMT-LIB1 and SMT-LIB2 formats files. It also could be used by Python, SMT-LIBv2 and even C library. STP preprocesses the input through the application of mathematical and logical identities, and then eagerly translates constraints into a purely propositional logic formula that it feeds to an off-the-shelf SAT solver. STP views memory as untyped bytes. It provides only three data types: booleans, bitvectors, and arrays of bitvectors. A bitvector is an unsigned, fixed-length sequence of bits. For example, “0010” is a constant, 4-bit bitvector representing the constant 2. ¶Build and Run We can build this project on Linux or Docker, however, you know, Google isn’t well supported in China, so I can’t use “repo” execution which needed by Docker. In this document, I will use a quick install. Firstly, we need to install many dependencies. Then, since STP uses “minisat” as its SAT solver by default, we need to install it first. It is very simple to do this by “cmake”. The following is part of the output. Then we could start to install STP (To get the code, we need to use “git clone” but not download it directly). This project depends on various external tools to do testing. Here we install “lit” and do some individual tests and use “GoogleTest” to write some unit tests. ¶Analyze Individual Test An individual test is like this. In this screenshot, we can see that this file is judging “b = (c || b)” and “((c || b) = b) &lt; c &lt; b”. We could find that an individual test file may contain these components: “; line”: comments; “set-info”: set some configuration information for running this file; “declare-fun”: definite some functions and their return types; “assert”: like C lang, do some judgement; “exit”: return. ¶Analyze Unit Test We can simply run unit test by giving “lit” the individual tests directory or run “make C-api-tests” to build the C-api tests as unit tests. The Cpp file is like this. From this picture, we can see that a C-api test contains many simple verifications. ¶Analyze the Code Structure From the above picture, I give the following simple understandings to this project. “Interface”: Define a C interface to achieve the file ins and outs; “Sat”: Copy from “minisat” to call SAT solver. “AST”: Implement the abstract syntax tree for parsed solver inputs; “Util”: Store some header files for small tasks; “Printer”: Appoint some output formats; “Simplifier”: Simplify algorithms for AST; “Parser”: Store some parsers for the CVC, SMT-LIB1, SMT-LIB2 inputs; “STPManager”: Hold all components together.","categories":[{"name":"solver","slug":"solver","permalink":"http://meng.uno/categories/solver/"},{"name":"SMT","slug":"solver/SMT","permalink":"http://meng.uno/categories/solver/SMT/"}],"tags":[{"name":"solver","slug":"solver","permalink":"http://meng.uno/tags/solver/"},{"name":"STP","slug":"STP","permalink":"http://meng.uno/tags/STP/"},{"name":"SMT","slug":"SMT","permalink":"http://meng.uno/tags/SMT/"}]},{"title":"跨领域分词国内外研究现状","slug":"word-seg-history","date":"2017-12-22T12:15:00.000Z","updated":"2018-02-13T14:06:49.673Z","comments":true,"path":"posts/e38d3f1c/","link":"","permalink":"http://meng.uno/posts/e38d3f1c/","excerpt":"","text":"¶国内研究 国内研究中文分词的科研单位主要有：中科院、清华、北大、北京语言学院、东北大学、MSRA、IBM研究院以及哈工大等。 国内主要的成熟的分词系统：ICTCLAS（汉语词法分析系统）、海量信息、盘古分词、结巴分词、BosonNLP以及**哈工大语言云（LTP-Cloud）**等。 国内在中文分词算法的研究上进展颇丰，参与的科研机构也比较多，使用的方法也比较杂乱，从[1]—[19]可以看出。国内分词算法上的进展主要有：2005年，哈工大[13]在分词阶段以基于词的n-gram方法为核心。先将词按照词典初步切分，并从训练语料统计得到3-gram信息，动态规划计算哪条切分路径最优。但在命名实体识别、新词识别、消除分词歧义部分使用ME模型。2007年，赵海等人[19]研究了基于子串标注的分词算法，在Bakeoff-2005测试集上准确度较高。2009年，[3]利用一种基于N元语法的汉语自动分词系统, 将分词与标注结合起来, 用词性标注来参与评价分词结果。[34]提出了一种字词联合解码的分词方法，算法中使用了字、词信息，充分发挥由字构词识别未登录词的能力。2010年，[35]提出基于词边界分类的分词方法，该方法对字符之间的边界进行分类，判断是否为词的边界，从而达到分词目的。[36]将基于字的生成模型与基于字的判别模型进行联合。2014年，[29]对[28]的模型做了重要改进，引入了标签向量来更精细地刻画标签之间的转移关系，其改进程度类似于引入Markov特征到最大熵模型之中。2015年，为了更完整精细地对分词上下文建模，[30]提出了一种带有自适应门结构的递归神经网络(GRNN)抽取n-gram特征，其中的两种定制的门结构（重置门、更新门）被用来控制n-gram信息的融合和抽取。2016年，[31]将GRNN和LSTM联合起来使用。该模型中，先用双向LSTM提取上下文敏感的局部信息，然后在滑动窗口内将这些局部信息用带门结构的递归神经网络融合起来，最后用作标签分类的依据。[32]提出了一种基于转移的模型用于分词，并将传统的特征模版和神经网络自动提取的特征结合起来，在神经网络自动提取的特征和传统的离散特征的融合方法做了尝试。2017年，[33]通过简化网络结构，混合字词输入以及使用早期更新（early update）等收敛性更好的训练策略，设计了一个基于贪心搜索(greedy search)的快速分词系统。该算法与之前的深度学习算法相比不仅在速度上有了巨大提升，分词精度也得到了进一定提高。 在领域自适应方面相关研究比较少，2008年，[45]利用并发展针对单个汉字的构词能力和构词模式公式, 计算词的构词能力和词的构词模式, 并以此作为新词发现的规则, 对科技领域做了新词发现和新技术发现的实验。2012年，[41]通过将外部词典信息融入统计分词模型 (使用CRF 统计模型)来实现领域自适应性。在确定一个领域并给出这个领域的文献数据集合的前提下，[44]主要从这两个步骤进行新词发现：首先对特定领域的文献集合进行分词处理，在进行分词处理方面使用了基于统计的N-Gram方法，较为有效地找出了词典中所不存在地新词汇；第二个步骤为新的专业词汇的抽取，这是一个根据已有专业词汇来发现未知专业词汇的过程，目的从第一步中所产生的新的词汇中抽取出新的属于目标领域的专业词汇，在这个步骤中，使用了Apriori方法。2013年，[40]实现了基于生语料的领域自适应分词模型和双语引导的汉语分词，并提出融合多种分词结果的方法，通过构建格状(Lattice)结构并使用动态规划算法得到较佳汉语分词结果。2015年，[39]提出Active Learning与n-gram统计特征相结合，通过对目标领域文本与已有标注语料差异统计分析，选择含有最多未标记过得语言现象的小规模语料优先进行人工标注的方法，此法验证在科技文献上有所提高。[43]提出使用卡方统计 量以及边界熵提升未登录词的处理能力，并结合自学习和协同学习策略进一步改善字标注分词方法在领域适应性方面的性能。2016年，[42]提出一种条件随机场与领域词典相结合的方法提高领域自适应性，并根据构词规则提出了固定词串消解，动词消解，词概率消解三种方法消除歧义。 ¶国外研究 国外研究中文分词的主要科研机构有：斯坦福、SUTD、UC Berkeley、CMU、CityU等。 国外成熟的分词系统有：Core NLP（斯坦福 NLP Group）、Zpar（SUTD）、Basis Technology、Open NLP (Apache 基金会)等。 国外分词算法上的进展：2003年之前，主要集中在词典与人工规则相结合，词典与概率统计规则相结合。2005年，开始使用基于字序列标注的分词方法，该方法始于[20]，第一次将严格的串标注学习应用于分词在[21]和[22]之后。[23]与[24]的出现，基于CRF模型崭露头角，在此之后，CRF多个变种构成了深度学习时代之前的标准分词模型。基于词的随机过程建模导致一个CRF变种，即semi-CRF(半条件随机场)模型的直接应用。2006年，基于字序列标注的方法已经开始盛行，核心模型仍然是ME与CRF，同年，[25]发表semi-CRF的第一个分词实现。[26]提出了一种基于子词（subword）的标注学习，基本思路是从训练集中抽取高频已知词构造子词词典。2007年，ME的方法已经开始退出舞台，CRF越来越成为主流。2010年，核心方法还是基于CRF模型，后处理是SVM-HMM模型。2011年，当子串的抽取和统计度量得分计算扩展到训练集之外，[27]实际上提出了一种扩展性很强的半监督分词方法，实验也验证了其有效性。2013年，[28]提出神经网络中文分词方法，首次验证了深度学习方法应用到中文分词任务上的可行性。 在领域自适应上，由耶鲁大学教授提出的Active Learning得到了较为广泛的使用。 待补充 ¶参考文献 [1] 马晏. 基于评价的汉语自动分词系统的研究与实现[D]. 清华大学, 1991. [2] 张国兵, 李淼. 一种基于局部歧义词网格的快速分词算法[J]. 计算机工程与应用, 2008, 44(12):175-177. [3] 石佳, 蔡皖东. 基于N元语法的汉语自动分词系统研究[J]. 微电子学与计算机, 2009, 26(7):98-101. [4] 韩莹, 王茂发, 陈新房,等. 汉语自动分词词典新机制—词值哈希机制[J]. 计算机系统应用, 2013, 22(2):233-235. [5] 蒋才智, 王浩. 基于memcached的动态四字双向词典机制[J]. 计算机应用研究, 2011, 28(1):152-154. [6] 刘超, 王卫东. 基于双哈希词典机制中文分词的研究[J]. 信息技术, 2016, 40(11). [7] 刘挺, 吴岩, 王开铸. 串频统计和词形匹配相结合的汉语自动分词系统[J]. 中文信息学报, 1998, 12(1):17-25. [8] 唐涛. 面向特定领域的中文分词技术的研究[D]. 沈阳航空航天大学, 2012. [9] 卢志茂, 刘挺, 郎君,等. 神经网络和贝叶斯网络在汉语词义消歧上的对比研究[J]. 高技术通讯, 2004, 14(8):15-19. [10] 廖先桃, 于海滨, 秦兵,等. HMM与自动规则提取相结合的中文命名实体识别[C]// 全国学生计算语言学研讨会. 2004. [11] 程志刚. 基于规则和条件随机场的中文命名实体识别方法研究[D]. 华中师范大学, 2015. [12] 祝继锋. 基于SVM和HMM算法的中文机构名称识别[D]. 吉林大学, 2017. [13] ZHUORAN WANG, TING LIU. Chinese Unknown Word Identification Based on Local Bigram Model[J]. International Journal of Computer Processing of Oriental Languages, 2012, 1(3):185-196. [14] 原媛, 彭建华, 张汝云. 基于统计的汉语词义消歧研究[J]. 信息工程大学学报, 2007, 8(4):501-504. [15] 肖建涛. 基于最大熵原理的汉语词义消歧与标注语言模型研究[D]. 北京机械工业学院 北京信息科技大学, 2007. [16] 张旭. 一个基于词典与统计的中文分词算法[D]. 电子科技大学, 2007. [17] 佟德琴. 基于字词联合解码的中文分词研究[D]. 大连理工大学, 2011. [18] 赵海, 揭春雨, 宋彦. 基于字依存树的中文词法-句法一体化分析[C]// 中国计算机语言学研究前沿进展. 2009. [19] 赵海, 揭春雨. 基于有效子串标注的中文分词[J]. 中文信息学报, 2007, 21(5):8-13. [20] Nianwen Xue. Chinese Word Segmentation as Character Tagging. Computational Linguistics and Chinese Language Processing, 8(1), 2003, pp. 29–48. [21] Hwee Tou Ng and Jin Kiat Low. Chinese part-of-speech tagging: One-at-a-time or all-at-once? word-based or character-based? In Conference on Empirical Methods in Natural Language Processing, 2004, pp. 277–284. [22] Jin Kiat Low, Hwee Tou Ng, and Wenyuan Guo. A maximum entropy approach to Chinese word segmentation. In Proceedings of the SIGHAN Workshop on Chinese Language Processing, 2005, pp. 448–455. [23] Huihsin Tseng, Pichuan Chang, Galen Andrew, Daniel Jurafsky, and Christopher Manning. A conditional random field word segmenter for SIGHAN bakeoff 2005. In Proceedings of the SIGHAN workshop on Chinese language Processing, vol. 171, 2005. [24] Fuchun Peng, Fangfang Feng, and Andrew McCallum. Chinese segmentation and new word detection using conditional random fields. In Proceedings of the international conference on Computational Linguistics, 2004, pp. 562–569. [25] Galen Andrew. A hybrid Markov/semi-Markov conditional random field for sequence segmentation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2006, pp. 465– 472. [26] Ruiqiang Zhang, Genichiro Kikui, and Eiichiro Sumita. Subword-based tagging for confidence-dependent Chinese word segmentation. In Proceedings of the Annual Meeting of the Association for Computational Linguistics and the international conference on Computational Linguistics, 2006, pp. 961–968. [27] Hai Zhao and Chunyu Kit. Integrating Unsupervised and Supervised Word Segmentation: the Role of Goodness Measures. Information Sciences, 181(1), 2011, pp. 163–183. [28] Xiaoqing Zheng, Hanyang Chen, and Tianyu Xu. Deep learning for Chinese word segmentation and POS tagging. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2013, pp.647–657. [29] Wenzhe Pei, Tao Ge, and Baobao Chang. Max-margin tensor neural network for Chinese word segmentation. In Proceedings of the Annual Meeting of the Association for Computational Linguistics, 2014, pp. 293–303. [30] Xinchi Chen, Xipeng Qiu, Chenxi Zhu, and Xuanjing Huang. Gated recursive neural network for Chinese word segmentation. In Proceedings of the Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, 2015a, pp. 1744–1753. [31] Jingjing Xu and Xu Sun. Dependency-based gated recursive neural network for Chinese word segmentation. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), 2016, pp. 567–572. [32] Meishan Zhang, Yue Zhang, and Guohong Fu. Transition-based neural word segmentation. In Proceedings of the Annual Meeting of the Association for Computational Linguistics, 2016, pp. 421–431. [33] Deng Cai, Hai Zhao, Zhisong Zhang, Yuan Xin, Yongjian Wu, and Feiyue Huang. Fast and accurate neural word segmentation for Chinese. In Proceedings of the Annual Meeting of the Association for Computational Linguistics, 2017. [34] 宋彦, 蔡东风, 张桂平,等. 一种基于字词联合解码的中文分词方法[J]. 软件学报, 2009, 20(9):2366-2375. [35] 李寿山, 黄居仁. 基于词边界分类的中文分词方法[J]. 中文信息学报, 2010, 24(1):3-7. [36] Wang K, Su K Y, Su K Y. A character-based joint model for Chinese word segmentation[C]// International Conference on Computational Linguistics. Association for Computational Linguistics, 2010:1173-1181. [37] 王娟, 曹庆花, 黄精籼,等. 基于受限领域的中文分词系统[J]. 信息系统工程, 2011(11):106-106. [38] 张少阳. 领域自适应中文分词系统的研究与实现[D]. 沈阳航空航天大学, 2017. [39] 许华婷, 张玉洁, 杨晓晖,等. 基于Active Learning的中文分词领域自适应[J]. 中文信息学报, 2015, 29(5):55-62. [40] 苏晨, 张玉洁, 郭振,等. 适用于特定领域机器翻译的汉语分词方法[J]. 中文信息学报, 2013, 27(5):184-190. [41] 张梅山, 邓知龙, 车万翔,等. 统计与词典相结合的领域自适应中文分词[J]. 中文信息学报, 2012, 26(2):8-12. [42] 朱艳辉, 刘璟, 徐叶强,等. 基于条件随机场的中文领域分词研究[J]. 计算机工程与应用, 2016, 52(15):97-100. [43] 韩冬煦, 常宝宝. 中文分词模型的领域适应性方法[J]. 计算机学报, 2015, 38(2):272-281. [44] 李明. 针对特定领域的中文新词发现技术研究[D]. 南京航空航天大学, 2012. [45] 王文荣, 乔晓东, 朱礼军. 针对特定领域的新词发现和新技术发现[J]. 现代图书情报技术, 2008, 24(2):35-40.","categories":[{"name":"毕设","slug":"毕设","permalink":"http://meng.uno/categories/毕设/"},{"name":"研究现状","slug":"毕设/研究现状","permalink":"http://meng.uno/categories/毕设/研究现状/"}],"tags":[{"name":"分词","slug":"分词","permalink":"http://meng.uno/tags/分词/"},{"name":"跨领域","slug":"跨领域","permalink":"http://meng.uno/tags/跨领域/"}]},{"title":"Software Verification Approaches","slug":"software-verification","date":"2017-12-11T13:19:48.000Z","updated":"2018-02-11T14:04:49.152Z","comments":true,"path":"posts/55e262ef/","link":"","permalink":"http://meng.uno/posts/55e262ef/","excerpt":"","text":"¶Network Function Virtualization (NFV) In the beginning, we need to know NFV which through the establishment of VNF (Virtualized Network Function) to achieve some network functions on a common server, switches, memory and other hardware devices, making these network functions on a common hardware device run, do not need to configure a new dedicated network elements, can greatly enhance the flexibility of the network deployment, and lower investment costs. In the process of realization of network functionality through NFV technology, VNF in the form of software running on the hardware, by way of example and to achieve termination VNF allocation and deallocation of resources. In order to avoid VNF packet forgery in transit and in storage and tampering, increasing the signature files in the software package VNF, the receiving end after receiving the VNF software package by verifying signature files for VNF package for secure authentication to ensure VNF packet during transmission security; in addition, the receiving end before VNF instantiated need for storage VNF package for secure authentication to ensure VNF package in the store security, which increased VNF instantiation delay, reduce the VNF instantiated performance. ¶Systems-Theoretic Process Analysis (STPA) STPA is for identifying harmful circumstances which could lead to accidents and generating detailed safety requirements which must be implemented in the design to prevent the occurrence of these unsafe scenarios in the system. STPA is a top-down process and it addresses many types of hazards of components and their interactions like design errors, software flaws and component interaction failures. One of the advantages of STPA is that it can be applied at any stage of the system development process. STPA is performed by four main steps: Before conducting an STPA analysis, the safety analysts should establish fundamentals of the analysis (e.g. accidents, the associated hazards) and construct the control structure diagram. For each control action in the control diagram, the safety analysts must identify the potentially unsafe control actions of the system that could lead to a hazardous state. A unsafe control action is a control action that violates system safety constraints. Use the identified hazardous control actions to create safety requirements and constraints. Determine how each potentially hazardous control action, identified in step 2., could occur by augmenting the control structure diagram with a process model. ¶Software Model Checking (SMC) SMC is an automatic technique based on a verification model which explore all possible software states in a brute-force manner to prove properties of their execution. The model checking process involves the target software to be formally modeled in the input language of a model checker and specifications (properties) to be formalized in a temporal logic. Many safety-critical software systems are being written in ANSI-C. Therefore, there exist a number of software model checker tools which are used to verify code conducted a comparison and evaluation of existing model checking tools for C code. This comparison showed that the SPIN model checker, a general-purpose model checker, uses an efficient algorithm to reduce the state explosion problem. ¶Safety Analysis Combining STPA and SMC This method can derive software safety requirements at the system level and to verify them at the code level. This approach is divided into three kinds of activities: Deriving software safety requirements using STPA; Formalizing of safety requirements and Verifying software against its safety requirements at the code level. The structure is like this: ¶Fault Tree Analysis (FTA) FTA is a top-down, deductive failure analysis in which an undesired state of a system is analyzed using Boolean logic to combine a series of lower-level events. The propose is to understand how systems can fail, to identify the best ways to reduce risk or to determine event rates of a safety accident or a particular system level failure. This method can divide into 5 steps: Define the undesired event to study; Obtain an understanding of the system; Construct the fault tree; Evaluate the fault tree; Control the hazards identified.","categories":[{"name":"Software Verification","slug":"Software-Verification","permalink":"http://meng.uno/categories/Software-Verification/"}],"tags":[{"name":"Software Verification","slug":"Software-Verification","permalink":"http://meng.uno/tags/Software-Verification/"}]},{"title":"Some Throughts on Big Graphs Research","slug":"big-graphs-throught","date":"2017-12-08T13:26:46.000Z","updated":"2018-02-11T14:04:49.149Z","comments":true,"path":"posts/52d6fa6b/","link":"","permalink":"http://meng.uno/posts/52d6fa6b/","excerpt":"","text":"¶Redesign the Frameworks Used for Big-Graphs Mining. Nowadays, researches on Big-graphs are only using those open source distributed systems such as Hadoop, Spark and so on. I don’t mean they are bad, but I think we could redesign some new frameworks based on they. If I do this research, I will first redesign some data structure such as Inverted files for those distributed systems. ¶Mine Frequent Subgraphs by Adding Some Parameters. Mining frequent subgraphs is very crucial to SNS network graphs. In these networks, a user is often associated with location information (e.g., positions of her hometown and check-ins). These networks are collectively known as spatial graphs. However, it isn’t mean those who are in a same location are in the same subgraph. For example, if I am in Singapore, I may also care China more Singapore, so I belong to the subgraph of China instead of others. In this circumstance, we need add more parameters to our mining methods to get the right mining result. ¶Temporal and Streaming Systems for Dynamic Graphs Despite the plurality of graph systems, majority of them support processing static graphs only. In reality, however, many graph applications today need to handle changes to the graphs over time. Many challenges remain in this sub-field. For example, most temporal and streaming graph systems cannot efficiently handle frequent vertex and edge deletions, as deletions often break the nice properties that enable incremental computation in these systems. Certainly, maybe I will do some research in this area to support efficient analysis of dynamic graphs. ¶Data Structure for Storing the Big-Graphs Most graph analysis systems assume that the graph is already generated in the requisite format for ingesting into the system. In practice, however, usually the graphs must first be extracted from non-graph data stores using a pre-processing step that generates the lists of nodes and edges. In many cases, graph analysis may form one component of a deep analysis pipeline, that also involves non-graph analytics operations; in such cases also, we may need to convert the data among different representations. The costs of such pre-processing or conversion steps can be significant, and in some cases, the cost of extracting graphs may dominate the actual computation that follows (e.g., if edges are generated by computing similarities between node attributes).","categories":[{"name":"Big Graphs","slug":"Big-Graphs","permalink":"http://meng.uno/categories/Big-Graphs/"}],"tags":[{"name":"Big Graphs","slug":"Big-Graphs","permalink":"http://meng.uno/tags/Big-Graphs/"}]},{"title":"浅析VR/AR+：医疗","slug":"vr-ar-medicine","date":"2017-11-18T13:07:15.000Z","updated":"2018-02-14T11:13:32.514Z","comments":true,"path":"posts/c1dd0093/","link":"","permalink":"http://meng.uno/posts/c1dd0093/","excerpt":"","text":"VR/AR介绍 虚拟现实技术（VR）是一种可以创建和体验虚拟世界的计算机仿真系统，它利用计算机生成一种模拟环境，是一种多源信息融合的、交互式的三维动态视景和实体行为的系统仿真使用户沉浸到该环境中。 VR是仿真技术的一个重要方向，是仿真技术与计算机图形学人机接口技术多媒体技术传感技术网络技术等多种技术的集合，是一门富有挑战性的交叉技术前沿学科和研究领域。VR主要包括模拟环境、感知、自然技能和传感设备等方面。模拟环境是由计算机生成的、实时动态的三维立体逼真图像。感知是指理想的VR应该具有一切人所具有的感知。除计算机图形技术所生成的视觉感知外，还有听觉、触觉、力觉、运动等感知，甚至还包括嗅觉和味觉等，也称为多感知。自然技能是指人的头部转动，眼睛、手势、或其他人体行为动作，由计算机来处理与参与者的动作相适应的数据，并对用户的输入作出实时响应，并分别反馈到用户的五官。传感设备是指三维交互设备。 而增强现实技术（AR）是一种实时地计算摄影机影像的位置及角度并加上相应图像、视频、3D模型的技术，这种技术的目标是在屏幕上把虚拟世界套在现实世界并进行互动。AR最早是于1990年提出的，之后随着电子产品运算能力的提升，其应用也是用途愈广。尤其是近两年来AR技术可谓是备受关注！现在的市场中由于可穿戴设备的出现，以及手机性能的进一步提升，AR技术也是持续升温。 AR是一种将真实世界信息和虚拟世界信息“无缝”集成的新技术，是把原本在现实世界的一定时间空间范围内很难体验到的实体信息（视觉信息,声音,味道,触觉等），通过电脑等科学技术，模拟仿真后再叠加，将虚拟的信息应用到真实世界，被人类感官所感知，从而达到超越现实的感官体验。真实的环境和虚拟的物体实时地叠加到了同一个画面或空间同时存在。不仅展现了真实世界的信息,而且将虚拟的信息同时显示出来，两种信息相互补充、叠加。在视觉化的AR实现中，用户利用头盔显示器，把真实世界与电脑图形多重合成在一起，便可以看到真实的世界围绕着它。 在接下来的叙述中，我将在第二部分分析VR/AR对于医生角度的应用，第三部分分析在病人角度的应用，第四部分是在医疗教育方面的应用，其他相关的研究我将在第五部分陈述，现阶段研究的不足将在第六部分分析，最后两部分是一点我的个人感想和本文结论。 对于医生的应用 ¶模拟手术 虚拟手术作为一个虚拟现实领域的重要研究方向，正成为科学家们的关注焦点。它是集现代医学、计算机图形学、计算机视觉、生物力学、材料学、机器人等诸多学科为一体的新型交叉研究领域。医生可以通过虚拟现实技术来模拟、指导医学手术所涉及的各种过程，包括手术计划制定、手术排练演习、手术教学、手术技能训练、术中引导手术、术后康复等。 80%的手术失误是人为因素引起的，因此手术训练极其重要。以前医生手术训练都只能在病人身上做，所以经常说有名的医生都是踏过多少人的血液才走过来的，这样付出的代价实在太大。在VR/AR技术飞速发展并广泛应用的今天，模拟手术在医生训练过程中非常重要的应用就是，医生可以在不接触实际病人的前提下模拟各种手术场景，模拟的场景可能比真实遇到的情况还要多，这样模拟训练的效果实际上就超过了真实的练刀。一方面，模拟训练可以在任何地方、任何时间反复模拟，深化印象，这个优点在实际病人身上是不可能也不允许做的，因为病人的资源是有限的。模拟手术就是把每个可能的手术场景都呈现在你的面前，每个人得到的机会都是无穷次的，医生可以反复看、反复练，并且对病人没有伤害。如果从这点来讲，一个经过模拟训练的医生再给病人做手术时，他的学习周期就会很短很短，这个实际上是对病人利益的极大保护。当前模拟手术在中国也已经有了，像强生公司、科汇公司的外科培训中心已经有腹腔镜的模拟，也有介入手术的模拟，当然还有达芬奇手术的模拟，但这种模拟还不是真实场景的，也就是说未来在VR技术里面，可以完全进入到手术室，然后在真实的场景里面进行模拟手术，那就更加接近于现实。 大家应该知道在体育运动里，比如足球、体操，都有慢动作回放，有动作捕捉去分析运动员动作是否做到位了，失误的原因是什么。这个技术同样可以用到外科手术里。通过运动捕捉或者手势识别和VR技术，在外科大夫进行学习或尝试以后，可以复原手术，看到手术的过程，如果有失误，原因是什么。这种回放能极大的帮助医生改进他们的技术。 ¶远程干预/指导 世界上首例实验性远程手术已经在1999年成功地进行。虚拟手术与远程干预将能够使在手术室中的外科医生能实时地获得远程专家的交互式会诊。交互工具可以使顾问医生把靶点投影于患者身上来帮助指导主刀外科医生的操作，甚或通过遥控帮助操纵仪器。这能使专家们技能的发挥不受空间距离的限制。如果VR技术在这一方面继续发展的话，可能会出现以后医生不用到医院上班，无论在任何地方都可以实施手术。缓解了当今医院基础设施不足的现状。同时，有些相同的手术，某专家可以通过VR技术远程指导，这样就打破了一个时间段只能进行一项手术的限制，大大提高医疗的效率。 ¶精确操作 如上文已经提到的达芬奇机器人，还有很多像这种医生能够远程控制其操作的手术设备，通过使用这些设备，能够在实际的手术中，避免因为医生长时间工作造成的身体情况变化而带来的手术质量参差不起的问题（例如某医生一天手术过多，太过劳累，这样后来的手术必然会质量下降）。如果使用了VR技术，远程控制诸如达芬奇机器人一样的手术设备，不管医生自己身体状况如何，只要控制到位，那些手术设备是不会因为工作时间长就产生不适的，这样也能保证手术质量优秀。同时，一个医生只有两只手，所以有些手术需要助手，而使用那些设备之后，一个医生可以控制很多只手，这样就能够协调统一，对手术质量有百利而无一害。 ¶协助执行日常任务 医生需要经常查看病人的病情，而在现在的医疗设施情况下，对于一个医生，可能得通过“查房”一间一间地去病房里与病人交流，而且交流记录难免会记忆不清或者甚至搞混了。有了VR技术虚拟医生协助真实医生实现这些复杂的工作，效率必然会大大提高。医生甚至都不用出办公室，只需要观察相应的VR反馈就可以基本实现之前的“查房”任务。这样一来就可以大大减轻医生的负担，必然会对医生的日常工作效率产生积极的影响。这些虚拟医生与病人交流的数据可以保存用来对之后的反馈对比，当然可以用其他机器学习的方法来进行一些预测之类的计算。并且基于大数据，可能这些虚拟医生对单个病人情况的分析会比真实的医生更专业，因为医生也不是能对每个症状都了如指掌的。 有些病人（例如老人和小孩等）可能在认识自己病情上有欠缺，例如忘记吃药，每次吃多少药等，在传统的方案中，要么有专人提醒，要么在显眼的地方做上标记提醒，总之效率不高或者费时费人力。当我们在某种小的设备上加上VR/AR提醒，以一个三维立体的形象的形式来提醒病人，既省时又省人力，效率相对还比较高。 ¶获得医药信息 医生可能不能记住每种药物的作用，以及每种药物的使用方式，假如能通过VR技术将每种药的使用信息都记录下来，通过相关的设备，让医生在给病人开药的时候头脑里能对这种药的所有情况都回顾一遍，同时还可以与几种相似的药做对比，找出最好的组合，避免偶尔的误用药。 ¶获取用户机体信息 在现在正常的医学治疗步骤中，医生想要检查病人某部位的病变情况，只能使用诸如CT、CTA等基于切片的二维人体部位图像，这种图像相对来讲专业要求度较高，对人体伤害较大，同时准确性也不能得到保障。将VR应用于此种工作，我们可以得到人体某部位的三维立体真实大小的模型，这样一来医生的判断会更加准确而且这种图识别起来相对不需要那么复杂的专业知识。 ¶血管照明（辅助手术） 这算是一种比较专业地说法，和辅助手术概念比较类似，简而言之就是通过PC应用软件帮助医务人员在手术中能够查看隐藏的血管。此前，心脏病专家借助谷歌眼镜疏通了一位49岁男患者阻塞的右冠状动脉。冠状动脉成像（CTA）和三维数据呈现在智能眼镜的显示器上，根据这些实时放大图像，医生可以方便地将血液导流到动脉。不同于传统手术，AR的介入就像一个”AR放大镜”，直接放大手术创口，患者的彩超、MRI、CT图像等将直接映在手术部位，让医生能够看到肉眼难以分辨的细微情况，获得“透视”功能，大大提高手术操作的效率和舒适度。 ¶损伤评估 在传统的医疗实践中，如果病人就诊，医生为了确定病人病情只能通过明显的外表特征或者患者的口头表述来确定，而这样的手法往往会带来误判或者病情程度判断不清等问题，特别是那种很难表述清楚的内科疾病。运用虚拟现实技术，我们可以针对不同的疾病设定不同的诊断场景，让用户在特定场景中将应该表现出来的病症全部表现出来，这样一来有利于增大诊断的准确性。 对于病人的应用 ¶智能康复系统 基于Kinnect等运动捕捉设备所设计出的很多结合VR/AR技术的智能康复系统，这些系统能够很好的帮助病人进行相应的康复训练。在之前我所看到的一个例子中， 病人只需要带上相应的可穿戴传感器就可以将自己的动作传到相应的计算机进而在计算机显示屏上显示用户的动作以及在显示屏中出现的影像之间的交互。在我所看到的实例中，他们只是能做到在场景中增加一些物体（例如长方体等），让病人在虚拟的环境中模拟各种体力锻炼。这样一来，我们就不需要实际花费很多的金钱来布置训练场景，而且VR所形成的场景还可以很轻易得更换，不用为维护实际的场景而花费很多精力。 调查显示，以色列的研究人员开发出一套“电脑辅助康复环境系统”，通过模拟划船、打球、慢跑等各种情景，来帮助残障人士改善平衡能力，恢复身体的运动机能。足部神经受损的博罗夫斯基就在接受“电脑辅助康复环境系统”的治疗。现在系统模拟的是“海上冲浪”，大屏幕上显示的是冲浪的场景，博罗夫斯基脚下的踏板会根据设置好的程序相应的摇动，他必须通过调节身体的姿势来保持平衡。同时，连接在他身上的传感器还能把各种身体体征数据传回电脑，以便医生调整训练强度和难度。丰富的影像和新颖的训练方式，让患者像在做游戏一样，更能提高患者本身的主动性和积极性，加强训练效果，缩短住院时间，加快康复过程。无论从时间、人力还是金钱上讲，VR/AR技术的使用必然会在康复系统上带来一场新的革命。 ¶帮助治疗某些疾病 有些疾病（例如某种危险情况恐惧症），需要病人在再临其境时才可能克服，但如果让患者在现实中的危险环境再次体验，可能会有安全性问题，而且相同的场景很难真实地完美还原。如果使用VR技术，就可以在基本不耗费后期资源的情况下反复体验相同的场景，在现实中，用户也不会有任何的伤害，而且可调节范围比较广，毕竟是电脑虚拟程序，恐怖程度、危险指数等都可以随心所欲地变化，与现实相比真的是有巨大的优势。 截肢者中最常见的烦恼就是幻肢痛——患者感到被切断的肢体仍在，且在该处发生疼痛。疼痛多在断肢的远端出现，疼痛性质有多种，如电击、切割、撕裂或烧伤等。对幻肢痛的发生原理，目前尚无统一意见，西医亦乏有效疗法。很有可能大脑对肢体仍然存有意识，即使它已经不存在了。尽管这样的问题发生存在一定的频率，但至今没有一种有效地方法适用于所有的截肢者。在使用VR技术治疗过程中研究人员使用头戴式耳机和一个传感器将患者带入虚拟的世界，患者可以感受到自己的肢体还在，并可以控制虚拟肢体从事某项工作或游戏。这样就能很好的解决这一疾病，有研究表明对这种疾病VR治疗作用十分显著。 VR对创伤后应激障碍也同样有很好的治疗作用。在对从伊拉克和阿富汗返回患有创伤后应激障碍的士兵所进行的VR治疗过程中，VR设备会将会把士兵带回中东的一个小镇，让他们再次“经历”战争和死亡，使其在适当的压力下逐渐学会处理，控制自己的情绪。虽然很多人对于这种治疗方式存在争议，支持者说使用虚拟现实技术与其他的治疗方式相结合会达到非常很理想的治疗效果。 VR可以帮助治疗的心理障碍并不仅仅局限于创伤后应激障碍。还有些心理问题（例如自闭症、害羞等），是一个杀人于无形的凶手，目前呈现向低龄化蔓延的趋势。虚拟现实可能也会成为这个问题的解决方案之一。如果有人能既为患者保守秘密有能很好的与用户交流，对治疗这些疾病肯定是有很大的好处的，但是现实中不可能存在这样的一个完美的“倾听者”，即使有，价钱也是不菲的。如果VR/AR能够起到这样的作用那必然会是又一大医学进展。 很多心理治疗师和精神专家常用的方式是通过在治疗过程中去引导患者回忆或者想象场景，以此来达到治疗的目的。VR的好处在于它能够让这种环境场景变得可视化和标准化。因此在心理治疗领域，比如说创伤应急、障碍症、恐惧症、自闭症、恐高症、幽闭症、公开演讲恐惧症、密集恐惧症等都可以通过VR技术的环境再现以达到治疗的目的。再比如说，焦虑症、注意力缺陷以及精神分裂症也可以通过VR来虚拟特定的人或是特效来改善相关的一些症状。 ¶虚拟问诊 在国内外，好的医生都是十分欠缺的，然而相同的疾病缺屡见不鲜，可以说很多小病完全可以在还是在早期的时候就通过及时就诊可以避免出现的，在之前的这么多年，很多搜索引擎也都在做相关的疾病问答系统，可悲的是大多受金钱诱惑，为金钱奴役，不干正事反而虚假宣传。VR技术的出现，必然在医疗问答方面带来很大的革新，患者可以通过VR设备与虚拟的医生直接进行交谈，不仅避免了文字表述不清的问题，而且也避免受网页上那么多的虚假广告的诱惑，更是给人一种如见真实医生的舒适的感觉，而且VR医生会比现实中医生更有耐心，更专职为你一人服务。 ¶缓解疼痛 读到这样一个故事，“2017年年初，美国的一位脂肪瘤患者开刀时，因为平时血压过高，医生只为她注射了少量镇静剂。医生为她戴上了VR设备，在手术过程中患者一直在玩一个埃及探险的游戏。手术过程中，监测仪器显示患者的一切生命体征参数，都非常平稳。在整个手术过程中，患者的血压不仅没有提升，反而下降了。手术完成后，患者表示她几乎没有感到疼痛。”我觉得有了这个实例，我不需要过多的解释，已经能够很好的说明VR在缓解病人疼痛上的作用了吧。无独有偶，接受重度烧伤治疗是一段痛苦的经历。伤口清理和绷带变化都会引发疼痛，即便使用吗啡等麻醉药物，仍有86%的病人会感到或多或少的疼痛，并且大量使用还会对身体造成一定伤害。1996年，华盛顿大学人机界面技术实验室（HITLab）研究人员发现孩子们在玩游戏时是越来越全神贯注后，想出了为治疗烧伤提供VR游戏，假设沉浸在游戏中会为病人带来积极疗效，他们会更专注于游戏，而减轻对疼痛的注意力。据调查，社会行为医学2011年发布的调查展示了浸入式游戏作为止痛剂的强大作用。并且现在这项技术已经被美国军方使用，帮助受伤的士兵接受治疗。 当然在平时的生活中，VR也是能够起到很好的。当我们沉浸在一个虚拟的美好的游戏环境中时，我们可以忘记暂时的伤痛，这是一个常识，也是VR能在这一方面得到巨大应用的一个原因。 ¶戒瘾 当今社会的另一大“疾病”，不是身体上的，更大多数是心理上的，例如网瘾、烟瘾甚至毒瘾。在以前的戒瘾所，采取的唯一方式就是物理上的隔离，在VR技术快速发展的今天，我们完全可以通过VR将患者的精力集中到正确的角度上，不仅可以将效果提高，而且省时省力。查阅资料发现，我国相关法律已经开始涉足使用VR进行戒毒活动了。 当然，其实在这里VR可能成为一把双刃剑，可能能将用户的注意力从其他那些及其不正常的生活习惯中解救出来，但是可能又会让用户陷入“VR瘾”中，现在我们还无法证明这个“VR瘾”和其他的“网瘾”、“烟瘾”等孰轻孰重，所以此法需要慎重使用。 ¶VR/AR与视觉结合 VR本身就是可以直接作用于人的视觉，视觉治疗方案与VR技术很容易匹配。现在升学、工作压力，导致大部分人都有眼部疾病或视觉障碍。VR在治疗眼部的疾病，比如儿童的斜视、近视以及立体视力的缺陷上有很好的效果。虽然在不久之前就有对近视等疾病的物理治疗方案，但是大多费时费力，而且没有听说有什么可观的进展。但是VR/AR的到来就完全不同了，大大提高了效率而且效果明显提高。同时可以制作一种VR设备用来缓解疲劳的眼球，当我们工作或者学习很长时间之后，可以用它来对眼球“做做操”。虽然我们都明白久看之后需要远眺一会，或者看看绿色的动西，但是迫于现实，我们可能很难做到（例如哈尔滨的冬天没有绿树。），但是这一切都可以用VR设备来实现。 ¶缓解术前压力 接受手术的患者到了陌生环境，难免会有应激反应。他们可能觉得在手术室外等候，麻药还没有生效的时候，他们有强烈的紧张感和恐惧感，甚至有了濒临死亡的体验。现在想一想，这种体验对每个人来说都是非常不好的。虽然术前医生和患者有充足时间做沟通，但是单纯靠用嘴讲、用图、甚至手画示意图，都是一件非常累的事情，因为手术的复杂性和专业性，包括一些专有名词，对患者来说真的是选择性记忆，他们有可能听了上半句，就忘了下半句，甚至把最主要的东西漏掉，支离破碎地理会医生的意思，即使再出色的现场描述也比不过真实环境的真实还原。如果运用VR技术，在手术开始前给患者放一段容易让他放松的内容，让他在进手术室之前，大致了解手术室和手术过程是什么样子的，就能消除他对未知环境的恐惧。我相信这对患者来说是人文的关怀，这在提高医学服务水平里面可以得到有效的应用。 ¶隐私保护 现在我国的搜索引擎在医疗上很不受人看好的一个主要原因就是其泄露用户隐私的现象太严重，所以很少有人真正愿意相信搜出来的东西。加入VR/AR元素进入我们的生活，我们可以与虚拟形象进行完全不用担心泄露隐私的情况下的交流。 医疗教育的应用 ¶手术教学 伴随互联网的继续发展，如果医学手术教育能够通过VR/AR技术实现，至少在解剖学课程上可以实现意想不到的效果。在相关的设计中，例如心脏的VR模型可以做的特别逼真，让学生可以把心脏托在手里面，随时都可以转圈、打开肌肉看，血流都可以看，这就可以大大缩短医学生的学习周期（而且可以打破时间、地点的限制来学习）。尤其对于外科医生来讲，外科医生很重要的工作就是解剖。局部解剖以前医学生只能通过书本来学习，看到的都是平面的东西，脑子里很少有立体的概念，无法产生互动，进而需要很长的时间来消化知识，甚至很多时候大多数医学生并不能形成很好的立体的模型在脑子中，所以这就是很多庸医出现的根源。VR/AR技术的出现使得医学生在真正操刀做手术之前，就能获得局部解剖的经验，能够有效提高手术的安全性和成功率。而如果医学生通过VR/AR技术实现解剖模拟，学习速度会大大加快，同时降低学习的成本。当然AR在医学教育的应用并不仅仅是在解剖学上面，在生理生化方面都是可以通过VR技术模拟场景的。如果我们可以获得很形象的信息的话，对医生的知识拓展和学习速度都会急剧加快。 据早在1993年的统计里，全球市场上出现的805个虚拟现实应用系统中就有49个应用于医学，主要应用在虚拟人体、医学图像学、药物分子研究等方面。大家都知道，在传统的医学教育中，如人体标本解剖和各种手术实训，大都受到标本、场地等限制，实训费用高昂。而且医学生不能通过反复在病人身上进行操作来提高临床实践能力、临床实践具有较大风险。而VR的直观和体验特性却可以很好地解决以上问题。目前在医学教育上应用较多的有虚拟人体解剖学、手术训练教学、虚拟实验室、虚拟医院等。类别也从内容、软件到硬件，甚至还有从事交叉研发的，比如，Oculus涉足了内容、硬件和软件等方面，微软HoloLens则是软硬件结合等。 利用VR技术来做外科手术培训另一个重要的特点是，大大节约了成本。在外科领域，医疗知识每隔6~8年就要翻一番，所以外科大夫在专业教育上尤其是在继续教育上需要不断追求对新技术的学习，这种新技术的学习成本是高昂的，方法是复杂的。而VR技术可以在某种程度上帮助大家学习或者熟悉这种新技术。 ¶教学用具改革 传统解剖学挂图和大部分多媒体课件上应用的教学图片都是二维模式，缺少直观的、立体的体验，造成了解剖学习的困难。模型、标本虽具有立体结构，但形式单一、僵硬，不能满足多角度、多层次的教学和实训需求。而虚拟人体解剖图，可在显示人体组织器官解剖结构的同时，显示其断面解剖结构，并可以任意旋转，提供器官或结构在人体空间中的准确定位、三维测量数据和立体图像。此前，美国加州健康科学西部大学（波莫纳）开设了一个虚拟现实学习中心，该中心拥有四种VR技术、zSpace显示屏、Anatomage虚拟解剖台、Oculus Rift和iPad上的斯坦福大学解剖模型，旨在帮助学生利用VR学习牙科、骨科、兽医、物理治疗和护理等知识。 相关研究进展 尽管业内不少人将2016/2017年称之为“VR发展元年”，若追溯VR发展的历史，早在1932年，Aldous Huxley在其推出的科幻小说《美丽新世界》中即对虚拟现实概念进行了描述。而直到1968年计算机科学家Ivan Sutherland开发了“达摩克利斯之剑”，使得VR设备具备了基本的雏形。随后，VR设备开始应用在一些专精领域，如宇航员的训练活动中。直到1987年，任天堂推出了Famicom3D System眼镜之后，Virtual Boy等设备将VR概念正式带入民用领域。而随着近些年来，视频技术以及移动硬件领域的不断发展，民用VR平台也根据使用者的不同呈现出了分化的状态，包括以游戏平台作为计算平台的专属VR平台、以PC作为计算平台的综合体感VR平台、以及以移动设备作为计算与显示窗口的VR眼镜。 硬件厂商方面，在对各类VR设备的研发加大投入力度，VR头盔，眼镜，以及附属的传感器设备在过去的一年中纷纷涌现。 视频平台方面，除了传统视频上传方式外，各大视频平台均开放了“全景视频”的上传接口，用于鼓励视频制作团队为平台增加全景类视频的内容量。但由于目前全景视频的制作与存储成本非常高，能够完成全景视频录制与制作的团队并不多，所以目前多数存留在VR平台端的视频实际为3D的“沉浸式”的视频内容。除此之外，部分平台采取聚合方式，将目前市面上鲜见的VR视频内容加以收集整理，集中呈现在用户面前。而技术方案提供方虽然距离用户较远，却是目前推进整个VR行业发展的最为重要的一方，技术方案将成型的算法，图像引擎等输出给视频平台或硬件厂商，以增强用户在两方的使用体感。 存在的问题 VR在医疗应用方面，相比用作练习、模拟来讲还是很欠缺的。AR in China 最近期的统计，如今国内从事AR应用开发的企业有200多家，其中80%倾向和已开发游戏类应用，剩余的也多偏向影视、购物等生活类应用。而专注在医健领域的应用，根据公开信息推测目前不超过10家。而在海外，据 CBInsights、CrunchBase、AngelList 网站的综合数据查询，目前有30家左右初创公司正专注在AR医疗应用领域。其中9家初创公司获得融资，总融资额达5.52亿美元，获投率达到了30%。AR在医健领域的应用还处于蓝海探索期。 纯粹的VR在医疗领域还是有很大欠缺的。在现在的VR辅助手术中，医生只能利用AR技术的一些优势，并不能完全交给VR来做，还需要加上传统方法，一边做手术一边对着电脑屏幕比对着看。 VR用于治疗方式的缺点是患者的想象和回忆难于把控，所以效果很难评估。 而且现在的VR在显示和精确度方面还是有很大的提升空间的。特别实在医疗领域，准确度至关重要。 对于医生而言，还有适应问题，这些新技术对于有经验的外科医生及其他专业医护人员来讲，“适应”是最大的挑战。 虽然VR技术在医学上应用后能够减少现实中的直接的隐私泄露，但是如果VR数据泄露将导致比现在信息泄露更严重的后果，毕竟VR可以记录整个人的信息而不仅仅是文字信息。 VR的一个很大的问题就是基础硬件设备的体验问题。如果要让医生或者被治疗者长时间呆在虚拟环境中，很容易产生一些生理不适的症状。 虽然说VR在医学上的应用很丰富，尤其是在心理治疗方面颇有成效。但是考虑到治疗的针对性和VR内容制作难度等各种问题，这种辅助治疗方法在现阶段很难进行大规模的应用。 医疗行业需要的是严谨的专业知识和态度，所以对于内容的要求也就相应的提高。如果要开发出一套模拟的人体用来交互培训，需要的是具备医学加上合理内容开发的复合型人才。而且考虑到医学诊断的高精度要求，许多器官或者组织的建模都要非常精细，不能有一丝的马虎，而现在的VR医疗应用更多的还是停留在头戴式VR视频方面。 其他要面临的困难还有：治疗和评估标准没有相关的评估标准、应用系统的交互性和易用性还不够完美。虚拟现实系统设备及其外设性价比例失衡，设备相对比较昂贵,致使大规模应用的时机还不够成熟。 个人感想 虽然最近VR/AR技术越来越火，相关研究也相当多，涉及的行业也是相当全面，但是在现在的情况下，绝大多数成就集中在仿真、游戏上，在医疗领域还是存在很多问题，还有很长的路要走。但希望不要又只能火两年而已。 在医疗工作的各个领域推广VR技术的应用，可以节省大量的时间与资源，从而更快捷、更安全的挽救生命。国际上由于虚拟现实技术的发展而发展起来的医疗电子设备正以每年10%的速度增长。随着计算机、多媒体技术、传感技术、通讯技术的发展以及各国对虚拟现实技术的日益重视，相信这一技术在医学上的应用在将来会取得更大的发展，它的发展前景非常诱人。可以预言，虚拟现实技术在医学中更广泛、更深入的应用将会给传统医疗带来革命性的变化。 在我们国家，新一轮的医疗体制改革如火如荼，传统的医疗体系已经岌岌可危，惟有引入新的信息技术才能适应时代要求。而且，新的医疗体制改革凸现了“社区医疗”的概念。“社区医疗”在全球医疗信息化中对应其第三个阶段，区域医疗信息网络（GMIS），是继医院管理系统（HMIS）、临床医疗信息系统（CIS）之后的阶段。美国所有医疗机构均实现了信息化管理，而中国尚处在初级阶段。将来中国的趋势必然是走向医疗信息化（e-Health）。为了实现这一战略目标，虚拟现实技术就是最佳的操作工具。因此，虚拟现实技术将在中国的“医改”过程中以及今后医疗事业的发展中扮演更加积极、重要的角色。 医疗VR是一个给人无限遐想的领域，它不再只存在于科幻小说爱好者的想象中，而是已经走进了临床研究者和现实生活中的医疗工作者的视野。虽然这是一个全新的领域，还不为大众所知，但是医疗VR技术是对患者的生活和医生的工作都可以产生积极影响的应用。我相信VR必将为医学领域带来一场大变革。 结论 VR/AR作为目前比较新潮的技术，在医学领域作用空前。其在医疗上无论从医生角度、患者角度还是医学教育角度都有着十分巨大的作用。现在相关的科学研究也发展迅速，当然也是存在很多的不足，尤其是我们国家在这方面的研究还很欠缺。在今后的一段时间内，我国的VR开发者还是应该多学习和借鉴国外的先进经验，同时保持在这方面的热情，相信在不久的将来，VR/AR定会在医学领域大大地大放异彩。 参考文献 刘建武, 叶志前, 陆金芳. 虚拟现实在医学中的应用进展[J]. 国际生物医学工程杂志, 2000(6):321-324. 王海舜, 潘利庆. 虚拟现实技术在医学中的应用[J]. 计算机应用, 1998, 22(6):49-54. 刘聚卑, 庄天戈. 虚拟现实在医学上的应用[J]. 北京生物医学工程, 2000, 19(1):47-54. 谭珂, 郭光友, 王勇军,等. 虚拟现实技术在医学手术仿真训练中的应用[J]. 解放军医学院学报, 2002, 23(1):77-79. 范立冬, 李曙光, 张治刚. 虚拟现实技术在医学训练中的应用[J]. 创伤外科杂志, 2008, 10(6):568-570. 谭海珠, 杨棉华, 陈丹芸,等. 虚拟现实技术在医学中的发展与应用[J]. 中华医学教育探索杂志, 2005, 4(6):410-412. 张晗 虚拟现实技术在医学教育中的应用探讨[J]. 西北医学教育, 2010, 18(1):48-51. 孙秀伟, 阎丽, 李彦锋. 虚拟现实技术(VR)在医疗中的应用展望[J]. 临床医学工程, 2007(5):17-20. 吴奇, 程薇曦. 虚拟现实技术在医学手术中的实现与应用[J]. 重庆医学, 2008, 37(21):2489-2491. 李舫, 宋志坚. HMD式光学穿透技术在医学增强现实中的研究进展[J]. 中国数字医学, 2012, 07(1):14-20. 孙国臣, 余新光, 陈晓雷,等. 基于多模态功能神经导航的虚拟现实及增强现实技术在神经外科教学中的应用[J]. 中国医学教育技术, 2015(1):66-69. 李潜. 增强现实技术为医学教育开拓无限未来[J]. 电脑知识与技术, 2012, 08(2):481-482. 张军毅. 医学增强现实建模及可视化研究[D]. 首都医科大学, 2008. 赵娜, 杨谊平. 增强现实技术与手术模拟[J]. 中华医学丛刊, 2004(4):58-59. Wang S, Parsons M, Stonemclean J, et al. Augmented Reality as a Telemedicine Platform for Remote Procedural Training.[J]. Sensors, 2017, 17(10):2294. Noll C, Jan U V, Raap U, et al. Mobile Augmented Reality as a Feature for Self-Oriented, Blended Learning in Medicine: Randomized Controlled Trial[J]. Jmir Mhealth &amp; Uhealth, 2017, 5(9):e139. Mero M, Susin A, Aplicada D M. Deformable 3D Objects for a VR medical application[J]. 2007. Crossan A, Brewster S, Reid S, et al. Multi-session VR Medical Training: The HOPS Simulator[J]. People and Computers XVI - Memorable Yet Invisible, 2002:213–226. Bezerra A. Evaluation of VR medical training applications under the focus of professionals of the health area[C]// ACM Symposium on Applied Computing. ACM, 2009:821-825. JLM Vazquez, BK Wiederhold, I Miller, et al. Virtual Reality Assisted Anesthesia (VRAA) during Upper Gastrointestinal Endoscopy: Report of 115 Cases— Analysis of Physiological Responses, 2017","categories":[{"name":"人机交互","slug":"人机交互","permalink":"http://meng.uno/categories/人机交互/"},{"name":"AR","slug":"人机交互/AR","permalink":"http://meng.uno/categories/人机交互/AR/"},{"name":"VR","slug":"人机交互/AR/VR","permalink":"http://meng.uno/categories/人机交互/AR/VR/"}],"tags":[{"name":"VR","slug":"VR","permalink":"http://meng.uno/tags/VR/"},{"name":"AR","slug":"AR","permalink":"http://meng.uno/tags/AR/"},{"name":"医疗","slug":"医疗","permalink":"http://meng.uno/tags/医疗/"}]},{"title":"中文分词小赛数据","slug":"nlpc","date":"2017-10-30T08:02:41.000Z","updated":"2018-02-17T02:11:10.782Z","comments":true,"path":"posts/649482ba/","link":"","permalink":"http://meng.uno/posts/649482ba/","excerpt":"","text":"纪念一下大四组织的一次中文分词小比赛。 ¶分项数据 训练数据： 链接: https://pan.baidu.com/s/1sl9JLqX 密码: 8am6 测试数据： 链接: https://pan.baidu.com/s/1eSeYhfO 密码: cnw2 相关参考答案： 链接: https://pan.baidu.com/s/1c2tVto0 密码: 3rpt 有切分歧义的100个句子：链接: https://pan.baidu.com/s/1gfJ7Duz 密码: 8mmx ¶所有数据 所有文件下载：链接: https://pan.baidu.com/s/1gfJ7Duz 密码: 8mmx ¶测试结果 相关PPT：http://www.meng.uno/nlpc.pdf","categories":[{"name":"AI","slug":"AI","permalink":"http://meng.uno/categories/AI/"},{"name":"NLP","slug":"AI/NLP","permalink":"http://meng.uno/categories/AI/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"http://meng.uno/tags/NLP/"}]},{"title":"JavaScript操作DOM","slug":"js_dom","date":"2017-03-05T08:03:01.000Z","updated":"2018-02-09T10:46:20.926Z","comments":true,"path":"posts/2c47a986/","link":"","permalink":"http://meng.uno/posts/2c47a986/","excerpt":"","text":"¶创建节点 除了可以使用createElement创建元素，也可以使用createTextNode创建文本节点。document.body指向的是&lt;body&gt;元素，document.documentElement则指向&lt;html&gt;元素。 123456 //创建节点 var createNode = document.createElement(\"div\"); var createTextNode = document.createTextNode(\"hello world\"); createNode.appendChild(createTextNode); document.body.appendChild(createNode); document.documentElement.appendChild(createNode); ¶插入节点 可以使用appendChild，insertBefore，insertBefore接收两个参数，第一个是插入的节点，第二个是参照节点，如insertBefore(a,b)，则a会插入在b的前面 123456 //插入节点 var createNode = document.createElement(\"div\");var createTextNode = document.createTextNode(\"hello world\");createNode.appendChild(createTextNode);var div1 = document.getElementById(\"div1\");document.body.insertBefore(createNode,div1); ¶替换和删除元素 从replaceChild和removeChild的字面意思看，就是删除子节点，因此调用者，需要包含子节点div1，不然调用会报错。返回的节点是替换的或删除的元素，被替换/删除的元素仍然存在，但document中已经没有他们的位置了。 1234 //替换元素 var replaceChild = document.body.replaceChild(createNode,div1);//删除元素 var removeChild = document.body.removeChild(div1); ¶节点的属性 firstChild:第一个子节点 lastChild:最后一个子节点 childNodes:子节点集合，获取其中子节点可 someNode.childNodes[index]或 someNode.childNodes.item(index) nextSibling:下一个兄弟节点 previousSibling：上一个兄弟节点 parentNode：父节点 123456 &lt;ul id=\"ul\"&gt;&lt;li&gt;sdsssssss&lt;/li&gt;&lt;li&gt;qqqq&lt;/li&gt;&lt;li&gt;wwww&lt;/li&gt;&lt;li&gt;eeee&lt;/li&gt;&lt;/ul&gt; 12345678910111213141516 //节点属性 var ul = document.getElementById(\"ul\"); var firstChild = ul.firstChild; console.log(firstChild.innerHTML); var lastChild = ul.lastChild; console.log(lastChild.innerHTML); var length = ul.childNodes.length; console.log(length); var secondChild = ul.childNodes.item(1); console.log(secondChild.innerHTML); var forthChild = ul.childNodes.item(2).nextSibling; console.log(forthChild.innerHTML); var thridChild = forthChild.previousSibling; console.log(thridChild.innerHTML); var parentNode = forthChild.parentNode; console.log(parentNode.innerHTML); ¶文档片段 好处在于减少dom的渲染次数，可以优化性能。 12345678910 //文本片段 var fragment = document.createDocumentFragment(); var ul = document.getElementById(\"ul\"); var li = null; for (var i = 4; i &gt;= 0; i--) &#123; li = document.createElement(\"li\"); li.appendChild(document.createTextNode(\"item \"+i)); fragment.appendChild(li); &#125; ul.appendChild(fragment); ¶克隆元素 someNode.cloneNode(true):深度克隆，会复制节点及整个子节点 someNode.cloneNode(false):浅克隆，会复制节点，但不复制子节点 123 //克隆var clone = ul.cloneNode(true);document.body.appendChild(clone); ¶注意： ¶childNodes.length存在跨浏览器的问题 可以看到有关列表的html片段没有用 123456 &lt;ul id=\"ul\"&gt;&lt;li&gt;sdsssssss&lt;/li&gt;&lt;li&gt;qqqq&lt;/li&gt;&lt;li&gt;wwww&lt;/li&gt;&lt;li&gt;eeee&lt;/li&gt;&lt;/ul&gt; 这种书写格式而是使用没有换行的格式书写，是因为在不同的浏览器中，获取ul.childNodes.length的结果有差异： 在ie中，ul.childNodes.length不会计算li之间的换行空格，从而得到数值为4 在ff、chrome,safari中，会有包含li之间的空白符的5个文本节点，因此ul.childNodes.length为9 若要解决跨浏览器问题，可以将li之间的换行去掉，改成一行书写格式。 ¶cloneNode存在跨浏览器的问题 在IE中，通过cloneNode方法复制的元素，会复制事件处理程序，比如，var b = a.cloneNode(true).若a存在click,mouseover等事件监听，则b也会拥有这些事件监听。 在ff,chrome,safari中，通过cloneNode方法复制的元素，只会复制特性，其他一切都不会复制 因此，若要解决跨浏览器问题，在复制前，最好先移除事件处理程序。","categories":[{"name":"前端","slug":"前端","permalink":"http://meng.uno/categories/前端/"}],"tags":[{"name":"前端","slug":"前端","permalink":"http://meng.uno/tags/前端/"}]},{"title":"HIT操作系统实验总结","slug":"oslab","date":"2017-01-04T12:50:26.000Z","updated":"2018-02-09T10:46:20.931Z","comments":true,"path":"posts/86743755/","link":"","permalink":"http://meng.uno/posts/86743755/","excerpt":"","text":"哈工大《操作系统》六次实验每次需要修改的文件见：修改文件列表 本实验总结源自github项目： MIC ¶操作系统引导 ¶bootsect.s 实现屏幕输出 修改打印的字符串（空白也算作一个字符） 读入setup.s代码（包括：设置驱动器、磁头，读取setup.s的磁道和扇区，并跳到相应位置开始执行） ¶setup.s （和bootsect.s中部分代码相同）打印相关信息 （原代码已经可以部分打印硬件信息）需要在相关位置嵌入msg实现打印提示信息功能 ¶build.c 将bootsect.s、setup.s、system.s编译、链接生成Image文件 ¶系统调用 unistd.h文件：添加系统调用功能号 sys.h声明新的系统调用处理函数；添加系统调用处理程序索引值到指针数组表中 system_call.s中增加系统调用总数 makefile添加新的系统调用所在文件的编译链接规则（依赖关系） ¶进程运行轨迹的跟踪与统计 ¶process.c 涉及到fork()和wait()系统调用 主要实现了一个函数——cpuio_bound() 用fork()建立若干个同时运行的子程序 父P等待所有子P退出后才退出，每个子P性质通过cpuio_bound()控制性质 ¶fork.c fork系统调用函数 ¶main.c 内核的入口函数main()，对它的修改是增加日志创建语句，并将log文件关联到文件描述符log文件记录进程状态转换轨迹 ¶kernel 主要寻找进程状态转换点： printk.c sched.c exit.c ¶信号量的实现和应用 ¶sem_open 打开信号量 ¶sem_wait 信号量P操作——value– ¶sem_post 信号量V操作——value++ ¶sem_unlink 释放信号量 ¶地址映射与共享 ¶shm.c shmget()：得到一个共享内存标识符或创建一个共享内存对象并返回共享内存标识符 shmat()：连接共享内存标识符为shmid的共享内存，连接成功后把共享内存区对象映射到调用进程的地址空间，随后可像本地空间一样访问 ¶sem.c 实现信号量的四种操作，与实验四相同 ¶字符显示的控制 ¶keyboard.S 添加对字符F12的输入判断 ¶console.c 添加输出到控制台的字符控制 ¶file_dev.c 添加输出到文件的字符控制","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://meng.uno/categories/操作系统/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://meng.uno/tags/操作系统/"}]},{"title":"手写数字识别（SVM）","slug":"svm_number_recog","date":"2016-12-17T04:08:13.000Z","updated":"2018-02-17T02:12:08.406Z","comments":true,"path":"posts/7dac38a/","link":"","permalink":"http://meng.uno/posts/7dac38a/","excerpt":"","text":"¶调用第三方库 在此我选用的是sk-learn的关于svm的库，其关于此次实验的svm函数定义为： svm.SVC(C=8.0, kernel=‘rbf’, gamma=0.1) svm.SVC()函数的几个重要参数在其官方的介绍文档中有如下的解释： C :误差项的惩罚参数，浮点型，可选 (默认=1.0)； kernel : 指定核函数类型，字符型，可选 (默认=‘rbf’)，如果使用自定义的核函数，需要预先计算核矩阵； gamma : 浮点型, 可选 (默认=0.0)，’rbf’核函数的系数，需要注意的是，此处的gamma与课本中的sigma是互为倒数的关系（所以其可以为0）。 因为是调用别人的库（应该说完全是别人的功劳），所以在实现上没有什么可以说的。 ¶代码 123456789101112131415161718192021222324252627282930313233 #!/usr/bin/env python3# -*- coding: utf-8 -*-\"\"\"Created on Thu Dec 1 13:30:21 2016@author: kuangmeng使用SVM分类器，从MNIST数据集中进行手写数字识别的分类程序\"\"\"import cPickleimport gzipfrom sklearn import svmimport timedef load_data(): \"\"\" 返回包含训练数据、验证数据、测试数据的元组的模式识别数据 \"\"\" f = gzip.open('data.gz', 'rb') training_data, validation_data, test_data = cPickle.load(f) f.close() return (training_data, validation_data, test_data)def Svm(): print (\"开始时间：\",time.strftime('%Y-%m-%d %H:%M:%S')) training_data, validation_data, test_data = load_data() # 传递训练模型的参数，这里用默认的参数 clf = svm.SVC(C=10.0, kernel='rbf', gamma=0.10,cache_size=8000,probability=False) # 进行模型训练 clf.fit(training_data[0], training_data[1]) # 测试集测试预测结果 predictions = [int(a) for a in clf.predict(test_data[0])] num_correct = sum(int(a == y) for a, y in zip(predictions, test_data[1])) print (\"%s 中的 %s 测试正确。\" % (num_correct, len(test_data[1]))) print (\"结束时间：\",time.strftime('%Y-%m-%d %H:%M:%S'))if __name__ == \"__main__\": Svm() ¶自己编程实现 在自己编程实现过程中，我也借鉴了很多其他人写的很成熟的方案，最终从数据结构、逻辑结构以及特征计算等方面得到比较合理的一组答案。 ¶逻辑结构 本次实验的程序分为“训练”和“测试”两部分，两部分分别进行的工作如下： ¶训练 加载数据 初始化模型 更新标签 初始化预测误差 迭代每个样本（用KT优化） 得到每个样本的模型 对步骤5的解释： 对于svm我们要求解a（数组），如果 a的所有分量满足svm对偶问题的KKT条件，那么这个问题的解就求出来了，我们svm模型学习也就完成了。如果没有满足KKT，那么我们就在 a中找两个分量 ai和 aj，其中 ai 是违反KKT条件最严重的分量，通过计算，使得 ai 和 aj满足KKT条件，直到a的所有分量都满足KKT条件。而且这个计算过程是收敛的，因为每次计算出来的新的两个分量，使得对偶问题中要优化的目标函数值更小。因为每次求解的那两个分量，是要优化问题在这两个分量上的极小值，所以每一次优化，都会使目标函数比上一次的优化结果的值变小。 ¶测试 加载数据 对每个数据预测 计算正确率与相关信息逻辑结构 特征计算 仿照KKT的优化方法，在本次试验中，我将每张图片作为一个数据。由此得到对每一个测试样本的预测（如果在某个分类的计算时结果为正，则说明该测试样本属于该类别，结果为0则不属于此类别）。 ¶其他杂项 核函数选择：按照传统，选择的是RBF核函数，函数形式与教材完全相同； 数据来源：来源自网友整理之后的数据（测试数据与训练数据没有均分）； SMO优化算法： 取初始值a(0)=0，令K=0； 选取优化变量a1(k) , a2(k) , 针对优化问题，求得最优解 a1(k+1) , a2(k+1) 更新 a(k) 为 a(k+1) ； 在精度条件范围内是否满足停机条件，即是否有变量违反KKT条件，如果违反了，则令k=k+1，跳转2，否则4； 求得近似解â =a(k+1) 其中第3步中，是否违反KKT条件，对于a(k)的每个分量按照以下的违反KKT条件的公式进行验算即可。 变量选取分为两步，第一步是选取违反KKT条件最严重的ai，第二步是根据已经选取的第一个变量，选择优化程度最大的第二个变量。 违反KKT条件最严重的变量可以按照这样的规则选取，首先看0&lt;ai&lt;C的那些分量中，是否有违反KKT条件的，如果有，则选取yig(xi)最小的那个做为a1。如果没有则遍历所有的样本点，在违反KKT条件的分量中选取yig(xi)最小的做为a1。 当选择了a1后，如果a1对应的E1为正，选择Ei最小的那个分量最为a2，如果E1为负，选择Ei最大的那个分量最为a2，这是因为anew2依赖于|E1−E2|。 如果选择的a2，不能满足下降的最小步长，那么就遍历所有的支持向量点做为a2进行试用，如果仍然都不能满足下降的最小步长，那么就遍历所有的样本点做为a2试用。如果还算是不能满足下降的最小步长，那么就重新选择a1。 ¶代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237 #!/usr/bin/env python3# -*- coding: utf-8 -*-\"\"\"Created on Sun Dec 4 14:24:53 2016@author: kuangmeng\"\"\"import timeimport osimport mathclass model: def __init__(self): self.a = [] self.b = 0.0 class DATA: def __init__(self): self.samples = [] # 样本数据 self.tests = [] # 测试数据 self.models = [] # 训练的模型 self.forecasterror = [] # 预测知与真实y之差Ei self.modelnum = 0 # 当前正使用或训练的模型 self.cache= [] # 缓存kernel函数的计算结果 self.sigma = 10 # sigma def init_models(self): for i in range(0, 10): m = model() for j in range(len(self.samples)): m.a.append(0) self.models.append(m) def init_cache(self): i = 0 for x in self.samples: print (\"正在计算第\",i+1,\"个样本的RBF核\") self.cache.append([]) j = 0 for z in self.samples: if i &gt; j: self.cache[i].append(self.cache[j][i]) else: self.cache[i].append(RBF(x,z)) j += 1 i += 1 class image: def __init__(self): self.data = [] self.num = 0 self.label = [] self.filename = \"\"gv = DATA()# RBF核函数def RBF(j, i): if j == i: return math.exp(0) sigma = gv.sigma ret = 0.0 for m in range(len(j.data)): for n in range(len(j.data[m])): ret += math.pow(int(j.data[m][n]) - int(i.data[m][n]), 2) ret = math.exp(-ret/sigma) return ret#加载测试与训练数据def loaddata(dirpath, name): files = os.listdir(dirpath) for file in files: img = image() img.data = images(dirpath + file) img.num = int(file[0]) img.filename = file name.append(img)#图片分列 def images(path): img = [] file = open(path, \"r\") for line in file: line = line[:-2] img.append(line) return img #更新样本标签，正在训练啥就将啥的标签定为1，其他的定为-1 def update_samples_label(num): for img in gv.samples: if img.num == num: img.label.append(1) else: img.label.append(-1) #初始化DATA.forecasterrordef init_forecasterror(): gv.forecasterror = [] for i in range(len(gv.samples)): diff = 0.0 for j in range(len(gv.samples)): if gv.models[gv.modelnum].a[j] != 0: diff += gv.models[gv.modelnum].a[j] * gv.samples[j].label[gv.modelnum] * gv.cache[j][i] diff += gv.models[gv.modelnum].b diff -= gv.samples[i].label[gv.modelnum] gv.forecasterror.append(diff)#更新DATA.forecasterror def update_forecasterror(i, new_ai, j, new_bj, new_b): for idx in range(len(gv.samples)): diff = (new_ai - gv.models[gv.modelnum].a[i])* gv.samples[i].label[gv.modelnum] * gv.cache[i][idx] diff += (new_bj - gv.models[gv.modelnum].a[j])* gv.samples[j].label[gv.modelnum] * gv.cache[j][idx] diff += new_b - gv.models[gv.modelnum].b diff += gv.forecasterror[idx] gv.forecasterror[idx] = diff# g(x)def predict(m): pred = 0.0 for j in range(len(gv.samples)): if gv.models[gv.modelnum].a[j] != 0: pred += gv.models[gv.modelnum].a[j] * gv.samples[j].label[gv.modelnum] * RBF(gv.samples[j],m) pred += gv.models[gv.modelnum].b return preddef save_models(): for i in range(10): fn = open(\"models/\" + str(i) + \"_a.model\", \"w\") for ai in gv.models[i].a: fn.write(str(ai)) fn.write('\\n') fn.close() fn = open(\"models/\" + str(i) + \"_b.model\", \"w\") fn.write(str(gv.models[i].b)) fn.close()def load_models(): for i in range(10): fn = open(\"models/\" + str(i) + \"_a.model\", \"r\") j = 0 for line in fn: gv.models[i].a[j] = float(line) j += 1 fn.close() fn = open(\"models/\" + str(i) + \"_b.model\", \"r\") gv.models[i].b = float(fn.readline()) fn.close()#### T: tolerance 误差容忍度(精度)# times: 迭代次数# 优化方法：SMO# C: 惩罚系数# modelnum: 模型序号0到9# step: aj移动的最小步长###def train(T, times, C, modelnum, step): time = 0 gv.modelnum = modelnum update_samples_label(modelnum) init_forecasterror() updated = True while time &lt; times and updated: updated = False time += 1 for i in range(len(gv.samples)): ai = gv.models[gv.modelnum].a[i] Ei = gv.forecasterror[i] #计算违背KKT的点 if (gv.samples[i].label[gv.modelnum] * Ei &lt; -T and ai &lt; C) or (gv.samples[i].label[gv.modelnum] * Ei &gt; T and ai &gt; 0): for j in range(len(gv.samples)): if j == i: continue kii = gv.cache[i][i] kjj = gv.cache[j][j] kji = kij = gv.cache[i][j] eta = kii + kjj - 2 * kij if eta &lt;= 0: continue new_aj = gv.models[gv.modelnum].a[j] + gv.samples[j].label[gv.modelnum] * (gv.forecasterror[i] - gv.forecasterror[j]) / eta # f 7.106 L = 0.0 H = 0.0 a1_old = gv.models[gv.modelnum].a[i] a2_old = gv.models[gv.modelnum].a[j] if gv.samples[i].label[gv.modelnum] == gv.samples[j].label[gv.modelnum]: L = max(0, a2_old + a1_old - C) H = min(C, a2_old + a1_old) else: L = max(0, a2_old - a1_old) H = min(C, C + a2_old - a1_old) if new_aj &gt; H: new_aj = H if new_aj &lt; L: new_aj = L if abs(a2_old - new_aj) &lt; step: # print (\"j = %d, is not moving enough\" % j) continue new_ai = a1_old + gv.samples[i].label[gv.modelnum] * gv.samples[j].label[gv.modelnum] * (a2_old - new_aj) # f 7.109 new_b1 = gv.models[gv.modelnum].b - gv.forecasterror[i] - gv.samples[i].label[gv.modelnum] * kii * (new_ai - a1_old) - gv.samples[j].label[gv.modelnum] * kji * (new_aj - a2_old) # f7.115 new_b2 = gv.models[gv.modelnum].b - gv.forecasterror[j] - gv.samples[i].label[gv.modelnum]*kji*(new_ai - a1_old) - gv.samples[j].label[gv.modelnum]*kjj*(new_aj-a2_old) # f7.116 if new_ai &gt; 0 and new_ai &lt; C: new_b = new_b1 elif new_aj &gt; 0 and new_aj &lt; C: new_b = new_b2 else: new_b = (new_b1 + new_b2) / 2.0 update_forecasterror(i, new_ai, j, new_aj, new_b) gv.models[gv.modelnum].a[i] = new_ai gv.models[gv.modelnum].a[j] = new_aj gv.models[gv.modelnum].b = new_b updated = True print (\"迭代次数: %d, 修改组合: i: %d 与 j:%d\" %(time, i, j)) break# 测试数据def test(): record = 0 record_correct = 0 for img in gv.tests: print (\"正在测试：\", img.filename) for modelnum in range(10): gv.modelnum = modelnum if predict(img) &gt; 0: print (\"测试结果：\",modelnum) record += 1 if modelnum == int(img.filename[0]): record_correct += 1 break print (\"相关记录数量:\", record) print (\"正确识别数量:\", record_correct) print (\"正确识别比例:\", record_correct/record) print (\"测试数据总量:\", len(gv.tests))if __name__ == \"__main__\": print (\"开始时间：\",time.strftime('%Y-%m-%d %H:%M:%S')) training = True loaddata(\"train/\", gv.samples) loaddata(\"test/\", gv.tests) print (\"训练数据个数：\",len(gv.samples)) print (\"测试数据个数：\",len(gv.tests)) if training == True: gv.init_cache() gv.init_models() print (\"模型初始化成功！\") print (\"当前时间：\",time.strftime('%Y-%m-%d %H:%M:%S')) T = 0.0001 C = 10 step = 0.001 gv.sigma = 1 if training == True: for i in range(10): print (\"正在训练模型:\", i) train(T, 10, C, i, step) save_models() else: load_models() for i in range(10): update_samples_label(i) print (\"训练完成时间：\",time.strftime('%Y-%m-%d %H:%M:%S')) test() print (\"测试完成时间：\",time.strftime('%Y-%m-%d %H:%M:%S'))","categories":[{"name":"AI","slug":"AI","permalink":"http://meng.uno/categories/AI/"},{"name":"模式识别","slug":"AI/模式识别","permalink":"http://meng.uno/categories/AI/模式识别/"}],"tags":[{"name":"模式识别","slug":"模式识别","permalink":"http://meng.uno/tags/模式识别/"}]},{"title":"多项式拟合曲线——最小二乘法","slug":"least_square_method","date":"2016-12-17T03:59:39.000Z","updated":"2018-02-17T02:10:59.079Z","comments":true,"path":"posts/1af17fd9/","link":"","permalink":"http://meng.uno/posts/1af17fd9/","excerpt":"","text":"直接上代码，最小二乘法比较简单，在拟合效果上也相当不错： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364 # -*- coding: utf-8 -*-import matplotlib.pyplot as pltimport numpyimport randomf = plt.figure()draw = f.add_subplot(111)#拟合函数的次数限制times=9tail=times+1x = numpy.arange(-2,2,0.1)y = [((xi-1)*(xi*xi-1)+0.5)*numpy.cos(xi) for xi in x]#所有使用到的全局变量声明i=0xlabel=[]ylabel=[]A=[]B=[]tempA=[]tempB=[]X=[]Y=[]#-----------------------------#生成数据，加入cos函数，作为噪声！for xi in x: r=float(random.randint(80,100))/100 xlabel.append(xi*r) ylabel.append(y[i]*r) i+=1draw.plot(xlabel,ylabel,color='b',linestyle='',marker='*')length=len(xlabel)for i in range(0,tail): tempA=[] for j in range(0,tail): temp=0.0 for k in range(0,length): d=1.0 for m in range(0,j+i): d=d*xlabel[k] temp+=d tempA.append(temp) A.append(tempA)for i in range(0,tail): temp=0.0 for k in range(0,length): d=1.0 for j in range(0,i): d=d*xlabel[k] temp+=ylabel[k]*d B.append(temp) #X为可行解X=numpy.linalg.solve(A,B)print('可行解a(x的系数)的矩阵表示为：[a0,---,a%d]'%(times))print(X)for i in range(0,length): temp=0.0 for j in range(0,tail): d=1.0 for k in range(0,j): d*=x[i] d*=X[j] temp+=d Y.append(temp)draw.plot(x,Y,color='r',linestyle='-',marker='.')","categories":[{"name":"AI","slug":"AI","permalink":"http://meng.uno/categories/AI/"},{"name":"机器学习","slug":"AI/机器学习","permalink":"http://meng.uno/categories/AI/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://meng.uno/tags/机器学习/"}]},{"title":"主成分分析（PCA）","slug":"pca","date":"2016-12-17T03:52:21.000Z","updated":"2018-02-17T02:11:23.106Z","comments":true,"path":"posts/6c0d033f/","link":"","permalink":"http://meng.uno/posts/6c0d033f/","excerpt":"","text":"¶实验要求 ¶实验目标 实现一个PCA模型，能够对给定数据进行降维（即找到其中的主成分） ¶实验过程 首先人工生成一些数据（如三维数据），让它们主要分布在低维空间中，如首先让某个维度的方差远小于其它维度，然后对这些数据旋转。生成这些数据后，用你的PCA方法进行主成分提取。 找一个人脸数据（小点样本量），用你实现PCA方法对该数据降维，找出一些主成分，然后用这些主成分对每一副人脸图像进行重建，比较一些它们与原图像有多大差别（用信噪比衡量）。 ¶实验准备 ¶降维的必要 多重共线性–预测变量之间相互关联。多重共线性会导致解空间的不稳定，从而可能导致结果的不连贯。 高维空间本身具有稀疏性。一维正态分布有68%的值落于正负标准差之间，而在十维空间上只有0.02%。 过多的变量会妨碍查找规律的建立。 仅在变量层面上分析可能会忽略变量之间的潜在联系。例如几个预测变量可能落入仅反映数据某一方面特征的一个组内。 ¶降维的目的 减少预测变量的个数 确保这些变量是相互独立的 提供一个框架来解释结果 降维的方法 主成分分析 因子分析 用户自定义复合 ¶有关PCA ¶PCA概念 主成分分析 （ Principal Component Analysis ， PCA ）或者主元分析。是一种掌握事物主要矛盾的统计分析方法，它可以从多元事物中解析出主要影响因素，揭示事物的本质，简化复杂的问题。计算主成分的目的是将高维数据投影到较低维空间。给定 n 个变量的 m 个观察值，形成一个 n * m 的数据矩阵， n 通常比较大。对于一个由多个变量描述的复杂事物，人们难以认识，那么是否可以抓住事物主要方面进行重点分析呢？如果事物的主要方面刚好体现在几个主要变量上，我们只需要将这几个变量分离出来，进行详细分析。但是，在一般情况下，并不能直接找出这样的关键变量。这时我们可以用原有变量的线性组合来表示事物的主要方面， PCA 就是这样一种分析方法。 ¶PCA作用范围 PCA 主要用于数据降维，对于一系列例子的特征组成的多维向量，多维向量里的某些元素本身没有区分性，比如某个元素在所有的例子中都为1，或者与1差距不大，那么这个元素本身就没有区分性，用它做特征来区分，贡献会非常小。所以我们的目的是找那些变化大的元素，即方差大的那些维，而去除掉那些变化不大的维，从而使特征留下的都是“精品”，而且计算量也变小了。 对于一个K维的特征来说，相当于它的每一维特征与其他维都是正交的（相当于在多维坐标系中，坐标轴都是垂直的），那么我们可以变化这些维的坐标系，从而使这个特征在某些维上方差大，而在某些维上方差很小。 ¶PCA的算法步骤 设有m条n维数据。 将原始数据按列组成n行m列矩阵X 将X的每一行（代表一个属性字段）进行零均值化，即减去这一行的均值 求出协方差矩阵C=1/mXX’ 求出协方差矩阵的特征值及对应的特征向量 将特征向量按对应特征值大小从上到下按行排列成矩阵，取前k行组成矩阵P Y=PX即为降维到k维后的数据 ¶实验环境 Spyder 作为Python开发的集成开发环境； 编程语言：Python 3.5 操作系统：macOS Sierra ¶小结 ¶PCA的应用分析 对于一个训练集，100个对象模板，特征是10维，那么它可以建立一个100*10的矩阵，作为样本。求这个样本的协方差矩阵，得到一个10*10的协方差矩阵，然后求出这个协方差矩阵的特征值和特征向量，应该有10个特征值和特征向量，我们根据特征值的大小，取前四个特征值所对应的特征向量，构成一个10*4的矩阵，这个矩阵就是我们要求的特征矩阵，100*10的样本矩阵乘以这个10*4的特征矩阵，就得到了一个100*4的新的降维之后的样本矩阵，每个特征的维数下降了。当给定一个测试的特征集之后，比如1*10维的特征，乘以上面得到的10*4的特征矩阵，便可以得到一个1*4的特征，用这个特征去分类。所以做PCA实际上是求得这个投影矩阵，用高维的特征乘以这个投影矩阵，便可以将高维特征的维数下降到指定的维数。 在进行基因表达数据分析时，一个重要问题是确定每个实验数据是否是独立的，如果每次实验数据之间不是独立的，则会影响基因表达数据分析结果的准确性。对于利用基因芯片所检测到的基因表达数据，如果用 PCA 方法进行分析，可以将各个基因作为变量，也可以将实验条件作为变量。当将基因作为变量时，通过分析确定一组“主要基因元素”，它们能够很好地说明基因的特征，解释实验现象；当将实验条件作为变量时，通过分析确定一组“主要实验因素”，它们能够很好地刻画实验条件的特征，解释基因的行为。 PCA作为基础的数学分析方法，其实际应用十分广泛，比如人口统计学、数量地理学、分子动力学模拟、数学建模、数理分析等学科中均有应用，是一种常用的多变量分析方法。 ¶PCA优缺点 ¶优点： 以方差衡量信息的无监督学习，不受样本标签限制； 各主成分之间正交，可消除原始数据成分间的相互影响； 可减少指标选择的工作量； 用少数指标代替多数指标，利用PCA降维是最常用的算法； 计算方法简单，易于实现。 ¶缺点： 主成分解释其含义往往具有一定的模糊性，不如原始样本完整； 贡献率小的主成分往往可能含有对样本差异的重要信息； 特征值矩阵的正交向量空间是否唯一有待讨论； 属于无监督学习。 ¶代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465 #!/usr/bin/env python3# -*- coding: utf-8 -*-\"\"\"Created on Tue Nov 29 15:51:25 2016@author: kuangmeng\"\"\"import numpy as npimport matplotlib.pyplot as plt#全局变量定义区XLabel = list()YLabel = list()phi = [0., 0.]#自己定义的矩阵转换函数def Transport(matrix): temp = list() for i in range(len(matrix[0])): temp.append(list()) for j in range(len(matrix)): temp[i].append(matrix[j][i]) return temp#加载文件（可以通过更改文件名来加载不同的测试数据）data_set = open('testSet.txt', 'r')for line in data_set.readlines(): data_line = line.strip().split() tmpx = float(data_line[0]) tmpy = float(data_line[1]) phi[0] += tmpx phi[1] += tmpy XLabel.append(tmpx) YLabel.append(tmpy)phi[0] = phi[0]/100.0phi[1] = phi[1]/100.0data_set.close()#加载结束temp_x = list()for i in range(100): temp_x.append([XLabel[i]-phi[0], YLabel[i]-phi[1]])temp_x_ = Transport(temp_x)sigma = np.dot(temp_x_, temp_x)D,V= np.linalg.eig(sigma)for i in range(2): for j in range(2): V.real[i][j] *= -1temp_v_ = Transport(V.real)tr1 = list()tr1.append(XLabel)tr1.append(YLabel)tr1 = Transport(tr1)xr1 = np.dot(tr1, temp_v_[0])xr2 = np.dot(phi, temp_v_[1])xr = tr1# print xrfor i in range(len(XLabel)): xr[i][0] = np.dot(xr1[i], V.real[0][0])+np.dot(xr2, V.real[0][1]) xr[i][1] = np.dot(xr1[i], V.real[1][0])+np.dot(xr2, V.real[1][1])# print xrplt.plot(XLabel, YLabel, 'r+')temp_xr = Transport(xr)plt.plot(temp_xr[0], temp_xr[1], 'b*')for i in range(len(XLabel)): plt.plot([XLabel[i],xr[i][0]], [YLabel[i],xr[i][1]])plt.axis([-8,6,-5,5])plt.xlabel = 'x'plt.ylabel = 'y'plt.show()","categories":[{"name":"AI","slug":"AI","permalink":"http://meng.uno/categories/AI/"},{"name":"机器学习","slug":"AI/机器学习","permalink":"http://meng.uno/categories/AI/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://meng.uno/tags/机器学习/"}]},{"title":"使用EM算法优化的GMM","slug":"gmm","date":"2016-12-17T03:16:53.000Z","updated":"2018-02-17T02:10:30.701Z","comments":true,"path":"posts/177fbbcc/","link":"","permalink":"http://meng.uno/posts/177fbbcc/","excerpt":"","text":"先上代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113 # -*- coding: utf-8 -*-import numpy as npimport matplotlib.pyplot as matimport matplotlib.mlab as mlab#EM算法def EM(dataSet,K): (N, M) = np.shape(dataSet) W = np.zeros([N, K]) P= N/K for k in range(K): W[np.floor(k*P):np.floor((k+1)*P), k] = 1 A,M,S = Mstep(dataSet,W) return W, A, M, S#M的跨度def Mstep(data,W): (N, M) = np.shape(data) K = np.size(W,1) Nk = np.sum(W,0) A = Nk/np.sum(Nk) Mm = data.T.dot(W).dot(np.diag(np.reciprocal(Nk))) S = np.zeros([M,M,K]) for k in range(K): datMean = data.T - Mm[0:,k][None].T.dot(np.ones([1,N])) S[:,:,k] = (datMean.dot(np.diag(W[0:,k])).dot(datMean.T))/Nk[k] return A,Mm,S#E的跨度def Estep(data,A,M,S): N = np.size(data,0) K = np.size(A) W = np.zeros([N,K]) for k in range(K): for i in range(N): W[i,k] = A[k]*multivariate(data[i,:][None].T, \\ M[:,k][None].T,S[:,:,k]) W = W*np.reciprocal(np.sum(W,1)[None].T) return Wdef multivariate(x, m, s): if len(x) == len(m) and (len(x), len(x)) == s.shape: det = np.linalg.det(s) const = 1.0/(np.math.pow((2*np.pi), float(len(x))/2) * np.math.pow(det, 1.0/2)) x_m = np.matrix(x - m) inv_ = np.linalg.inv(s) result = np.math.pow(np.math.e, -0.5 * (x_m.T * inv_ * x_m)) return const * result else: return -1#GMM主程序def GMM(): # 加载文件 input_file = open('points.dat') lines = input_file.readlines() Data = np.array([line.strip().split() for line in lines]).astype(np.float) (x, y) = np.shape(Data) mat.draw() mat.pause(0.01) mat.subplot(111) mat.plot(x, y, 'b*') learn = Data[np.math.ceil(x*0.8):x, 0:] train = Data[:np.math.floor(x*0.8), 0:] trainnum = 16 (W, Alpha, Mu, Sigma) = EM(train,trainnum) m = np.arange(-4.0, 4.0, 0.1) n = np.arange(-4.0, 4.0, 0.1) ax, ay = np.meshgrid(m, n) i = 0 prev = -9999 mat.clf() while(True): if(False): SigmaSum = np.sum(Sigma,2) for k in range(trainnum): Sigma[:,:,k] = SigmaSum W = Estep(train,Alpha,Mu,Sigma) Alpha,Mu,Sigma = Mstep(train,W) # trains = logLike(train,Alpha,Mu,Sigma) N,M = np.shape(train) P = np.zeros([N,len(Alpha)]) for k in range(len(Alpha)): for j in range(N): P[j,k] = multivariate(train[j,:][None].T,Mu[0:,k][None].T,Sigma[:,:,k]) trains = np.sum(np.log(P.dot(Alpha))) i = i + 1 #画图，训练和测试样本 mat.subplot(211) mat.scatter(train[0:,0],train[0:,1]) mat.hold(True) for k in range(0, trainnum): az = mlab.bivariate_normal(ax, ay, Sigma[0, 0, k], Sigma[1, \\ 1, k], Mu[0,k], Mu[1,k], Sigma[1, 0, k]) try: mat.contour(ax, ay, az) except: continue mat.hold(False) # Render these mat.draw() mat.pause(0.01) mat.subplot(212) mat.scatter(learn[0:,0],learn[0:,1]) mat.hold(True) for k in range(0, trainnum): az = mlab.bivariate_normal(ax, ay, Sigma[0, 0, k], Sigma[1, \\ 1, k], Mu[0,k], Mu[1,k], Sigma[1, 0, k]) try: mat.contour(ax, ay, az) except: continue mat.hold(False) if(i&gt;150 or abs(trains - prev)&lt; 0.01): break prev = trainsif __name__ == '__main__': GMM() ¶实验要求 ¶实验目标 实现一个混合高斯模型，并且用EM算法估计模型中的参数。 ¶实验过程 用混合高斯模型产生k个高斯分布的数据（其中参数自己设定），然后用你实现的EM算法估计参数，看看每次迭代后似然值变化情况，考察EM算法是否可以获得正确的结果（与你设定的结果比较）。 可以UCI上找一个简单问题数据，用你实现的GMM进行聚类。 ¶算法原理 ¶GMM算法 高斯模型就是用高斯概率密度函数（正态分布曲线）精确地量化事物，将一个事物分解为若干的基于高斯概率密度函数（正态分布曲线）形成的模型。 对图像背景建立高斯模型的原理及过程：图像灰度直方图反映的是图像中某个灰度值出现的频次，也可以认为是图像灰度概率密度的估计。如果图像所包含的目标区域和背景区域相比比较大，且背景区域和目标区域在灰度上有一定的差异，那么该图像的灰度直方图呈现双峰-谷形状，其中一个峰对应于目标，另一个峰对应于背景的中心灰度。对于复杂的图像，尤其是医学图像，一般是多峰的。通过将直方图的多峰特性看作是多个高斯分布的叠加，可以解决图像的分割问题。 在智能监控系统中，对于运动目标的检测是中心内容，而在运动目标检测提取中，背景目标对于目标的识别和跟踪至关重要。而建模正是背景目标提取的一个重要环节。 我们首先要提起背景和前景的概念，前景是指在假设背景为静止的情况下，任何有意义的运动物体即为前景。建模的基本思想是从当前帧中提取前景，其目的是使背景更接近当前视频帧的背景。即利用当前帧和视频序列中的当前背景帧进行加权平均来更新背景,但是由于光照突变以及其他外界环境的影响，一般的建模后的背景并非十分干净清晰，而高斯混合模型是是建模最为成功的方法之一。 混合高斯模型使用K（基本为3到5个）个高斯模型来表征图像中各个像素点的特征,在新一帧图像获得后更新混合高斯模型, 用当前图像中的每个像素点与混合高斯模型匹配,如果成功则判定该点为背景点, 否则为前景点。 通观整个高斯模型，主要是有方差和均值两个参数决定，对均值和方差的学习，采取不同的学习机制,将直接影响到模型的稳定性、精确性和收敛性 。由于我们是对运动目标的背景提取建模，因此需要对高斯模型中方差和均值两个参数实时更新。为提高模型的学习能力,改进方法对均值和方差的更新采用不同的学习率;为提高在繁忙的场景下,大而慢的运动目标的检测效果,引入权值均值的概念,建立背景图像并实时更新,然后结合权值、权值均值和背景图像对像素点进行前景和背景的分类。 具体实现过程： 为图像的每个像素点指定一个初始的均值、标准差以及权重。 收集N（一般取200以上，否则很难得到像样的结果）帧图像利用在线EM算法得到每个像 素点的均值、标准差以及权重。 从N+1帧开始检测，检测的方法： 对每个像素点： 将所有的高斯核按照 ω / σ 降序排序 选择满足下式的前M个高斯核：M = arg min(ω / σ &gt; T) 如果当前像素点的像素值在中有一个满足：就可以认为其为背景点。 更新背景图像，用EM算法。 ¶EM算法 EM 算法是 Dempster，Laind，Rubin 于 1977 年提出的求参数极大似然估计的一种方法，它可以从非完整数据集中对参数进行 MLE 估计，是一种非常简单实用的学习算法。这种方法可以广泛地应用于处理缺损数据，截尾数据，带有噪声等所谓的不完全数据(incomplete data)。 最大期望算法经过两个步骤交替进行计算： 第一步是计算期望（E），利用对隐藏变量的现有估计值，计算其最大似然估计值； 第二步是最大化（M），最大化在 E 步上求得的最大似然值来计算参数的值。 M 步上找到的参数估计值被用于下一个 E 步计算中，这个过程不断交替进行。 通过交替使用这两个步骤，EM算法逐步改进模型的参数，使参数和训练样本的似然概率逐渐增大，最后终止于一个极大点。直观地理解EM算法，它也可被看作为一个逐次逼近算法：事先并不知道模型的参数，可以随机的选择一套参数或者事先粗略地给定某个初始参数λ0 ，确定出对应于这组参数的最可能的状态，计算每个训练样本的可能结果的概率，在当前的状态下再由样本对参数修正，重新估计参数λ，并在新的参数下重新确定模型的状态，这样，通过多次的迭代，循环直至某个收敛条件满足为止，就可以使得模型的参数逐渐逼近真实参数。 具体实现步骤： 给出种类数k,初始化每一类高斯分布的均值μk，方差∑k以及每一类的概率πk； 执行EM； 计算似然，如果没有达到预期效果，则返回第2步； 计算每个数据点对于k个高斯分布的似然，选择似然最大的一类作为数据的最终分类。 其他的混合模型，例如朴素贝叶斯混合模型也是可以使用EM算法推出使用的，这一算法虽然在GMM中作为参数使用，但是其仍然可以单独发挥作用。我觉得EM算法就是相互迭代（毕竟其由E和M两部分组成嘛），求出一个稳定值，而这种相互迭代的方法用的范围挺广的，例如混合模型，K-means等都需要使用。 ¶与K-means的区别 在上文我也已经提到了EM算法可以用在K-means等其他需要迭代的方法上的事实，其实，我觉得GMM 和 K-means 很像，只不过后者要简单，而且相对来说实现并不是很高效。不过 GMM 是学习出一些概率密度函数来（所以 GMM 除了用在 clustering 上之外，还经常被用于 density estimation ），简单地说，K-means 的结果是每个数据点被 assign 到其中某一个 cluster 了，而 GMM 则给出这些数据点被 assign 到每个 cluster 的概率，又称作 soft assignment。 ¶实验环境 Spyder 作为Python开发的集成开发环境； 编程语言：Python 3.5； 操作系统：macOS Sierra。 ¶小结 GMM算法作为EM算法族的一个例子，它指定了各个参与杂合的分布都是高斯分布，即分布参数表现为均值Mu和方差Sigma。通过EM算法作为计算使用的框架，迭代地算出各个高斯分布的参数。 ¶GMM与K-means的思考 提到GMM不得不提K-means，总结了网上的资料以及老师上课的课件，我将两者的区别与联系陈述如下： 两者的联系: 都是迭代执行的算法，且迭代的策略也相同：算法开始执行时先对需要计算的参数赋初值，然后交替执行两个步骤，一个步骤是对数据的估计（k-means是估计每个点所属簇；GMM是计算隐含变量的期望）；第二步是用上一步算出的估计值重新计算参数值，更新目标参数（k-means是计算簇心位置；GMM是计算各个高斯分布的中心位置和协方差矩阵） 两者的区别: 首先，两者需要计算的参数不同：K-means是簇心位置；GMM是各个高斯分布的参数；其次，两者计算目标参数的方法不同：K-means是计算当前簇中所有元素的位置的均值；GMM是基于概率的算法，是通过计算似然函数的最大值实现分布参数的求解的。 ¶关于GMM引发的过拟合的思考 首先我想提到这样的一个“人辨认其他生物（例如鱼）”的例子。当我们被告知水里游的那个生物是鱼之后，我们会使用“在同样的地方生活的是同一种东西”这类似的假设，归纳出“在水里游的都是鱼”这样一个结论。当然这个过程是完全“本能”的，如果不仔细去想，我们也不会了解自己是怎样“认识鱼”的。另一个值得注意的地方是这样的假设并不总是完全正确的，甚至可以说总是会有这样那样的缺陷的，因为我们有可能会把虾、龟、甚至是潜水员当做鱼。也许你觉得可以通过修改前提假设来解决这个问题，例如，基于“生活在同样的地方并且穿着同样衣服的是同一种东西”这个假设，你得出结论：在水里有并且身上长有鳞片的是鱼。可是这样还是有问题，因为有些没有长鳞片的鱼现在又被你排除在外了。 机器在识别方面面临着和人一样的问题，在机器学习中，一个学习算法也会有一个前提假设，这里被称作“归纳偏执”。例如线性回归，目的是要找一个函数尽可能好地拟合给定的数据点，它的归纳偏执就是“满足要求的函数必须是线性函数”。一个没有归纳偏执的学习算法从某种意义上来说毫无用处，就像一个完全没有归纳能力的人一样，在第一次看到鱼的时候有人告诉他那是鱼，下次看到另一条鱼了，他并不知道那也是鱼，因为两条鱼总有一些地方不一样的，或者就算是同一条鱼，在河里不同的地方看到，或者只是看到的时间不一样，也会被他认为是不同的，因为他无法归纳，无法提取主要矛盾、忽略次要因素，只好要求所有的条件都完全一样──然而哲学家已经告诉过我们了：世界上不会有任何样东西是完全一样的，所以这个人即使是有无比强悍的记忆力，也绝学不到任何一点知识。 于是有了上面的铺垫，我们就可以引出论题——“过拟合 ”，就像前面的回归的问题，如果去掉“线性函数”这个归纳偏执，因为对于 N 个点，我们总是可以构造一个 N-1 次多项式函数，让它完美地穿过所有的这 N 个点，或者如果我用任何大于 N-1 次的多项式函数的话，我们甚至可以构造出无穷多个满足条件的函数出来。如果假定特定领域里的问题所给定的数据个数总是有个上限的话，我可以取一个足够大的 N ，从而得到一个（或者无穷多个）“超级函数”，能够拟合这个领域内所有的问题。 没有归纳偏执或者归纳偏执太宽泛会导致过拟合 ，然而另一个极端──限制过大的归纳偏执也是有问题的：如果数据本身并不是线性的，强行用线性函数去做回归通常并不能得到好结果（例如我在“实验一：多项式拟合曲线”中就做过相应的测试）。难点正在于在这之间寻找一个临界点。不过我们在这里相对于机器来说有一个很大的优势：人通常不会孤立地用某一个独立的系统和模型去处理问题，一个人每天都会从各个来源获取大量的信息，并且通过各种手段进行整合处理，归纳所得的所有知识最终得以统一地存储起来，并能有机地组合起来去解决特定的问题。 以上就是我关于“过拟合”的一点不全面的思考！","categories":[{"name":"AI","slug":"AI","permalink":"http://meng.uno/categories/AI/"},{"name":"机器学习","slug":"AI/机器学习","permalink":"http://meng.uno/categories/AI/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://meng.uno/tags/机器学习/"}]},{"title":"Android新闻软件编写","slug":"androidnews","date":"2016-12-16T07:01:14.000Z","updated":"2018-02-09T10:46:20.938Z","comments":true,"path":"posts/8fb3f6d8/","link":"","permalink":"http://meng.uno/posts/8fb3f6d8/","excerpt":"","text":"当我开始学安卓开发时，我发现网上最多的教程就是关于Android上的新闻客户端开发的（而且课时特别长），我本人觉得完全是那些上传网课的人想拉时长牟利，在写完listview之后，因为我们的《软设》项目需要，我也来做做“新闻页”，我只写显示过程（不涉及爬虫），只是为了记录下开发过程供初学者及日后自己回顾。 首先，我在values/string目录加上如下条目，用作显示（内容无关）： 123456789101112131415161718192021222324252627282930313233343536 &lt;string name=\"title\"&gt;是上帝除四害是的次数不多是彻底那就是地产表示比不对是不死都今?&lt;/string&gt; &lt;string name=\"text\"&gt;我是测手术储备货币结算你说的内存金士顿内存就剧场那就看到手残你从从今年刷卡才能加内存显卡才能收到你今年的你朝鲜才能常出现从侠客行朝鲜&lt;/string&gt; &lt;string-array name=\"text_arr\"&gt; &lt;item&gt;bids比貂蝉死不打算比赛的buds不v电话苏帮你吧报错还加班猝死地产表示出版社u白崇禧必须&lt;/item&gt; &lt;item&gt;但是不撒手撒就行字数限制到6个字，多的用省略号，是设置什么属学校决定停止晚自习，我和同学一起回荚冬 我是在那次孝雅之星的事迹报告会上认识她的。当轮到她上场的时候，主持人这样说道：“她是一个外表刚强，内心柔弱的人。”话音刚落，她班上的同学一阵哄堂大笑。 我用疑惑的眼神看了看身旁的同学，她告诉我，在她们班上谁都知道她是一个标准的女汉子。她的话勾起了我的好奇心，使我有了想听听她的故事的欲望。 她步履坚定的走上了演讲台，先是向我们深深地鞠了一躬，便开始娓娓道来她的事迹。 她的父母都在外打拼，忙于事业，所以很少有空去照顾她，所以家中的一切只能由她一人包办。后来，她又有了一个妹妹，致使她身上的担子又加重了许多，但她依然十分 坚强的承担这一切。她说妹妹的到来对于她来说像一个天使一样美好，而并不是觉得她是一个负担。当我们回到家中扑在父母怀里撒娇时，她在床头哄着妹妹入睡；当我作文网 http://wwW.zuoWen8.Com/们安稳的进入梦乡时，她却还在奋笔疾书。夜的黑暗与漫长，只有她才知道；思念的感受有多浓稠，只有她才知道；内心的压抑有多难受，只有她才知 道。 当她说到妹妹因调皮将很烫的饭菜洒到她的手臂上，她还得继续给妹妹喂饭时，当她提及妹妹做坏事后她忍气吞声的到别人家中道歉时，她哽咽了，将头扭到一边独自抹眼泪。 我们沉默了，低头不语。忧伤的气息迅速在全场蔓延，每个人的心都在和她共鸣着，有好几次，她正准备开口时，却都卡在了喉咙，全场为她响起了雷鸣般经久不息的掌声。 &lt;/item&gt; &lt;item&gt;看到他我想到了爸爸，幸好他今天不上班，不用冒那么大的雪，假如哪个人是我爸爸，我多么希看有一个好心人上前伸出一只手，帮他一把。假如那是你，&lt;/item&gt; &lt;item&gt;我停了车子，想往帮助他，可我也象那些来来往往的行人一样，脚步并没有动，的确有很多人同情他，同情也的确对他没用，他还是站不起来，一遍一遍看他起来又摔倒，只好转过头， 不看他，疼痛无奈，一个中年男子的窘态在众人眼前暴露无遗，这时的他没有一点男子汉的心胸。&lt;/item&gt; &lt;item&gt;走到一个小岔路口时，我看到路的另一边一个中年男子坐在地上，他穿着青色衣服，双手扶地，似乎挣扎着坐起来，一次又一次尝试着。旁边躺着他的尽看的大梁自行车，等待着主人扶 起它，在这路上最难过的就是他们了吧！也只有他们可以相互安慰。&lt;/item&gt; &lt;item&gt;春天，春姑娘带来了蒙蒙细雨和柔和的春风，并把它们化作一只大画笔，把绿色涂在草坪上。这时，无数只小燕子从远方飞来，在草坪上飞来飞去。&lt;/item&gt; &lt;item&gt;夏天，草坪旁的花坛里，月季花欣然怒放，引来了勤劳的小蜜蜂和翩翩起舞的蝴蝶，热闹极了。&lt;/item&gt; &lt;item&gt;冬天，雪花落到草坪上，给草坪盖上了一层厚厚的棉被，来年，小草更加茁壮成长。&lt;/item&gt; &lt;item&gt;草坪就像一个氧气袋，它通过光合作用，净化空气，美化环境。我们要爱护学校的草坪。&lt;/item&gt; &lt;/string-array&gt; &lt;string-array name=\"title_arr\"&gt; &lt;item&gt;死地产表示出版社u白崇禧必须&lt;/item&gt; &lt;item&gt;停止晚自习，我和同学一起回荚冬&lt;/item&gt; &lt;item&gt;假如哪个人是我爸爸，我多么希看有一个好心人上前伸出一只手，帮他一把。假如那是你，&lt;/item&gt; &lt;item&gt;我停了的行人一样，脚步并没有动，的确有很多人同情他，同情也的确对他没用，他还是站不起来，一遍一遍看他起来又摔倒，只好转过头，他没有一点男子汉的心胸。&lt;/item&gt; &lt;item&gt;他穿着青色衣服，双手扶地，似乎挣扎着坐起来，一次又一次尝试着。旁边躺着他的尽看的大梁自行车，等待着主人扶&lt;/item&gt; &lt;item&gt;春天。&lt;/item&gt; &lt;item&gt;夏天极了。&lt;/item&gt; &lt;item&gt;冬天，雪花落到&lt;/item&gt; &lt;item&gt;草坪就像的草坪。&lt;/item&gt; &lt;/string-array&gt; 接着编写显示主界面： 123456789101112131415161718192021222324252627 public class MainActivity extends AppCompatActivity&#123; private ListView listview; //private ArrayAdapter&lt;String&gt;arr_adapter; private SimpleAdapter simp_Adapter; private List&lt;Map&lt;String,String&gt;&gt;datalist; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); listview = (ListView)findViewById(R.id.listview); datalist = new ArrayList&lt;Map&lt;String,String&gt;&gt;(); simp_Adapter = new SimpleAdapter(this,getData(),R.layout.item, new String[]&#123;\"title\",\"text\"&#125;,new int[]&#123;R.id.title,R.id.text&#125;); listview.setAdapter(simp_Adapter); &#125; private List&lt;Map&lt;String,String&gt;&gt; getData()&#123; String[] data_text = getResources().getStringArray(R.array.text_arr); String[] data_title = getResources().getStringArray(R.array.title_arr); for(int i=0;i&lt;data_text.length;i++)&#123; Map&lt;String,String&gt;map = new HashMap&lt;String,String&gt;(); map.put(\"title\",data_title[i]); map.put(\"text\",data_text[i]); datalist.add(map); &#125; return datalist; &#125;&#125; 其对应的activity_main.xml文件为： 12345678910111213141516171819 &lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;RelativeLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:tools=\"http://schemas.android.com/tools\" android:id=\"@+id/activity_main\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:paddingBottom=\"@dimen/activity_vertical_margin\" android:paddingTop=\"@dimen/activity_vertical_margin\" tools:context=\"com.example.lpf.test.MainActivity\"&gt; &lt;ListView android:id=\"@+id/listview\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:layout_alignParentBottom=\"true\" android:layout_alignParentStart=\"true\" android:background=\"@color/bg\" android:divider=\"@color/item_item\" android:dividerHeight=\"10dp\"/&gt;&lt;/RelativeLayout&gt; 再然后，编写点击后的后台跳转逻辑： 1234567891011121314 public class ShowActivity extends AppCompatActivity &#123; protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_show); Bundle bundle = getIntent().getExtras(); String title = bundle.getString(\"title\"); String text = bundle.getString(\"text\"); TextView title_view = (TextView) findViewById(R.id.title); title_view.setText(title); TextView text_view = (TextView) findViewById(R.id.text); text_view.setMovementMethod(ScrollingMovementMethod.getInstance()); text_view.setText(text); &#125;&#125; 对应的activity_show.xml文件如下： 123456789101112131415161718192021222324252627 &lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;LinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" android:orientation=\"vertical\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:paddingBottom=\"@dimen/activity_vertical_margin\" android:paddingLeft=\"@dimen/activity_horizontal_margin\" android:paddingRight=\"@dimen/activity_horizontal_margin\" android:paddingTop=\"@dimen/activity_vertical_margin\"&gt; &lt;TextView android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:id=\"@+id/title\" android:text=\"@string/title\" android:textSize=\"22sp\" android:typeface=\"monospace\" android:background=\"@color/itembg\"/&gt; &lt;TextView android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:id=\"@+id/text\" android:textSize=\"18sp\" android:textColor=\"@color/textbg\" android:typeface=\"normal\" android:scrollbars=\"vertical\" android:text=\"@string/text\"/&gt;&lt;/LinearLayout&gt; 最后就是负责点击跳转的任务的后台程序了： 1234567891011121314151617181920212223 public class TestActivity extends ListActivity &#123; String[] data = &#123;\"北京\",\"西安\",\"广州\",\"上海\"&#125;; ListView lstview; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); lstview = (ListView)findViewById(R.id.listview); lstview.setOnItemClickListener(new AdapterView.OnItemClickListener()&#123; @Override public void onItemClick(AdapterView&lt;?&gt; parent, View view, int position, long id) &#123; String s = data[position]; &#125; &#125;); ArrayAdapter&lt;String&gt; adapter = new ArrayAdapter&lt;String&gt;( this, R.layout.item, R.id.listview, data ); lstview.setAdapter(adapter); &#125;&#125; 附加一个item.xml用于接收显示： 1234567891011121314151617181920212223242526272829 &lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;LinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" android:orientation=\"vertical\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:paddingBottom=\"@dimen/activity_vertical_margin\" android:paddingLeft=\"@dimen/activity_horizontal_margin\" android:paddingRight=\"@dimen/activity_horizontal_margin\" android:paddingTop=\"@dimen/activity_vertical_margin\" android:background=\"@drawable/white_bg\"&gt; &lt;TextView android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:id=\"@+id/title\" android:text=\"@string/title\" android:textSize=\"20sp\" android:typeface=\"monospace\" android:background=\"@color/itembg\"/&gt; &lt;TextView android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:id=\"@+id/text\" android:textSize=\"15sp\" android:textColor=\"@color/textbg\" android:typeface=\"normal\" android:maxLines=\"3\" android:ellipsize=\"end\" android:text=\"@string/text\"/&gt;&lt;/LinearLayout&gt; 至此一个新闻客户端基本框架就已经编写完毕！","categories":[{"name":"Android","slug":"Android","permalink":"http://meng.uno/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://meng.uno/tags/Android/"}]},{"title":"Linux 0.11启动引导","slug":"os","date":"2016-12-16T06:52:23.000Z","updated":"2018-02-09T10:46:20.931Z","comments":true,"path":"posts/6c138ff9/","link":"","permalink":"http://meng.uno/posts/6c138ff9/","excerpt":"","text":"Linux引导启动程序程序在boot目录下，有bootset.s, head.s和setup.s（编译后），其中： ¶bootset.s 系统启动时首先是进入实模式，从地址0xffff0（这地址映射的rom-bios在内存的地址）处开始执行bios代码，然后执行系统检测（也就是自检过程）,然后初始化实模式的中断向量表(实模式中断向量在内存物理地址0处)。然后将启动设备的第一个扇区（512字节，也就是bootset.s编译完成的内容）内容读取到内存0x7c00(31kB)处，并且跳转到这里。 跳转到bootset.s后，bootset.s主要做如下工作： bootset.s在最前面的几句代码先将自己移动到内存0x90000（576kB）处； bootset.s将启动设备第2个扇区到第五个扇区内容（4个扇区里面存放的是setup.s的内容）读取到内存0x90200处，也就是bootset.s后面； 将内核其他模块读取到0x10000（64KB）处，读取的大小为192KB，对于当时的内核来说确实是足够大了； 在bootset.s偏移508处定义了根文件系统的设备号，并且根据编译选项进行了赋值操代码默认启动驱动器是软盘a，然后就是bootset.s,setup.s,和内核镜像都成放在软盘a中; ¶setup.s 将系统的一些参数存放在0x90000处,覆盖之前的bootset.s,参数主要包括，内存大小，硬盘参数，显存的参数信息以及根文件系统的设备号; 定义了GDT表，最后加载了gdtr和ldtr，最后跳到保护模式GDT表定义在setup.s,也就是在0x90200的那段内存中，LDT还没有定义。 ¶head.s 其被编译到内核镜像中。重新定义了GDT表(目前就一个第二个段描述符有效)和并定义LDT表（表中中断处理程序目前还是指向一个默认的处理程序），并加载相应的寄存器； 内存开始处设置页目录表，一共有4个叶目录，初始化页目录，然后开启分页，最后跳到主函数main()。 至此，系统启动引导完成。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://meng.uno/categories/操作系统/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://meng.uno/tags/操作系统/"}]},{"title":"Android的ListView的使用","slug":"android_listview","date":"2016-12-15T05:58:11.000Z","updated":"2018-02-09T10:46:20.916Z","comments":true,"path":"posts/5d6c9819/","link":"","permalink":"http://meng.uno/posts/5d6c9819/","excerpt":"","text":"可能我们在手机APP上使用的最多的视图就是列表了，那么Android列表（ListView）该怎么使用呢？ 首先还是显示界面activity_main.xml: 12345678910111213141516171819 &lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;RelativeLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:tools=\"http://schemas.android.com/tools\" android:id=\"@+id/activity_main\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:paddingBottom=\"@dimen/activity_vertical_margin\" android:paddingTop=\"@dimen/activity_vertical_margin\" tools:context=\"com.example.lpf.test.MainActivity\"&gt; &lt;ListView android:id=\"@+id/listview\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:layout_alignParentBottom=\"true\" android:layout_alignParentStart=\"true\" android:background=\"@color/bg\" android:divider=\"@color/item_item\" android:dividerHeight=\"10dp\"/&gt;&lt;/RelativeLayout&gt; 之后是其对应的MainActivity.java文件： 123456789101112131415161718192021222324252627 public class MainActivity extends AppCompatActivity&#123; private ListView listview; //private ArrayAdapter&lt;String&gt;arr_adapter; private SimpleAdapter simp_Adapter; private List&lt;Map&lt;String,String&gt;&gt;datalist; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); listview = (ListView)findViewById(R.id.listview); datalist = new ArrayList&lt;Map&lt;String,String&gt;&gt;(); simp_Adapter = new SimpleAdapter(this,getData(),R.layout.item, new String[]&#123;\"title\",\"text\"&#125;,new int[]&#123;R.id.title,R.id.text&#125;); listview.setAdapter(simp_Adapter); &#125; private List&lt;Map&lt;String,String&gt;&gt; getData()&#123; String[] data_text = getResources().getStringArray(R.array.text_arr); String[] data_title = getResources().getStringArray(R.array.title_arr); for(int i=0;i&lt;data_text.length;i++)&#123; Map&lt;String,String&gt;map = new HashMap&lt;String,String&gt;(); map.put(\"title\",data_title[i]); map.put(\"text\",data_text[i]); datalist.add(map); &#125; return datalist; &#125;&#125; 其他文件保持不变即可。 至此，一个Android列表程序就实现了。","categories":[{"name":"Android","slug":"Android","permalink":"http://meng.uno/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://meng.uno/tags/Android/"}]},{"title":"Android实现输入框回车输入","slug":"android_enter","date":"2016-12-15T05:22:51.000Z","updated":"2018-02-09T10:46:20.915Z","comments":true,"path":"posts/e60b1ba5/","link":"","permalink":"http://meng.uno/posts/e60b1ba5/","excerpt":"","text":"用惯了iOS的各位在开发安卓程序或者使用安卓手机时，都会遇到这样一个问题：原本在iOS上都是回车输入，而到了Android上却需要点击按钮完成输入（对比两个系统上的QQ就发现了）。我一直在使用iOS系统，因为《软设》才着手Android开发，所以我就想能不能像iOS上的那样实现一个输入框+回车符完成输入呢？经过我查找资料，发现确实可以： 12345678910111213141516 &lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;LinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:tools=\"http://schemas.android.com/tools\" android:orientation=\"vertical\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:weightSum=\"1\"&gt; &lt;EditText android:id=\"@+id/edit_message\" android:layout_margin=\"30dp\" android:layout_width=\"match_parent\" android:layout_height=\"80dp\" android:hint=\"请输入文本信息 ...\" android:imeOptions=\"actionSearch\" android:singleLine=\"true\"/&gt;&lt;/LinearLayout&gt; 在EditText中加入了imeOptions就可以将回车符转变成各种各样的功能： actionDone——回车符–&gt;完成 actionSend——回车符–&gt;发送 actionGo——回车符–&gt;前进 actionNext——回车符–&gt;下一项 actionNone——回车符–&gt;无动作 actionPrevious——回车符–&gt;上一项 actionSearch——回车符–&gt;搜索 actionUnspecified——回车符–&gt;未指定 actionSend——回车符–&gt;发送 又查阅资料发现：ime是Input Method Editors的缩写，也就是输入法编辑器，原来如此，不过想使用这个属性，必须加上android:inputType 或者 android:singleline=”true” 至此，就完成了Android回车符向iOS的转化！","categories":[{"name":"Android","slug":"Android","permalink":"http://meng.uno/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://meng.uno/tags/Android/"}]},{"title":"Android页面跳转","slug":"android_pages_jump","date":"2016-12-15T04:46:49.000Z","updated":"2018-02-09T10:46:20.917Z","comments":true,"path":"posts/1da18548/","link":"","permalink":"http://meng.uno/posts/1da18548/","excerpt":"","text":"¶前情提要 开发安卓单页面程序久了，必然会思考怎么开发像现在一般Android应用程序那样的多页面（指页面有跳转）程序，我也是在搜索了其他牛人的（海量）博客之后，才总结出如下的这点精华步骤（又要感慨一下国内搜索引擎之渣）！ ¶编写AndroidManifest.xml 首先，我们要确定我们需要怎样的跳转，既然跳转，无非就是自动跳转或者点击按钮，无论哪种，首先我们必须有两个界面（至少），所以在AndroidManifest.xml中，我们需要这样写： 123456789101112131415161718192021222324 &lt;manifest xmlns:android=\"http://schemas.android.com/apk/res/android\" package=\"uno.meng.download\"&gt; &lt;application android:allowBackup=\"true\" android:icon=\"@mipmap/ic_launcher\" android:theme=\"@style/AppTheme\"&gt; &lt;activity android:name=\".MainActivity\" android:label=\"@string/app_name\"&gt; &lt;intent-filter&gt; &lt;action android:name=\"android.intent.action.MAIN\" /&gt; &lt;category android:name=\"android.intent.category.LAUNCHER\" /&gt; &lt;/intent-filter&gt; &lt;/activity&gt; &lt;activity android:name=\".ResultActivity\" android:label=\"@string/comeback\" android:parentActivityName=\".MainActivity\" &gt; &lt;meta-data android:name=\"android.support.PARENT_ACTIVITY\" android:value=\".MainActivity\"/&gt; &lt;/activity&gt; &lt;/application&gt;&lt;/manifest&gt; 其中，每个 对应一个界面，从代码中可见，我将后一个页面加了一个返回前一个页面的“返回符”。 ¶编写跳转前界面search.xml 由于我在此将介绍怎么使用按钮跳转（带输入），所以直接在主界面search.xml（名称随意）中声明这两个组件（按钮，输入框）： 123456789101112131415161718192021 &lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;LinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:tools=\"http://schemas.android.com/tools\" android:orientation=\"vertical\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:weightSum=\"1\"&gt; &lt;EditText android:id=\"@+id/edit_message\" android:layout_margin=\"30dp\" android:layout_width=\"match_parent\" android:layout_height=\"80dp\" android:hint=\"请输入文本信息 ...\"/&gt; &lt;Button android:id=\"@+id/button\" android:text=\"点击提交 \" android:layout_margin=\"100dp\" android:layout_width=\"127dp\" android:layout_height=\"wrap_content\" android:onClick=\"sendMessage\" /&gt;&lt;/LinearLayout&gt; 可见，我对按钮加了一个onClick事件。 ¶编写对应的MainActivity.java 在search.xml对应的MainActivity.java文件中我们写好onCreate方法（每个文件都会有）以及sendMessage方法： 123456789101112131415 public class MainActivity extends AppCompatActivity &#123; public final static String EXTRA_MESSAGE = \"uno.meng.download.MESSAGE\"; public void sendMessage()&#123; EditText editText = (EditText)findViewById(R.id.edit_message); String message = editText.getText().toString(); Intent intent = new Intent(this, ResultActivity.class); intent.putExtra(EXTRA_MESSAGE,message); startActivity(intent); &#125; @Override protected void onCreate(Bundle savedInstanceState)&#123; super.onCreate(savedInstanceState); setContentView(R.layout.search); &#125;&#125; ¶编写接收界面result.xml 然后到result.xml接收（我用的一个框来接收）： 123456789101112 &lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;LinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:tools=\"http://schemas.android.com/tools\" android:orientation=\"vertical\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:weightSum=\"1\"&gt; &lt;TextView android:layout_margin=\"30dp\" android:layout_width=\"match_parent\" android:layout_height=\"80dp\"/&gt;&lt;/LinearLayout&gt; ¶编写接收对应的ResultActivity.java 编写对应的ResultActivity.java文件， 将从MainActivity.java接收来的文字打印到result.xml的框中： 123456789101112131415 public class ResultActivity extends AppCompatActivity&#123; private Intent intent; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.result); intent = getIntent(); String message = intent.getStringExtra(MainActivity.EXTRA_MESSAGE); System.out.println(message); TextView textview = new TextView(this); textview.setTextSize(100); textview.setText(message); setContentView(textview); &#125;&#125; 到此为止，已经完成了Android页面跳转！","categories":[{"name":"Android","slug":"Android","permalink":"http://meng.uno/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://meng.uno/tags/Android/"}]},{"title":"表格搜索","slug":"tablesearch","date":"2016-12-13T04:29:32.000Z","updated":"2018-02-09T10:46:20.941Z","comments":true,"path":"posts/49d54823/","link":"","permalink":"http://meng.uno/posts/49d54823/","excerpt":"","text":"虽然表格的排列相当困难，但表格的搜索却非常容易。增加一个搜索输入，如果那里的值匹配到了任意一行的文本，则显示该行，并隐藏其他所有的行。使用jQuery来实现就像下面这么简单： 12345 var allRows = $(\"tr\");$(\"input#search\").on(\"keydown keyup\", function() &#123; allRows.hide(); $(\"tr:contains('\" + $(this).val() + \"')\").show();&#125;); 没有看错，就是这么简单，如果是在实际应用中，可以这样来写： 先声明一个按钮： 1 &lt;input type=\"search\" id=\"search\" placeholder=\"请输入内容……\"&gt; 在input框之后加入以下JavaScript代码： 123456789101112131415 &lt;script&gt;// Quick Table Search$('#search').keyup(function() &#123; var regex = new RegExp($('#search').val(), \"i\"); var rows = $('table tr:gt(0)'); rows.each(function (index) &#123; title = $(this).children(\"#title\").html() if (title.search(regex) != -1) &#123; $(this).show(); &#125; else &#123; $(this).hide(); &#125; &#125;);&#125;);&lt;/script&gt; 完美运行有木有！！！","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/categories/软件工程/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/tags/软件工程/"}]},{"title":"使用JavaScript将页面导出为图片","slug":"canvas","date":"2016-12-13T04:20:18.000Z","updated":"2018-02-09T10:46:20.919Z","comments":true,"path":"posts/f03eda59/","link":"","permalink":"http://meng.uno/posts/f03eda59/","excerpt":"","text":"昨天心血来潮，突然想将我们组开发的网站上的“导出Excel”功能做一点拓展，于是就想能不能直接将网页表格导出为图片！ 在我的不懈搜索后（搜索过程中绝大部分博客上的博文要么相互抄袭要么没什么屁用），终于得到了“canvas2image.js”这个神奇的JavaScript脚本，具体使用办法见如下代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556 &lt;!doctype html&gt;&lt;html&gt;&lt;script src=\"canvas2image.js\"&gt;&lt;/script&gt;&lt;body&gt; &lt;canvas id=\"cvs\"&gt;&lt;/canvas&gt; &lt;button id=\"save\"&gt;save&lt;/button&gt;&lt;script&gt; var canvas, ctx, bMouseIsDown = false, iLastX, iLastY, $save, $imgs, $convert, $imgW, $imgH, $sel; function init ()&#123; canvas = document.getElementById('cvs'); ctx = canvas.getContext('2d'); $save = document.getElementById('save'); $convert = document.getElementById('convert'); $sel = \"png\"; $imgs = document.getElementById('imgs'); $imgW = 1980; $imgH = 2000; bind(); draw(); &#125; function bind () &#123; canvas.onmousedown = function(e) &#123; bMouseIsDown = true; iLastX = e.clientX - canvas.offsetLeft + (window.pageXOffset||document.body.scrollLeft||document.documentElement.scrollLeft); iLastY = e.clientY - canvas.offsetTop + (window.pageYOffset||document.body.scrollTop||document.documentElement.scrollTop); &#125; canvas.onmouseup = function() &#123; bMouseIsDown = false; iLastX = -1; iLastY = -1; &#125; canvas.onmousemove = function(e) &#123; if (bMouseIsDown) &#123; var iX = e.clientX - canvas.offsetLeft + (window.pageXOffset||document.body.scrollLeft||document.documentElement.scrollLeft); var iY = e.clientY - canvas.offsetTop + (window.pageYOffset||document.body.scrollTop||document.documentElement.scrollTop); ctx.moveTo(iLastX, iLastY); ctx.lineTo(iX, iY); ctx.stroke(); iLastX = iX; iLastY = iY; &#125; &#125;; $save.onclick = function (e) &#123; var type = $sel.value, w = $imgW.value, h = $imgH.value; Canvas2Image.saveAsImage(canvas, w, h, type); &#125; &#125; onload = init;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/categories/软件工程/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/tags/软件工程/"}]},{"title":"Java导出Excel","slug":"java2excel","date":"2016-12-06T14:16:48.000Z","updated":"2018-02-09T10:46:20.923Z","comments":true,"path":"posts/7725d215/","link":"","permalink":"http://meng.uno/posts/7725d215/","excerpt":"","text":"完成这个实验，你需要下载jxljar包，具体方法自行百度。 接下来我将直接使用具体代码进行讲解我的实现过程。 文件名： ExcelAction.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879 package net.kuangmeng.excel;/*这里是所有需要导入的库，不用担心当你写好其他代码时，编辑器会提示或者自动帮你补全！*/import java.io.File;import java.io.FileOutputStream;import java.io.IOException;import java.util.ArrayList;import java.util.List;import com.opensymphony.xwork2.ActionSupport;import jxl.Workbook;import jxl.format.Alignment;import jxl.format.Colour;import jxl.format.UnderlineStyle;import jxl.format.VerticalAlignment;import jxl.write.Label;import jxl.write.WritableCellFormat;import jxl.write.WritableFont;import jxl.write.WritableSheet;import jxl.write.WritableWorkbook;import jxl.write.WriteException;import jxl.write.biff.RowsExceededException;@SuppressWarnings(\"serial\")public class ExcelAction extends ActionSupport&#123; public static void main(String[] args) &#123; //主函数调用 //listth为导出excel的表头信息 list&lt;String&gt; listth = new ArrayList&lt;String&gt;; //listtd为导出的excel表项 list&lt;String&gt; listtd = new ArrayList&lt;String&gt;; //num为表的列数 int num ; exportExcel(tablename,listth,listtd,num); &#125;//真正的导出excel方法 public static void exportExcel(String fileName,List&lt;String&gt; listth,List&lt;String&gt; listtd,int num) &#123; //设置保存文件具体位置及文件名 String excelName =\"C:\\\\Users\\\\meng\\\\Desktop\\\\\"+fileName+\".xls\"; try &#123; File excelFile = new File(excelName); // 如果文件存在就删除它 if (excelFile.exists()) excelFile.delete(); // 打开文件 WritableWorkbook book = Workbook.createWorkbook(excelFile); // 生成名为“第一页”的工作表，参数0表示这是第一页 WritableSheet sheet = book.createSheet(\"Up2U导出表格 \", 0); // 文字样式 jxl.write.WritableFont wfc = new jxl.write.WritableFont( WritableFont.ARIAL, 10, WritableFont.NO_BOLD, false, UnderlineStyle.NO_UNDERLINE, jxl.format.Colour.BLACK); jxl.write.WritableCellFormat wcfFC = new jxl.write.WritableCellFormat( wfc); jxl.write.WritableCellFormat wcfF = new jxl.write.WritableCellFormat(wfc); wcfF.setBackground(jxl.format.Colour.BLACK); // 设置单元格样式 wcfFC.setBackground(jxl.format.Colour.GRAY_25);// 单元格颜色 wcfFC.setAlignment(jxl.format.Alignment.CENTRE);// 单元格居中 // 在Label对象的构造子中指名单元格位置是第一列第一行(0,0) // 以及单元格内容为 for(int i=0;i&lt;listth.size()/(num-2);i++)&#123; for(int j=0;j&lt;num-2;j++)&#123; sheet.addCell(new Label(j,i,listth.get(i*(num-2)+j),wcfFC)); &#125; &#125; for(int i=listth.size()/(num-2);i&lt;(listth.size()+listtd.size())/(num-2);i++)&#123; for(int j=0;j&lt;num-2;j++)&#123; sheet.addCell(new Label(j,i,listtd.get((i-1)*(num-2)+j),wcfF)); &#125; &#125; // 写入数据并关闭文件 book.write(); book.close(); System.out.println(\"Excel创建成功\"); &#125; catch (Exception e) &#123; System.out.println(e); &#125; &#125;&#125;","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/categories/软件工程/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/tags/软件工程/"}]},{"title":"Mac MySQL无法启动解决方案","slug":"mysql_error","date":"2016-12-06T13:24:05.000Z","updated":"2018-02-09T10:46:20.929Z","comments":true,"path":"posts/115ed5e0/","link":"","permalink":"http://meng.uno/posts/115ed5e0/","excerpt":"","text":"正像这次博客的日期那样，《软工》大项目接近尾声了，然而直到今天我才真正解决了这个大难题——Mac MySQL无法使用！！！ 检查MySQL是否成功安装 1 mysql --version 关闭MySQL连接（即使没连也无妨） 1 sudo /usr/local/mysql/support-files/mysql.server stop 登录管理员 12 cd /usr/local/mysql/bin/sudo su 禁止MySQL验证来登录（此时不验证密码） 1 ./mysqld_safe --skip-grant-tables &amp; （此时应该成功进入mysql&gt;）设置密码 1 UPDATE mysql.user SET authentication_string=PASSWORD('*****') WHERE User='root'; （若显示密码过期）设置密码永不过期 1 ALTER USER 'root'@'localhost' PASSWORD EXPIRE NEVER; 刷新MySQL的系统权限 1 flush privileges; 至此应该来说MySQL应该好使了。","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/categories/软件工程/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/tags/软件工程/"}]},{"title":"Java发送邮件","slug":"javamail","date":"2016-12-04T14:30:34.000Z","updated":"2018-02-09T10:46:20.925Z","comments":true,"path":"posts/21f3b9c2/","link":"","permalink":"http://meng.uno/posts/21f3b9c2/","excerpt":"","text":"我觉得学会Java mail是一件很自豪的事，怎么说呢，邮箱这么有逼格的东西都能被你玩的很溜的话，一定不一般。 本次试验使用了 javax.mail.jarjar包，请自行百度下载。 我实现的Java mail主要包括4个部分： 发送邮件使用的基本信息 邮件发送器 发件人设置 实际发送 四个部分组成。 ¶发送邮件使用的基本信息 文件名：MailSenderInfo.java 代码如下，我仍然以备注的形式讲解： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495 package net.kuangmeng.mail; /** * 发送邮件需要使用的基本信息 */ import java.util.Properties; public class MailSenderInfo &#123; // 发送邮件的服务器的IP和端口 private String mailServerHost; private String mailServerPort = \"25\"; // 邮件发送者的地址 private String fromAddress; // 邮件接收者的地址 private String toAddress; // 登陆邮件发送服务器的用户名和密码 private String userName; private String password; // 是否需要身份验证 private boolean validate = false; // 邮件主题 private String subject; // 邮件的文本内容 private String content; // 邮件附件的文件名 private String[] attachFileNames; /** * 获得邮件会话属性 */ public Properties getProperties()&#123; Properties p = new Properties(); p.put(\"mail.smtp.host\", this.mailServerHost); p.put(\"mail.smtp.port\", this.mailServerPort); p.put(\"mail.smtp.auth\", validate ? \"true\" : \"false\"); return p; &#125; public String getMailServerHost() &#123; return mailServerHost; &#125; public void setMailServerHost(String mailServerHost) &#123; this.mailServerHost = mailServerHost; &#125; public String getMailServerPort() &#123; return mailServerPort; &#125; public void setMailServerPort(String mailServerPort) &#123; this.mailServerPort = mailServerPort; &#125; public boolean isValidate() &#123; return validate; &#125; public void setValidate(boolean validate) &#123; this.validate = validate; &#125; public String[] getAttachFileNames() &#123; return attachFileNames; &#125; public void setAttachFileNames(String[] fileNames) &#123; this.attachFileNames = fileNames; &#125; public String getFromAddress() &#123; return fromAddress; &#125; public void setFromAddress(String fromAddress) &#123; this.fromAddress = fromAddress; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; public String getToAddress() &#123; return toAddress; &#125; public void setToAddress(String toAddress) &#123; this.toAddress = toAddress; &#125; public String getUserName() &#123; return userName; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125; public String getSubject() &#123; return subject; &#125; public void setSubject(String subject) &#123; this.subject = subject; &#125; public String getContent() &#123; return content; &#125; public void setContent(String textContent) &#123; this.content = textContent; &#125; &#125; ¶邮件发送器 文件名：SimpleMailSender.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105 package net.kuangmeng.mail;import java.util.Date; import java.util.Properties; import javax.mail.Address; import javax.mail.BodyPart; import javax.mail.Message; import javax.mail.MessagingException; import javax.mail.Multipart; import javax.mail.Session; import javax.mail.Transport; import javax.mail.internet.InternetAddress; import javax.mail.internet.MimeBodyPart; import javax.mail.internet.MimeMessage; import javax.mail.internet.MimeMultipart; /** * 简单邮件（不带附件的邮件）发送器 */ public class SimpleMailSender &#123; /** * 以文本格式发送邮件 * @param mailInfo 待发送的邮件的信息 */ public boolean sendTextMail(MailSenderInfo mailInfo) &#123; // 判断是否需要身份认证 MyAuthenticator authenticator = null; Properties pro = mailInfo.getProperties(); if (mailInfo.isValidate()) &#123; // 如果需要身份认证，则创建一个密码验证器 authenticator = new MyAuthenticator(mailInfo.getUserName(), mailInfo.getPassword()); &#125; // 根据邮件会话属性和密码验证器构造一个发送邮件的session Session sendMailSession = Session.getDefaultInstance(pro,authenticator); try &#123; // 根据session创建一个邮件消息 Message mailMessage = new MimeMessage(sendMailSession); // 创建邮件发送者地址 Address from = new InternetAddress(mailInfo.getFromAddress()); // 设置邮件消息的发送者 mailMessage.setFrom(from); // 创建邮件的接收者地址，并设置到邮件消息中 Address to = new InternetAddress(mailInfo.getToAddress()); mailMessage.setRecipient(Message.RecipientType.TO,to); // 设置邮件消息的主题 mailMessage.setSubject(mailInfo.getSubject()); // 设置邮件消息发送的时间 mailMessage.setSentDate(new Date()); // 设置邮件消息的主要内容 String mailContent = mailInfo.getContent(); mailMessage.setText(mailContent); // 发送邮件 Transport.send(mailMessage); return true; &#125; catch (MessagingException ex) &#123; ex.printStackTrace(); &#125; return false; &#125; /** * 以HTML格式发送邮件 * @param mailInfo 待发送的邮件信息 */ public static boolean sendHtmlMail(MailSenderInfo mailInfo)&#123; // 判断是否需要身份认证 MyAuthenticator authenticator = null; Properties pro = mailInfo.getProperties(); //如果需要身份认证，则创建一个密码验证器 if (mailInfo.isValidate()) &#123; authenticator = new MyAuthenticator(mailInfo.getUserName(), mailInfo.getPassword()); &#125; // 根据邮件会话属性和密码验证器构造一个发送邮件的session Session sendMailSession = Session.getDefaultInstance(pro,authenticator); try &#123; // 根据session创建一个邮件消息 Message mailMessage = new MimeMessage(sendMailSession); // 创建邮件发送者地址 Address from = new InternetAddress(mailInfo.getFromAddress()); // 设置邮件消息的发送者 mailMessage.setFrom(from); // 创建邮件的接收者地址，并设置到邮件消息中 Address to = new InternetAddress(mailInfo.getToAddress()); // Message.RecipientType.TO属性表示接收者的类型为TO mailMessage.setRecipient(Message.RecipientType.TO,to); // 设置邮件消息的主题 mailMessage.setSubject(mailInfo.getSubject()); // 设置邮件消息发送的时间 mailMessage.setSentDate(new Date()); // MiniMultipart类是一个容器类，包含MimeBodyPart类型的对象 Multipart mainPart = new MimeMultipart(); // 创建一个包含HTML内容的MimeBodyPart BodyPart html = new MimeBodyPart(); // 设置HTML内容 html.setContent(mailInfo.getContent(), \"text/html; charset=utf-8\"); mainPart.addBodyPart(html); // 将MiniMultipart对象设置为邮件内容 mailMessage.setContent(mainPart); // 发送邮件 Transport.send(mailMessage); return true; &#125; catch (MessagingException ex) &#123; ex.printStackTrace(); &#125; return false; &#125; &#125; ¶发件人设置 文件名：MyAuthenticator.java 1234567891011121314151617 package net.kuangmeng.mail;import javax.mail.*; public class MyAuthenticator extends Authenticator&#123; String userName=null; String password=null; public MyAuthenticator()&#123; &#125; public MyAuthenticator(String username, String password) &#123; this.userName = username; this.password = password; &#125; protected PasswordAuthentication getPasswordAuthentication()&#123; return new PasswordAuthentication(userName, password); &#125; &#125; ¶实际发送 文件名：MailAction.java package net.kuangmeng.mail; import net.kuangmeng.*; public class MailAction { @SuppressWarnings(&quot;static-access&quot;) public static void main(String[] args){ //这个类主要是设置邮件 MailSenderInfo mailInfo = new MailSenderInfo(); mailInfo.setMailServerHost(&quot;smtp.yeah.net&quot;); mailInfo.setMailServerPort(&quot;25&quot;); mailInfo.setValidate(true); mailInfo.setUserName(&quot;*****@yeah.net&quot;); mailInfo.setPassword(&quot;******&quot;);//您的邮箱密码 mailInfo.setFromAddress(&quot;*****@yeah.net&quot;); mailInfo.setToAddress(&quot;****@qq.com&quot;); mailInfo.setSubject(&quot;你好！&quot;);//邮件主题 mailInfo.setContent(&quot;这是一个测试&quot;);//邮件内容 //这个类主要来发送邮件 SimpleMailSender sms = new SimpleMailSender(); sms.sendTextMail(mailInfo);//发送文体格式 sms.sendHtmlMail(mailInfo);//发送html格式 } }","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/categories/软件工程/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/tags/软件工程/"}]},{"title":"Bash的使用","slug":"bash","date":"2016-12-03T09:23:17.000Z","updated":"2018-02-09T10:46:20.918Z","comments":true,"path":"posts/19f2d195/","link":"","permalink":"http://meng.uno/posts/19f2d195/","excerpt":"","text":"¶显示 “Hello world!” echo Hello world! ¶每一句指令以换行或分号隔开： echo ‘This is the first line’; echo ‘This is the second line’ ¶声明一个变量： Variable=“Some string” ***这是错误的做法：***Variable = “Some string” ***原因：***Bash 会把 Variable 当做一个指令，由于找不到该指令，因此这里会报错。 ***也不可以这样：***Variable= ‘Some string’ ***原因：***Bash 会认为 ‘Some string’ 是一条指令，由于找不到该指令，这里再次报错。这个例子中 ‘Variable=’ 这部分会被当作仅对 ‘Some string’ 起作用的赋值。） ¶使用变量： 123 echo $Variableecho \"$Variable\"echo '$Variable' 当你赋值 (assign) 、导出 (export)，或者以其他方式使用变量时，变量名前不加 $。如果要使用变量的值， 则要加 $。 注意: ’ (单引号) 不会展开变量（即会屏蔽掉变量）。 ¶在变量内部进行字符串代换 echo ${Variable/Some/A} 会把 Variable 中首次出现的 “some” 替换成 “A”。 ¶变量的截取 Length=7 echo ${Variable:0:Length} 这样会仅返回变量值的前7个字符 ¶变量的默认值 echo ${Foo:-“DefaultValueIfFooIsMissingOrEmpty”} 对 null (Foo=) 和空串 (Foo=&quot;&quot;) 起作用； 零（Foo=0）时返回0 注意这仅返回默认值而不是改变变量的值 ¶内置变量： ¶下面的内置变量很有用 12345 echo \"Last program return value: $?\"echo \"Script's PID: $$\"echo \"Number of arguments: $#\"echo \"Scripts arguments: $@\"echo \"Scripts arguments separated in different variables: $1 $2...\" ¶读取输入： 123 echo \"What's your name?\"read Name # 这里不需要声明新变量echo Hello, $Name! ¶通常的 if 结构看起来像这样： ’man test’ 可查看更多的信息 123456 if [ $Name -ne $USER ]then echo \"Your name isn't your username\"else echo \"Your name is your username\"fi ¶根据上一个指令执行结果决定是否执行下一个指令 12 echo \"Always executed\" || echo \"Only executed if first command fails\"echo \"Always executed\" &amp;&amp; echo \"Only executed if first command does NOT fail\" ¶在 if 语句中使用 &amp;&amp; 和 || 需要多对方括号 123456789 if [ $Name == \"Steve\" ] &amp;&amp; [ $Age -eq 15 ]then echo \"This will run if $Name is Steve AND $Age is 15.\"fiif [ $Name == \"Daniya\" ] || [ $Name == \"Zach\" ]then echo \"This will run if $Name is Daniya OR Zach.\"fi ¶表达式的格式如下: echo $(( 10 + 5 )) ¶指令可以带有选项： 与其他编程语言不同的是，bash 运行时依赖上下文。比如，使用 ls 时，列出当前目录。 -l``` 列出文件和目录的详细信息 12345 ## 前一个指令的输出可以当作后一个指令的输入。```grep``` 用来匹配字符串。## 用下面的指令列出当前目录下所有的 txt 文件：```ls -l | grep \"\\.txt\" ¶以 ^EOF$ 作为结束标记从标准输入读取数据并覆盖 hello.py 123456789 cat &gt; hello.py &lt;&lt; EOF#!/usr/bin/env pythonfrom __future__ import print_functionimport sysprint(\"#stdout\", file=sys.stdout)print(\"#stderr\", file=sys.stderr)for line in sys.stdin: print(line, file=sys.stdout)EOF ¶重定向可以到输出，输入和错误输出 1234567 python hello.py &lt; \"input.in\"python hello.py &gt; \"output.out\"python hello.py 2&gt; \"error.err\"python hello.py &gt; \"output-and-error.log\" 2&gt;&amp;1python hello.py &gt; /dev/null 2&gt;&amp;1# &gt; 会覆盖已存在的文件， &gt;&gt; 会以累加的方式输出文件中。python hello.py &gt;&gt; \"output.out\" 2&gt;&gt; \"error.err\" ¶覆盖 output.out , 追加 error.err 并统计行数 12 info bash 'Basic Shell Features' 'Redirections' &gt; output.out 2&gt;&gt; error.errwc -l output.out error.err ¶运行指令并打印文件描述符 （比如 /dev/fd/123） 12 # 具体可查看： man fdecho &lt;(echo \"#helloworld\") ¶以 “#helloworld” 覆盖 output.out 1234 cat &gt; output.out &lt;(echo \"#helloworld\")echo \"#helloworld\" &gt; output.outecho \"#helloworld\" | cat &gt; output.outecho \"#helloworld\" | tee output.out &gt;/dev/null ¶清理临时文件并显示详情（增加 ‘-i’ 选项启用交互模式） 1 rm -v output.out error.err output-and-error.log ¶一个指令可用 $( ) 嵌套在另一个指令内部 ¶以下的指令会打印当前目录下的目录和文件总数 1 echo &quot;There are $(ls | wc -l) items here.&quot; ¶反引号 `` 起相同作用，但不允许嵌套 优先使用 $() 1 echo &quot;There are `ls | wc -l` items here.&quot; ¶Bash 的 case 语句与 Java 和 C++ 中的 switch 语句类似 123456 case \"$Variable\" in # 列出需要匹配的字符串 0) echo \"There is a zero.\";; 1) echo \"There is a one.\";; *) echo \"It is not null.\";;esac ¶循环遍历给定的参数序列 ¶变量$Variable 的值会被打印 3 次 1234 for Variable in &#123;1..3&#125;do echo \"$Variable\"done ¶或传统的 “for循环” 1234 for ((a=1; a &lt;= 3; a++))do echo $adone 也可以用于文件 ¶用 cat 输出 file1 和 file2 内容 1234 for Variable in file1 file2do cat \"$Variable\"done 或作用于其他命令的输出 ¶对 ls 输出的文件执行 cat 指令 1234 for Output in $(ls)do cat \"$Output\"done ¶while 循环 12345 while [ true ]do echo \"loop body here...\" breakdone ¶你也可以使用函数 ¶定义函数 1234567 function foo ()&#123; echo \"Arguments work just like script arguments: $@\" echo \"And: $1 $2...\" echo \"This is a function\" return 0&#125; ¶更简单的方法 12345 bar ()&#123; echo \"Another way to declare functions!\" return 0&#125; ¶调用函数 1 foo &quot;My name is&quot; $Name ¶有很多有用的指令需要学习 ¶打印 file.txt 的最后 10 行 1 tail -n 10 file.txt ¶打印 file.txt 的前 10 行 1 head -n 10 file.txt ¶将 file.txt 按行排序 1 sort file.txt ¶报告或忽略重复的行，用选项 -d 打印重复的行 1 uniq -d file.txt ¶打印每行中 ‘,’ 之前内容 1 cut -d &apos;,&apos; -f 1 file.txt ¶将 file.txt 文件所有 ‘okay’ 替换为 ‘great’, （兼容正则表达式） 1 sed -i &apos;s/okay/great/g&apos; file.txt ¶将 file.txt 中匹配正则的行打印到标准输出 这里打印以 “foo” 开头, “bar” 结尾的行 \"^foo.*bar$\" file.txt``` 1234 使用选项 &quot;-c&quot; 统计行数```grep -c &quot;^foo.*bar$&quot; file.txt ¶如果只是要按字面形式搜索字符串而不是按正则表达式，使用 fgrep (或 grep -F) 1 fgrep &quot;^foo.*bar$&quot; file.txt ¶以 bash 内建的 ‘help’ 指令阅读 Bash 自带文档 123456 helphelp helphelp forhelp returnhelp sourcehelp . ¶用 man 指令阅读相关的 Bash 手册 123 apropos bashman 1 bashman bash ¶用 info 指令查阅命令的 info 文档 （info 中按 ? 显示帮助信息） 1234 apropos info | grep '^info.*('man infoinfo infoinfo 5 info ¶阅读 Bash 的 info 文档 1234 info bashinfo bash 'Bash Features'info bash 6info --apropos bash","categories":[{"name":"Shells","slug":"Shells","permalink":"http://meng.uno/categories/Shells/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"http://meng.uno/tags/Shell/"},{"name":"Bash","slug":"Bash","permalink":"http://meng.uno/tags/Bash/"}]},{"title":"Java web中的浮出层使用","slug":"iframe","date":"2016-11-23T05:30:45.000Z","updated":"2018-02-09T10:46:20.923Z","comments":true,"path":"posts/fa7b6881/","link":"","permalink":"http://meng.uno/posts/fa7b6881/","excerpt":"","text":"进行《软件工程》大项目时，遇到想在主页上仿Google首页上的那种“一个输入框+两个按钮”，同时一个按钮搜索、一个按钮上传文件，于是到网上查了好久，都没有关于“一个按钮实现文件上传”的功能介绍，最后只能使用“通过一个浮出层弹出上传文件”这种方式，下面贴出JavaScript代码。 在按钮中使用时只需要这样使用就行： 1 &lt;a href=\"javascript:_iframe() %&gt;')\" class=\"button\"&gt;点击进入我的博客&lt;/a&gt; JavaScript代码如下： 123456789101112 &lt;script&gt; function _iframe() &#123; zeroModal.show(&#123; title: '我的博客', iframe: true, url: 'http://www.meng.uno', width: '60%', height: '60%', cancel: true &#125;); &#125; &lt;/script&gt;","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/categories/软件工程/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/tags/软件工程/"}]},{"title":"Mac sudo命令无法使用","slug":"sudo_error","date":"2016-11-19T03:29:25.000Z","updated":"2018-02-11T14:13:13.698Z","comments":true,"path":"posts/e3b9b515/","link":"","permalink":"http://meng.uno/posts/e3b9b515/","excerpt":"","text":"在之前好长一段时间，不知道因为我改动了哪个文件的权限，导致sudo命令无法使用，每次启动sudo总会报什么权限不对的错误，在网上找了好久都没找到解决办法，包括stackoverflow这么牛逼哄哄的网站上面问题人采纳的方案都无济于事，今天闲来无事，又想解决这个问题，这次我是直接进苹果的“Mac 支持”上看的，发现Mac有个单用户模式（在此给出连接），我进入单用户模式，然后就是一个黑框框，在里面输入以下几条命令： 123 mount -uw /chown root:wheel /etc/sudoerschmod 440 /etc/sudoers 大致就是恢复文件权限之类的吧，结果reboot之后，居然就好了😝。 特此记录以下，给出现同种问题的小伙伴提供下。 其实，我的MySQL也有问题，我正准备进MySQL官网看看有什么解决办法😂，所以说，有什么事，能看懂英文的，尽量去软件官网找解决办法！！","categories":[{"name":"sudo","slug":"sudo","permalink":"http://meng.uno/categories/sudo/"},{"name":"error","slug":"sudo/error","permalink":"http://meng.uno/categories/sudo/error/"}],"tags":[{"name":"sudo","slug":"sudo","permalink":"http://meng.uno/tags/sudo/"},{"name":"error","slug":"error","permalink":"http://meng.uno/tags/error/"}]},{"title":"String的“+”操作分析","slug":"string_plus","date":"2016-11-01T08:39:36.000Z","updated":"2018-02-10T13:09:13.130Z","comments":true,"path":"posts/fc57b387/","link":"","permalink":"http://meng.uno/posts/fc57b387/","excerpt":"","text":"¶起源 昨天，我和队友讨论字符串拼接问题时，他提到了这个问题：直接“+”操作好像是生成了临时的一个新String，然后拼接，再复制给原来的String。带着这个问题，我查了下，得出以下的结论。 ¶结论 我查到的信息之一这样说：因为“+”拼接字符串，每拼接一次都是再内存重新开辟一个新的内存区域（堆里边）,然后把得到的新的字符串存在这块内存，字符串如果很大，循环次多又多，那么浪费了很多时间和空间的开销。 我查到的信息之二这么说：当拼接次数较少时，其实编译器会将其优化为StringBuilder类型，只是当拼接次数特别多时，编译器优化时将会产生过多的StringBuilder类型，从而导致空间浪费。 ¶策略 当拼接次数较少时，我们可以直接使用“+”操作，而当拼接数量较大时，我们最好使用StringBuilder类型。 ¶操作 123 StringBuilder SB = new StringBuilder();SB.append(……);String Result = SB.toString();","categories":[{"name":"Java开发Tips","slug":"Java开发Tips","permalink":"http://meng.uno/categories/Java开发Tips/"},{"name":"String","slug":"Java开发Tips/String","permalink":"http://meng.uno/categories/Java开发Tips/String/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/tags/软件工程/"}]},{"title":"将多个input合并成一个字符串提交给后台","slug":"inputaswhole","date":"2016-10-29T04:50:24.000Z","updated":"2018-02-09T10:46:20.924Z","comments":true,"path":"posts/f12d3e70/","link":"","permalink":"http://meng.uno/posts/f12d3e70/","excerpt":"","text":"¶需求 我在做我们的《软件工程》作业时，遇到了这样一个问题：我们需要打开一个表，这个表的列数不确定，但要增加增加行的操作。 ¶实现 于是，需求产生了，我需要将前端的多个input标签内容合并成一个字符串来进行提交，我看了几个比较牛的方法（json、ognl……）但是好像与我们的需求偏的有点远（如果可以实现，欢迎留言），最后，没办法只能自己想，由于我还是会一点JavaScript的，所以我就想用JavaScript实现，在尝试了很多次之后，终于成功了，在此先贴上代码。 123456789101112131415161718192021222324 &lt;script type=\"text/javascript\"&gt;function n(n)&#123; var num=\"\"; for(var i=0;i&lt;n;i++)&#123; num += document.getElementById(\"num\"+i).value; &#125;document.getElementById(\"result\").value = num;&#125;&lt;/script&gt;&lt;% int num=3;%&gt;&lt;form action=\"addAction\"&gt;&lt;input id=\"num\" name=\"num\" value=&lt;%=num %&gt; type=\"text\"&gt;&lt;% for(int i=0;i&lt;num;i++)&#123;%&gt;&lt;input id=\"num&lt;%=i %&gt;\" type=\"text\" onblur=\"n(&lt;%=num%&gt;)\"&gt;&lt;% &#125;%&gt;&lt;input name=\"str\" id=\"result\" type=\"hidden\" &gt;&lt;button &gt;提交&lt;/button&gt;&lt;/form&gt; ¶分析 最后来分析，到底是怎么实现的，其实道理特别简单，就是JavaScript获取input的个数，然后一个循环，将所有input合并，并且给到一个“hidden”的input里，在后台接收这个input就可以了。","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/categories/软件工程/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/tags/软件工程/"}]},{"title":"Git学习小结","slug":"use_git","date":"2016-10-21T07:50:24.000Z","updated":"2018-02-09T10:46:20.940Z","comments":true,"path":"posts/5850713f/","link":"","permalink":"http://meng.uno/posts/5850713f/","excerpt":"","text":"¶从Git官方教程出发 进入git教程官网我们可以发现，主要从这几个方面来讲解的（几乎所有你能搜到的博客都是这么一成不变！）： ¶建立项目 init clone ¶基本操作 add status diff commit reset rm mv ¶分支管理 branch checkout merge mergetool log stash tag ¶分享与更新 fetch pull push remote submodule 看到这里，我们基本的git学习就可以结束了，要问为什么我只写标题而不写内容，我只想说，我写这篇博客只是为了通过自己写一遍命令来复习一遍而已。😝","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/categories/软件工程/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/tags/软件工程/"}]},{"title":"E-mail小爬虫","slug":"ruby_email_crawler","date":"2016-10-10T06:18:08.000Z","updated":"2018-02-11T14:12:34.629Z","comments":true,"path":"posts/5d4e2c71/","link":"","permalink":"http://meng.uno/posts/5d4e2c71/","excerpt":"","text":"Ruby据说是一个比Python还要简洁还要快速的编程语言 ：） 好吧，这里并不是要挑起编程语言之间的战争，每个语言都有自己适应的场景，作为程序员应该知道在什么样的应用场景之下，用哪种的语言来实现业务逻辑，才是最重要的。 这次，我们使用Ruby来获取网页上的e-mail地址。 不知道各位有没有在成堆的垃圾邮件中，寻找某宝密码重置的邮件，简直是杯具…… 我们总是小心翼翼的保护着我们的邮箱，但还是被别有用心的人知道；e-mail爬虫就是这些人的工具之一，它可以在某个网页上过滤出一个个的e-mail，然后发送垃圾邮件。 “加密”你的email地址，防止爬虫收集 当然，我们抱着学习的心态，来了解它的基本结构，揭开它神秘的面纱。 代码下载： git clone http://git.shiyanlou.com/shiyanlou/email_spider ¶准备工作 实验楼已经提供了Ruby运行环境，但是，还是需要我们安装一些插件： 将gem下载源换为国内源 请确保只有ruby.taobao.org 12345 $ gem sources --remove http://rubygems.org/$ gem sources -a http://mirrors.aliyuncs.com/rubygems/$ gem sources -l**CURRENT SOURCES **http://mirrors.aliyuncs.com/rubygems/ 安装Ruby爬虫库 anemone 1234 $ sudo apt-get update$ sudo apt-get install ruby1.9.1-dev$ sudo apt-get install libsqlite3-dev$ sudo gem install anemone 查看对应的数据库支持 Ruby数据库支持 12 sudo gem install data_mappersudo gem install dm-sqlite-adapter ¶数据库设计 我们使用sqlite3来放置我们扒下来的数据： Site：存储爬行过的网站 Page：存储爬行过的存在email地址的页面的URL Address：email地址 我们只讲解其中一个表的model，其他更深入的请看： data_mapper property详解 Page模型需要include模块DataMapper::Resource，引入相应的方法，其中就包括了property，belongs_to，has n，validates_presence_of，这些我们马上需要用到的方法。 property：定义了对象的属性（表的字段类型），Serial是自增ID，并且是主键。 belongs_to： 定义了一对多的关系，一个网站可能包含了多个网页URL has n：定义多对多的关系，一个网页上可能包含多个email地址，一个email可能同时存在多个网页上。 validates_presence_of：检查 url是否存在。 data_mapper validates详解 ¶爬虫代码 首先，我们需要引入uri 和 anemone包，其次还需要刚才定义的数据库的model 1234567 require 'uri'require 'anemone'require_relative 'data'data是对data.rb文件的引用。ARGV：获取命令行参数ruby crawl.rb http://www.test.test ARGV是Ruby的数组，所以我们用循环来处理它，因为我可以输入不只一个URL，如果，我们使用多线程的话，这样就可以同一时间处理多个URL，事半功倍。 然后马上使用URI()来处理传入的URL，结果返回给uri，下一步就把这个结果存入数据库中，uri.host网站的域名，和当前时间(这里使用的是内置模块Time) URI模块。 接下来的事情就很写意了，我们不需要自己去做很多的比如什么广度和深度算法的设计，我们只需要给它一个入口的URL，它会自动的去爬行，根本停不下来啊！ 使用模块Anemone的方法crawl创建一个新的爬虫，参数就传一个我们想爬行的URL就OK了！ Storage.PStore用来缓存新扒下来的网页代码，on_every_page处理每个页面，正则去匹配email，该页面的所有email会被包装在一个数组里面，然后循环这个数组并将结果存放数据库。 Anemone爬虫模块 if判断将会去查询address表，如果这个数据存在就更新，不存在则创建。 Datamapper更删查改详解 最后，将得到的E-mail地址输出到屏幕，又接着下一次循环，你要是不想等了，直接Ctrl+c吧 ：）","categories":[{"name":"Ruby","slug":"Ruby","permalink":"http://meng.uno/categories/Ruby/"},{"name":"爬虫","slug":"Ruby/爬虫","permalink":"http://meng.uno/categories/Ruby/爬虫/"},{"name":"E-mail","slug":"Ruby/爬虫/E-mail","permalink":"http://meng.uno/categories/Ruby/爬虫/E-mail/"}],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://meng.uno/tags/爬虫/"},{"name":"E-mail","slug":"E-mail","permalink":"http://meng.uno/tags/E-mail/"},{"name":"Ruby","slug":"Ruby","permalink":"http://meng.uno/tags/Ruby/"}]},{"title":"我的Java+Struts2+MySQL配置","slug":"profile_javaweb","date":"2016-10-07T11:18:54.000Z","updated":"2018-02-09T10:46:20.933Z","comments":true,"path":"posts/61cdd944/","link":"","permalink":"http://meng.uno/posts/61cdd944/","excerpt":"","text":"¶在Eclipse中配置Struts2 为了配置Struts2，首先我明确了，配置其所需要的各个部分的文件，我的理解是，一个web.xml(配置监听器)、一个struts.xml(配置“action”)、导入必要的jar包，现将配置好的文件结构截图展示如下： 其中，web.xml与struts.xml具体内容将在以后篇幅具体展开！ ¶在Eclipse中配置MySQL 通过对该实验的理解，我发现eclipse配置数据库，并不是针对某一个项目，而是针对整个集成开发环境，所以，相应地配置MySQL也是整个IDE的事，在软件的总配置中，如下图所示位置： 此为我成功地加入了MySQL之后的界面，如果没有加入，需要点击右侧的“Add…”进行添加，如下图： 由于我添加的是最新的MySQL 5.1，所以在具体的项目中，我也需要导入相应版本的jar包，用来加载MySQL驱动： 添加的具体方法是将本地的此jar文件拖动到“WebContent-&gt;WEB-INF-&gt;lib”文件夹下，然后右键，将其添加到“Build Path”。 ¶在Eclipse中配置Tomcat Tomcat是一个开源的web应用服务器，与MySQL一样，它也是对整个集成开发环境而言的，所以关于其的配置，也在eclipse的设置中，已经配置好的环境如下： 如果是第一次配置，仍然需要点击右侧的“Add…”来选择你要安装的版本： 再下一步就是要选择安装的tomcat的地址与安装名称了： 点击结束，就会自动安装好，每次对着web项目点击右键，在“Run As”选项下，第一个，就是：Run On Server，即在tomcat上运行该程序。 至此，开发环境已经完全搭建好了，接下来就是实际的开发过程了!","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/categories/软件工程/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/tags/软件工程/"}]},{"title":"软工实验二回顾","slug":"lab2_se","date":"2016-10-06T12:42:57.000Z","updated":"2018-02-09T10:46:20.927Z","comments":true,"path":"posts/5353b854/","link":"","permalink":"http://meng.uno/posts/5353b854/","excerpt":"","text":"到现在为止，实验二基本上接近尾声了，今天发现了好几个特别坑的地方，现在乘着兴致，我将其总结如下： ¶SAE的坑 首先，我想发表一下关于我们《软件工程》课所要用的SaaS平台——SAE的唾弃： 特别贵 特别不人性 错误特别多 …… ¶怎么应对SAE的坑 ¶关于数据库的选择 我之前用的是“共享型”的，后来一直不成功，怎么都连不上（还不报错）！于是，我换成“独享型”还是没什么改变！！！在再三排查之后，发现原来是一个比较简单的又比较不注意的地方，而且网上还没有相关教程！！！ 原来， 我们本地的MySQL是不区分大小写的，而SAE上的MySQL大小写敏感！！ ¶连上数据库之后 在刚才的惊喜之后，又有了另一个问题，就是：原来SAE上传之后需要相对路径，不能使用我原来使用的绝对路径！ ¶关于中文 基本上在编写每一个页面时都会遇到关于中文的问题。 ¶数据库插入中文 如果没有声明，默认情况下好像MySQL不是utf-8的编码，所以我将MySQL数据库地址后加入?useUnicode=true&amp;characterEncoding=utf8，就解决了这个问题。 ¶网页传输遇到中文 我将一个页面的中文传递到另一个页面，发现在另一个页面接收时，其为空或者乱码，很乱的那种！后来，经过查询，我将“s”添加上，例如&lt;s:from&gt;…… 暂时只想到这么多啦！！","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/categories/软件工程/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/tags/软件工程/"}]},{"title":"软工实验一要点回顾","slug":"lab1_se","date":"2016-09-28T10:57:29.000Z","updated":"2018-02-09T10:46:20.926Z","comments":true,"path":"posts/9ba24af6/","link":"","permalink":"http://meng.uno/posts/9ba24af6/","excerpt":"","text":"距离实验一结束已经有一段时间了，之所以选择在现在这个时候写这篇回顾，是想考验一下，是否真的像老师说的那样： “变量名没有特殊意义的话，过段时间就看不懂了！” 虽然没有到那种程度，但是确实：养成一个好的起变量名的习惯，是非常非常重要的！ 这一次再看以前的代码，觉得有几点比较好的地方： ¶方法较清晰 我们组在一开始规划的时候，就将这次实验“藐视”了，以至于我们只能使用一开始想好的强大的数据结构：数组！！！ 我们几乎把每种数组都用了一遍，也算是锻炼我们Java结构化编程基础了吧！我们 用String数组存放以“+/-”分割下来的多项式的每一项； 用Int数组存放每一项的符号； 用Char数组存放原始的输入串的每一个字符——以删掉多余的空格…… 总之，Java基本的元素，我们淋漓尽致地用上了！！ ¶安排较合理 我们没有将这次实验当做什么大的项目来做，反而是想“投机取巧”。 怎么个巧呢？待我一点点招来： 首先，我们在基本功能保障的情况下，写好了化简以及简化、求导等主要功能； 然后，当我想要添加功能时，我觉得我可以不用改动已经写好的功能，而仅仅将输入做处理，做成我们需要的样子！！ 是不是很机智！ 于是，在我们后来的拓展中，我们仅仅以一个for循环就实现一个功能的神速，比较简单地完成了这次实验。 ¶后记 这是我使用Java写的第一个项目，有很多东西没法用的那么熟练，例如：每次分割字符串，我们都是用“substring+for循环”来实现。 后来，我终于发现我为什么没法用 split了，原来在使用它的时候，参数如果是符号，就要加“\\”，对，是两个“\\”，这样才行。 也算是通过实验掌握的一个Java小知识吧！！","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/categories/软件工程/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/tags/软件工程/"}]},{"title":"一次数学建模经历","slug":"cumum2016","date":"2016-09-12T04:25:49.000Z","updated":"2018-02-09T10:46:20.920Z","comments":true,"path":"posts/832e4a48/","link":"","permalink":"http://meng.uno/posts/832e4a48/","excerpt":"","text":"经过三个白天，一个黑夜的战斗，我们终于如期赶出我们的数学建模论文。我将链接附加于此，希望大家帮忙指正。版权所有，请勿抄袭。 https://mega.nz/#!PMliSAbb!6hoWFHJEI3W3M0Exn6edmbhhl2CGdZa7XRom-KjktVI 结果：省一 三天日记 ¶第一天 看看现在的时间，竞赛第一天就这么过去了。然而到现在为止，我们什么都没做！！ ¶为什么会这样？ 我觉得，最主要的原因，应该是我们组自己的问题——从来没有实际模拟过！就在开赛的前几天，我们还在为平时的课而发愁。 还有就是，我们的选题，虽然我学过一年的交通，但是在这道题上，我还是显得手足无措，丝毫没有思路，当初我们之所以选这道题是因为我们觉得第一题可能不太适合我们非数学系的人做，这么看来，第二题不适合 我们非工程学生做啊233。 ¶我的想法 虽然有这么多的困难，但是我觉得我还是很有信心的，毕竟这次竞赛意义非比寻常！ 虽然有那么多的不适合，但是还是有很努力的小伙伴们一起！ ¶立个Flag 我们一定做好这次建模！ ¶第二天 我们或许还是太年轻，太没有经验，昨天大好时光居然就那么浪费了，谁知道今天依旧没有什么头绪。还 有10分钟就明天了，可是到现在我们连一个模型都没建好，连第一题都没有写出来。虽说第一次，失败了也没有关系，但是如果还有时间可以努力，但是已经宣布你失败了，谁会甘心！ 我们从早上8点到正心去合作讨论，一直到刚才不久，才回到寝楼的自习室，继续我们的”创举“，只能用充实来形容这一天天的生活。 不过，大学生嘛，总得在大学期间有所追求，有所疯狂，眼看着已经大三，这应该是我们这组人唯一一次参加的数学建模了。时间不多也不少，还有一半！ 看着对面的两个队友都在认真地查阅着文献，而我却在这写博客，着实有点不好意思，不过还好，马上就结束了，希望我能在接下来的一半时间里，认真投入，也预祝我们对在这次比赛中取得好成绩！ ¶第三天 本来昨天才应该是第三天，可是我觉得加上这11个小时，第三天才算完整！ 说实话，前两天我们真的没做出什么像样的东西来，连第二题都没有写完，连模型都没有建起来，但是最后一天往往就是转机！ 第三天如往常一样来临，这一次我们起的一个比一个晚，总是听到周围同学不想做了的豪情壮语，我们也有点想要放弃了呢。 但我们没一个人敢先提“放弃”，就这样我们仅仅抱着想把这次竞赛打完的想法，一点点凑着我们丝毫没有连贯性的论文。 夜，很快就来了，我们都感到疲倦。 最终只有我和赵正宇坚持熬夜来做，我们避开楼管大叔，来到正心楼8楼，准确地说是822教室，教室里随处可见考研教材和英语资料。 我们选了最后一排，继续我们的创作，本来丝毫没有连贯性的一篇一万多字的“杂文”，居然在我们不到三个小时的时间里将它完全驯服妥帖。 我们本来都在暗自高兴，也就聊到了其他的一些事情，可能没有这次竞赛，不会和这位老乡这么亲切，也不会体验到真正的努力是什么滋味！ 乘着兴致，我很快又做完了平时需要几个小时才能完成的评优评奖答辩PPT。 这是天已经亮了，哈尔滨远没有家乡那么热闹，一切都还在睡梦中。 我们迫不及待地一遍遍保存、转换格式、阅读……确保没有什么错误了，我们又急切地准备提交了。这一切简直不敢相信，只能说太佩服自己了！ 今天早晨，吃了这学期第一次早餐，最饱的一次早餐……","categories":[{"name":"数学建模","slug":"数学建模","permalink":"http://meng.uno/categories/数学建模/"}],"tags":[{"name":"数学建模","slug":"数学建模","permalink":"http://meng.uno/tags/数学建模/"}]}]}