{"meta":{"title":"欢迎来到匡盟盟的博客！","subtitle":"Colyn 崛起正当时！","description":"Mengmeng Kuang's Blog!","author":"匡盟盟","url":"http://meng.uno"},"pages":[{"title":"关于我","date":"2018-02-11T06:17:40.354Z","updated":"2018-02-11T06:17:40.334Z","comments":true,"path":"about/index.html","permalink":"http://meng.uno/about/index.html","excerpt":"","text":""},{"title":"分类","date":"2018-02-11T06:17:12.750Z","updated":"2018-02-11T06:17:12.723Z","comments":true,"path":"categories/index.html","permalink":"http://meng.uno/categories/index.html","excerpt":"","text":""},{"title":"留言板","date":"2018-02-11T06:17:58.309Z","updated":"2018-02-11T06:17:58.301Z","comments":true,"path":"comments/index.html","permalink":"http://meng.uno/comments/index.html","excerpt":"","text":""},{"title":"标签云","date":"2018-02-11T06:17:27.163Z","updated":"2018-02-11T06:17:27.143Z","comments":true,"path":"tags/index.html","permalink":"http://meng.uno/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"What are Human Genome Project and ENCODE Project?","slug":"genome","date":"2018-02-18T11:54:31.000Z","updated":"2018-02-18T13:25:50.293Z","comments":true,"path":"posts/32469d52/","link":"","permalink":"http://meng.uno/posts/32469d52/","excerpt":"","text":"Human Genome Project The Profile of the Project 人类基因组计划(Human Genome Project,简称HGP)是由美国科学家于1985年率先提出，又于1990年正式启动的。来自美国、英国、法国、德国、日本和中国科学家共同参与了这一预算达30亿美元的人类基因组计划。按照这个计划的设想，在2005年，要把人体内约10万个基因的密码全部解开，同时绘制出人类基因的谱图。换句话说，就是要揭开组成人体4万个基因的30亿个碱基对的秘密。 这一计划的最终目的是测定人类基因组30亿个基本化学组成（称为碱基对或核苷酸），进而揭开与人类的生老病死有关的数万个基因的相互关系。1984年，美国能源部开会，开始酝酿“人类基因组计划”。1989年，美国能源部和美国国家卫生研究所提出了人类基因图谱工程。美国在1990年10月1日率先启动人类基因组计划。美国人类基因组顾问委员会委员梅纳德•奥尔森是人类基因组计划最早的推动者之一，另外美国一个测序中心的主任罗伯特•沃特斯顿以及英国的人类基因组总负责人均表示支持。美国完成人类基因组计划近54%的工作量，为人类基因组计划最大的贡献国。英国是人类基因组计划的第二大贡献国，共34%的贡献都是由Wellcome基金会资助的Sanger中心完成的。日本、法国、德国对人类基因组计划的贡献分别为6.8%、2.8%与2.2%。中国承担了3号染色体区域短臂端粒侧约30 cM，约占人类整个基因组1% 的测序工作。中国的华大基因、国家自然科学基金会、中科院遗传所南方基因中心、北方人类基因组中心等单位及于军、杨焕明、汪建、刘斯奇、吴旻、强伯勤、陈竺等也给予人类基因组计划大力的推动。 The Importance of the Project 目的 人类是在“进化”历程上最高级的生物，对人类基因的研究有助于认识自身、掌握生老病死规律、疾病的诊断和治疗、了解生命的起源。 测出人类基因组DNA的30亿个碱基对的序列，发现所有人类基因，找出它们在染色体上的位置，破译人类全部遗传信息。 在人类基因组计划中，还包括对五种生物基因组的研究：大肠杆菌、酵母、线虫、果蝇和小鼠，称之为人类的五种“模式生物”。 HGP的目的是解码生命、了解生命的起源、了解生命体生长发育的规律、认识种属之间和个体之间存在差异的起因、认识疾病产生的机制以及长寿与衰老等生命现象、为疾病的诊治提供科学依据。 意义 人类基因组计划是一项规模宏大，跨国跨学科的科学探索工程。其宗旨在于测定组成人类染色体(指单倍体)中所包含的30亿个碱基对组成的核苷酸序列，从而绘制人类基因组图谱，并且辨识其载有的基因及其序列，达到破译人类遗传信息的最终目的。基因组计划是人类为了探索自身的奥秘所迈出的重要一步。 “人类基因组计划”与”曼哈顿原子弹计划”和”阿波罗计划”并称为二十世纪三大科学计划。 The Achievement of the Project 2000年6月26日，美国总统克林顿与英国首相布莱尔共同宣布人类基因组计划工作草图完成；次年2月，工作草图的具体序列信息、测序所采用的方法以及序列的分析结果被国际人类基因组测序联盟和塞雷拉基因组的科学家分别公开发表于《自然》与《科学》杂志。这一工作草图覆盖了基因组序列的83％，包括常染色质区域的90％（带有150,000个空缺，且许多片断的顺序和方位并没有得到确定）。 2001年2月12日，美国Celera公司与人类基因组计划分别在《科学》和《自然》杂志上公布了人类基因组精细图谱及其初步分析结果。 2003年，发现了新的方法通过检测另外的库来关闭Gaps。使用FISH技术或其他方法来分析没有闭合的Gaps大小。22，21条染色体就是用这种方式。 1999年至2006年，完成了全部23条染色体的测序工作，具体如下： 1999年12月，22号染色体测序完成； 2000年5月，21号染色体测序完成； 2001年12月，20号染色体测序完成； 2003年2月，14号染色体测序完成； 2003年6月，男性特有的Y染色体测序完成； 2003年5月和7月，7号染色体测序完成； 2003年10月，6号染色体测序完成； 2004年4月，13号和19号染色体测序完成； 2004年5月，9号和10号染色体测序完成； 2004年9月，5号染色体测序完成； 2004年12月，16号染色体测序完成； 2005年3月，X染色体测序完成； 2005年4月，2号和4号染色体测序完成； 2005年9月，18号染色体测序完成； 2006年1月，8号染色体测序完成； 2006年3月，11号,12号和15号染色体测序完成； 2006年4月，17号和3号染色体测序完成；Human Genome Project Information 2006年5月，1号染色体测序完成；Human Genome Project Information 2004年，国际人类基因组测序联盟的研究者宣布，人类基因组中所含基因的预计数目从先前的30,000至40,000（在计划初期的预计数目则高达2,000,000）调整为20,000至25,000。预期还需要多年的时间来确定人类基因组中所含基因的精确数目。 截止到2005年，人类基因组计划的测序工作已经完成。 The Research Contents of the Project 遗传图谱 遗传图谱又称连锁图谱（linkage map），它是以具有遗传多态性（在一个遗传位点上具有一个以上的等位基因，在群体中的出现频率皆高于1%）的遗传标记为“路标”，以遗传学距离（在减数分裂事件中两个位点之间进行交换、重组的百分率，1%的重组率称为1cM）为图距的基因组图。遗传图谱的建立为基因识别和完成基因定位创造了条件。意义：6000多个遗传标记已经能够把人的基因组分成6000多个区域，使得连锁分析法可以找到某一致病的或表现型的基因与某一标记邻近（紧密连锁）的证据，这样可把这一基因定位于这一已知区域，再对基因进行分离和研究。对于疾病而言，找基因和分析基因是个关键。 物理图谱 物理图谱是指有关构成基因组的全部基因的排列和间距的信息，它是通过对构成基因组的DNA分子进行测定而绘制的。绘制物理图谱的目的是把有关基因的遗传信息及其在每条染色体上的相对位置线性而系统地排列出来。DNA物理图谱是指DNA链的限制性酶切片段的排列顺序，即酶切片段在DNA链上的定位。因限制性内切酶在DNA链上的切口是以特异序列为基础的，核苷酸序列不同的DNA，经酶切后就会产生不同长度的DNA片段，由此而构成独特的酶切图谱。因此，DNA物理图谱是DNA分子结构的特征之一。DNA是很大的分子，由限制酶产生的用于测序反应的DNA片段只是其中的极小部分，这些片段在DNA链中所处的位置关系是应该首先解决的问题，故DNA物理图谱是顺序测定的基础，也可理解为指导DNA测序的蓝图。广义地说，DNA测序从物理图谱制作开始，它是测序工作的第一步。制作DNA物理图谱的方法有多种，这里选择一种常用的简便方法──标记片段的部分酶解法，来说明图谱制作原理。 序列图谱 随着遗传图谱和物理图谱的完成，测序就成为重中之重的工作。DNA序列分析技术是一个包括制备DNA片段化及碱基分析、DNA信息翻译的多阶段的过程。通过测序得到基因组的序列图谱。 基因图谱 简介 基因图谱是在识别基因组所包含的蛋白质编码序列的基础上绘制的结合有关基因序列、位置及表达模式等信息的图谱。在人类基因组中鉴别出占具2%~5%长度的全部基因的位置、结构与功能，最主要的方法是通过基因的表达产物mRNA反追到染色体的位置。 意义 它能有效地反应在正常或受控条件中表达的全基因的时空图。通过这张图可以了解某一基因在不同时间不同组织、不同水平的表达；也可以了解一种组织中不同时间、不同基因中不同水平的表达，还可以了解某一特定时间、不同组织中的不同基因不同水平的表达。人类基因组是一个国际合作项目：表征人类基因组，选择的模式生物的DNA测序和作图，发展基因组研究的新技术，完善人类基因组研究涉及的伦理、法律和社会问题，培训能利用HGP发展起来的这些技术和资源进行生物学研究的科学家，促进人类健康。 The Contributions of the Project 对人类疾病的贡献 人类疾病相关的基因是人类基因组中结构和功能完整性至关重要的信息。对于单基因病，采用“定位克隆”和“定位候选克隆”的全新思路，导致了亨廷顿氏舞蹈症、遗传性结肠癌和乳腺癌等一大批单基因遗传病致病基因的发现，为这些疾病的基因诊断和基因治疗奠定了基础。对于心血管疾病、肿瘤、糖尿病、神经精神类疾病（老年性痴呆、精神分裂症）、自身免疫性疾病等多基因疾病是疾病基因研究的重点。健康相关研究是HGP的重要组成部分，1997年相继提出：“肿瘤基因组解剖计划”“环境基因组学计划”。 对医学的贡献 基因诊断、基因治疗和基于基因组知识的治疗、基于基因组信息的疾病预防、疾病易感基因的识别、风险人群生活方式、环境因子的干预。 对生物技术的贡献 基因工程药物 分泌蛋白（多肽激素，生长因子，趋化因子，凝血和抗凝血因子等）及其受体。 诊断和研究试剂 基因和抗体试剂盒、诊断和研究用生物芯片、疾病和筛药模型。 细胞工程 胚胎和成年期干细胞、克隆技术、器官再造技术。 The Project with China 作为继美、英、法、德、日6个成员国之后中唯一的发展中国家，中国对人类基因组的的贡献不只是工作量，在这个划时代的里程碑上，已经刻上了中国人的名字，中国在生物组学的发展上占有一席之地，通过参与这一计划，我们可以分享数据、资源、技术与发言权，最终来开发我国自己的基因资源。中国的加入改变了国际人类基因组计划原有的组织格局，提高其国际合作的形象，带来了国际社会对“国际人类基因组计划精神”的支持，联合国教科文组织关于人类基因组基本信息免费共享的声明，就是在中国代表的直接努力下促成的。可以说，中国需要人类基因组计划，而基因组计划也使我国的基因测序能力进人世界前列，在中国本土成长起来的作为我国基因组学的典型代表、创新型机构——华大基因已经成为全球最大的基因组学中心。 因此，人类基因组计划对华大基因的影响力也是举足轻重的，华大基因也因此而“生”的伟大。华大基因随着“国际人类基因组计划1%项目”的正式启动而诞生。华大基因自成立之日起就站在世界同步的轨迹上，使得中国的基因组学研究位于跟踪——参与——同步的国际地位。为后期的华大基因在基因组上的引领及跨越式发展奠定了基础。 在人类基因组计划之后，人类基因研究开始朝着与人类生育健康、肿瘤个体化治疗、病原微生物、遗传性疾病、血液病等的相关疾病的基因检测方向发展，未来，医疗技术将从末端的疾病治疗，逐步走向前端的基因诊断和预防，个性化医疗及精准医疗。人类将通过基因检测技术、通过个性化医疗以更精确的诊断，预测潜在疾病的风险，提供更有效、更有针对性的治疗，预防某种疾病的发生，比“治有病”更节约治疗成本。 华大基因希望凭借全球领先的基因组学技术，华大基因将千万家庭远离遗传性出生缺陷，肿瘤能早期检测和诊断并能全景式、定期监控个人健康动态，人人做到“我的基因我知道，我的健康我做主”。其研究方向主要涉及遗传性出生缺陷、肿瘤、心脑血管疾病、精准医疗 # The ENCODE Project The Profile of the Project The ENCODE Project（即Encyclopedia Of DNA Elements，中文译作DNA元件百科全书计划），是美国国立人类基因组研究院（US National Human Genome Research Institute，NHGRI）在2003年9月启动的跨国研究项目。该项目旨在解析人类基因组中的所有功能性元件，它是人类基因组计划完成之后，又一重要的跨国基因组学研究项目。该项目联合了来自美国，英国，西班牙，新加坡和日本的32个实验室的422名科学家的努力，获得了迄今最详细的人类基因组分析数据（他们获得并分析了超过15兆兆字节的原始数据）。研究花费了约300年的计算机时间，对147个组织类型进行了分析，以确定哪些能打开和关闭特定的基因，以及不同类型细胞之间的“开关”存在什么差异。 The Achievement of the Project 近年来基因研究已经取得巨大进展。不过，迄今为止，这些研究主要还集中在编码蛋白的特定基因上，而它们所佔的比例不到整个人类基因组的2%。ENCODE计划首次系统地研究了所有类型的功能元件的位点和组织方式。 迄今为止，ENCODE计划主要集中研究了44个靶标共3000万个DNA硷基对。负责该计划数据整合和分析工作的欧洲分子生物学实验室主任Ewan Birney说：“我们的结论揭示了有关DNA功能元件构成的重要原理，为从DNA转录到哺乳动物进化的一切过程提供了新的认识。” 研究发现，人类基因组中的大多数DNA都会转录成RNA，这些副本会普遍交叠。因此，人类基因组实际上是一个非常复杂的网络，所谓的无用基因实际上非常少。基因只不过是众多具有特定功能的DNA序列类型之一。科学家们在基因之外的调控区域新发现了4491个转录启动位点，这一数字超过了已知基因的10倍。这些都挑战了长期以来的一个观点，即基因组中的基因是孤立的，同时，新的发现也支持了人类基因数量应该超过3万个的看法。 ENCODE计划的另一个巨大成就就是对哺乳动物基因组进化的认识。传统理论认为，与生理功能相关的重要DNA序列往往位于基因组中的“进化限制”区域，它们在物种进化过程中更容易保存下来。但是，最新的研究表明，大约一半人类基因组中的功能元件在进化过程中不会受到很大限制。科学家认为，哺乳动物缺乏“进化限制”这一点，很可能意味著许多物种的基因组都囊括了大量包括RNA转录副本在内的功能元件，在进化过程中，这些功能元件成了基因“仓库”。 此次ENCODE计划的成果亮点还包括：确定了许多之前不为人知的DNA转录启动位点；推翻了传统观点的认识，调控区域也有可能位于DNA转录启动位点的下游；确定了组蛋白变化的特定标记；加深了人们对组蛋白改变协调DNA复制的理解。 2012年9月5日，ENCODE项目的阶段性研究结果被整理成30篇论文发表于《自然》（6篇），《基因组研究》（6篇）和《基因组生物学》（18篇）上。 研究结果显示，人类基因组内的非编码DNA至少80%是有生物活性的，而并非之前认为的“垃圾” DNA （junk DNA）。这些新的发现有望帮助研究人员理解基因受到控制的途径，以及澄清某些疾病的遗传学风险因子。 ENCODE是人类基因组计划之后国际科学界在基因组学研究领域取得的又一重大进展。 2012年12月21日，ENCODE项目被《科学》杂志评为本年度十大科学突破之一。 The Research Contents of the Project 试点研究的内容 对编码的功能DNA进行鉴定和分类；对已存在的几种方法进行测试和比较，严格分析了人类基因组序列中已被定义的序列。 阐明人类生物学和疾病之间的关系。 对大量鉴定基因特征的方法、技术和手段进行检测和评估。 研究对象 编码蛋白基因 非编码蛋白基因 调控区域 染色体结构维持和调节染色体复制能力的DNA元件 研究特点 采用综合性研究策略 重视新技术的研发 将计划向学术界和公司开放 The Contributions of the Project 人细胞转录全景图 通过ENCODE项目，人们知道RNA是基因组编码的遗传信息的直接输出。细胞的大部分调节功能都集中在RNA的合成、加工和运输、修饰和翻译之中。研究人员证实，75%的人基因组能够发生转录，并且观察到几乎所有当前已标注的RNA和上千个之前未标注的RNA的表达范围与水平、定位、加工命运、调节区和修饰。总之，这些观察结果表明人们需要重新定义基因的概念。 人基因组中可访问的染色质全景图 DNase I超敏感位点(DNase I hypersensitive sites, DHSs)是调节性DNA序列的标记物。研究人员通过对125个不同的细胞和组织类型进行全基因组谱分析而鉴定出大约290万个人DHSs，并且首次大范围地绘制出人DHSs图谱。 基因启动子的远距离相互作用全景图 在ENCODE项目中，研究人员选择1%的基因组作为项目试点区域，并且利用染色体构象捕获碳拷贝(chromosome conformation capture carbon copy, 简称为5C)技术来综合性地分析了这个区域中转录起始位点和远端序列元件之间的相互作用。他们获得GM12878、K562和HeLa-S3细胞的5C图谱。在每个细胞系，他们发现启动子和远端序列元件之间存在1000多个远距离相互作用。 GENCODE：ENCODE项目的人基因组参照标注 GENCODE项目旨在利用计算分析、人工标注和实验验证来鉴定出人基因组中所有的基因特征。GENCODE第七版(GENCODE v7)公开发布了基因组标注数据集，包含了20687个蛋白编码的RNA基因座位、9640个长链非编码RNA基因座位，并且拥有33977个在UCSC基因数据库和RefSeq数据库中不存在的编码性转录本。它还对公开获得的长链非编码RNA(long noncoding RNA, lncRNA)进行最全面的标注。 我的认识 在上这门课之前，我从没认真想过这个问题，到底研究基因有什么用？通过这几天的学习，以及对文章所提的两个项目的检索、认识，我对基因测序这一工作，有了更深层次的认识。 虽然外界关于基因测序有不同的看法，例如有人支持，因为它可以为医学做贡献；有人反对，因为这样做相当于为基因做了一次曝光，这样一来，就有优劣基因之分。在我看来，这一任务还是利大于弊的，毕竟现在看来是这样。科学家可以通过对已有的基因测序结果的分析，总结出基因的“中心法则”，使我们对自身有了更进一步的了解。再者，基因分析有很多好的应用，通过对胎儿基因分析可以达到优生的目的，以及对有基因缺陷、先天性遗传病患者可以提供治标治本的治疗方案。 当然，要了解所有基因的功能还有很长的一段路要走。例如以前人们所认为的垃圾DNA实际上并不“垃圾”，它们在基因组的进化、每个个体的差异性以及许多其他方面扮演着重要角色，是世界上许多实验室着力研究的目标。 即使已经过了将近30年，人类基因组也没有完成“完全”测序，不过我们了解到了基因并不是静态的，而是处在复杂的变化之中，所以对人类基因的研究也是对人类自身的研究，这一研究将会一直进行下去，永无终点。 虽然人类基因组目前也只是一张初步的蓝图，需要经过更多的研究和分析。但是人类已经通过对基因组的学习，进入了医学的新纪元，为预防、诊断和治疗疾病带来了新的方法。所以对基因组的研究势必将成为人类新的曙光。 总之，我对基因组计划以及ENCODE计划充满期待与支持。 参考资料 HGP计划百度百科：http://dwz.cn/3ITVf3 人类基因组计划- 维基百科http://dwz.cn/3JHOap 科学松鼠会之人类基因组计划 http://dwz.cn/3JHOXZ ENCODE项目百度百科：http://dwz.cn/3ITSPr Genome网 https://www.genome.gov/10005107/encode-project ENCODE项目官网：https://www.encodeproject.org “DNA元件百科全书”首批成果出炉，链接：http://big5.cas.cn/xw/kjsm/gjdt/200706/t20070619_1011212.shtml","categories":[{"name":"生物信息","slug":"生物信息","permalink":"http://meng.uno/categories/生物信息/"}],"tags":[{"name":"生物信息","slug":"生物信息","permalink":"http://meng.uno/tags/生物信息/"},{"name":"Genome","slug":"Genome","permalink":"http://meng.uno/tags/Genome/"},{"name":"ENCODE","slug":"ENCODE","permalink":"http://meng.uno/tags/ENCODE/"}]},{"title":"关于比特币（Bitcoin）","slug":"bitcoins","date":"2018-02-14T11:47:44.000Z","updated":"2018-02-14T12:14:20.810Z","comments":true,"path":"posts/7bfe1542/","link":"","permalink":"http://meng.uno/posts/7bfe1542/","excerpt":"","text":"比特币术语 比特币 首字母大写的Bitcoin用来表示比特币的概念或整个比特币网络本身。例如：“今天我学了些有关Bitcoin协议的内容。” 而没有大写的bitcoin则表示一个记账单位。例如：“我今天转出了10个bitcoin。”该单位通常也简写为BTC或XBT。 比特币地址 比特币地址就像一个物理地址或者电子邮件地址。这是别人付给你比特币时你唯一需要提供的信息。然而一个重要的区别是，每个地址应该只用于单笔交易。 对等式网络 对等式网络是指，通过允许单个节点与其他节点直接交互，从而实现整个系统像有组织的集体一样运作的系统 。对于比特币来说，比特币网络以这样一种方式构建——每个用户都在传播其他用户的交易。而且重要的是，不需要银行作为第三方。 哈希率 哈希率是衡量比特币网络处理能力的测量单位。为保证安全，比特币网络必须进行大量的数学运算。当网络达到10Th/秒的哈希率时，就意味着它能够进行每秒10万亿次的计算。 交易确认 交易确认意味着一笔交易已经被网络处理且不太可能被撤销。当交易被包含进一个块时会收到一个确认，后续的每一个块都对应一个确认。对于小金额交易单个确认便可视为安全，然而对于比如1000美元的大金额交易，等待6个以上的确认比较合理。每一个确认都成指数级地降低交易撤销的风险。 块链 块链是一个按时间顺序排列的比特币交易公共记录。块链由所有比特币用户共享。它被用来验证比特币交易的永久性并防止双重消费。 密码学 密码学是数学的一个分支，它让我们创造出可以提供很高安全性的数学证明。电子商务和网上银行也用到了密码学。对于比特币来说，密码学用来保证任何人都不可能使用他人钱包里的资金，或者破坏块链。密码学也用来给钱包加密，这样没有密码就用不了钱包。 签名 密码学签名是一个让人可以证明所有权的数学机制。对于比特币来说，一个比特币钱包和它的私钥通过一些数学魔法关联到一起。当你的比特币软件用对应的私钥为一笔交易签名，整个网络都能知道这个签名和已花费的比特币相匹配。但是，世界上没有人可以猜到你的私钥来窃取你辛苦赚来的比特币。 钱包 比特币钱包大致实体钱包在比特币网络中的等同物。钱包中实际上包含了你的私钥，可以让你消费块链中分配给钱包的比特币。和真正的钱包一样，每个比特币钱包都可以显示它所控制的所有比特币的总余额，并允许你将一定金额的比特币付给某人。这与商家进行扣款的信用卡不同。 区块 一个块是块链中的一条记录，包含并确认待处理的交易。平均约每10分钟就有一个包含交易的新块通过挖矿的方式添加到块链中。 双重消费 如果一个不怀好意的用户试图将比特币同时支付给两个不同的收款人，就被称为双重消费。比特币挖矿和块链将就两比交易中那笔获得确认并被视为有效在网络上达成一致。 私钥 私钥是一个证明你有权从一个特定的钱包消费比特币的保密数据块，是通过一个密码学签名来实现的 。如果你使用的是钱包软件，你的私钥就存储在你的计算机内；如果使用的是在线钱包，你的私钥就存储在远程服务器上。千万不能泄露私钥，因为它们可以让你消费对应比特币钱包里的比特币。 挖矿 比特币挖矿是利用计算机硬件为比特币网络做数学计算进行交易确认和提高安全性的过程。作为对他们服务的奖励，矿工可以得到他们所确认的交易中包含的手续费，以及新创建的比特币。挖矿是一个专业的、竞争激烈的市场，奖金按照完成的计算量分割。并非所有的比特币用户都挖矿，挖矿赚钱也并不容易。 Bit Bit是标明一个比特币的次级单位的常用单位 -1,000,000 bit 等于1 比特币 (BTC 或 B⃦).，这个单位对于标示小费、商品和服务价格更方便。 BTC BTC 是用于标示一个比特币 (B⃦). 的常用单位。 比特币账户 我们可以在bitcoin.org上选择自己的钱包。我在这里向大家展示使用一个浏览器插件GreenAddress，下载链接是：https://chrome.google.com/webstore/detail/greenaddress/dgbimgjoijjemhdamicmljbncacfndmp/related 注册 打开安装好的GreenAddress，没有账户点击右上角，开始注册。 打码的位置请保存下来，应该需要用它来登录 接着是验证你保存没保存（想的还很周到）。 再就是添加两步验证，这个比较常见了，我只选了“邮件”验证，推荐是选两个，要不然总是有warning。 使用 接着就进入主界面了，有很多配置需要大家自己去查看，主界面显示了你的“Bitcoin URI”，分享这个，别人就可以向你转钱了，应该。 最后强调一下，我的比特币地址是：3CEzyZnpij4WnrAsHhhcaoD1Kf5JqSAEGj","categories":[],"tags":[{"name":"比特币","slug":"比特币","permalink":"http://meng.uno/tags/比特币/"},{"name":"Bitcoin","slug":"Bitcoin","permalink":"http://meng.uno/tags/Bitcoin/"}]},{"title":"简单的Python3爬虫","slug":"crawl-py","date":"2018-02-12T12:18:15.000Z","updated":"2018-02-13T14:08:54.149Z","comments":true,"path":"posts/51d32f19/","link":"","permalink":"http://meng.uno/posts/51d32f19/","excerpt":"","text":"我们先从分析原理入手，然后再使用Python提供的基本的库urllib。 注意，我全程使用的是Python3，如果你必须使用不同版本，请自行百度某些库及函数的转换，需要使用的库不一定你的电脑上预装了，所以请自行百度安装。 原理 网络爬虫，也叫网络蜘蛛(Web Spider)，如果把互联网比喻成一个蜘蛛网，Spider就是一只在网上爬来爬去的蜘蛛。网络爬虫就是根据网页的地址来寻找网页的，也就是URL。 URL URL就是统一资源定位符(Uniform Resource Locator)，它的一般格式如下(带方括号[]的为可选项)： protocol ://hostname[:port]/path/[;parameters][?query]#fragment 可见，一个URL包含三个部分： protocol：协议，例如https，http等； hostname[:port]：主机名(端口号为可选参数)，一般网站默认的端口号为80，例如我的博客域名www.meng.uno，可以作为主机名使用; path：第三部分就是主机资源的具体地址，如目录和文件名等。 爬虫就是向URL发送请求，然后得到响应，基本就实现了爬取网页的功能。 URI可以分为URL,URN或同时具备locators 和names特性的一个东西。URN作用就好像一个人的名字，URL就像一个人的地址。换句话说：URN确定了东西的身份，URL提供了找到它的方式。 从浏览器发送和接收数据看起 进入我的首页www.meng.uno，打开浏览器的“检查”功能，选项卡选到“Network”，然后点击所有文章，随便选择一条，我们可以发现如下截图的&quot;Headers&quot; 我们可以发现最明显的有两个区域（我已经圈出来了）：“request”和“response”。从字面意思上来看，我们就知道分别是（发送的）请求和（收到的）回复。 接收的信息是我们请求的网页给的，不用我们管，但是“请求的网页”是我们需要提前设定的，当然最简单的方式就是什么都不设置。爬虫会增加网站的负荷，所以很多网站希望大家通过API的方式使用其开放的资源而禁止爬虫，其中的一个做法就是判断你的请求内容（不全的基本都是爬虫）。于是，为了做到一个完整的可用的爬虫，我们需要模拟真实用户的请求，这就要求我们伪造“User Agent”。 常见的“User Agent”列举如下： Android Mozilla/5.0 (Linux; Android 4.1.1; Nexus 7 Build/JRO03D) AppleWebKit/535.19 (KHTML, like Gecko) Chrome/18.0.1025.166 Safari/535.19 Mozilla/5.0 (Linux; U; Android 4.0.4; en-gb; GT-I9300 Build/IMM76D) AppleWebKit/534.30 (KHTML, like Gecko) Version/4.0 Mobile Safari/534.30 Mozilla/5.0 (Linux; U; Android 2.2; en-gb; GT-P1000 Build/FROYO) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1 Firefox Mozilla/5.0 (Windows NT 6.2; WOW64; rv:21.0) Gecko/20100101 Firefox/21.0 Mozilla/5.0 (Android; Mobile; rv:14.0) Gecko/14.0 Firefox/14.0 Google Chrome Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.94 Safari/537.36 Mozilla/5.0 (Linux; Android 4.0.4; Galaxy Nexus Build/IMM76B) AppleWebKit/535.19 (KHTML, like Gecko) Chrome/18.0.1025.133 Mobile Safari/535.19 iOS Mozilla/5.0 (iPad; CPU OS 5_0 like Mac OS X) AppleWebKit/534.46 (KHTML, like Gecko) Version/5.1 Mobile/9A334 Safari/7534.48.3 Mozilla/5.0 (iPod; U; CPU like Mac OS X; en) AppleWebKit/420.1 (KHTML, like Gecko) Version/3.0 Mobile/3A101a Safari/419.3 User Agent已经设置好了，但是还应该考虑一个问题，程序的运行速度是很快的，如果我们利用一个爬虫程序在网站爬取东西，一个固定IP的访问频率就会很高，这不符合人为操作的标准，因为人操作不可能在几ms内，进行如此频繁的访问。所以一些网站会设置一个IP访问频率的阈值，如果一个IP访问频率超过这个阈值，说明这个不是人在访问，而是一个爬虫程序。 一个很简单的解决办法就是设置延时，但是这显然不符合爬虫快速爬取信息的目的，所以另一种更好的方法就是使用IP代理。使用代理的步骤： 调用urlib.request.ProxyHandler()，proxies参数为一个字典； 创建Opener(类似于urlopen，这个代开方式是我们自己定制的)； 安装Opener； 这个网站提供了很多代理主机：http://www.xicidaili.com/ 正则表达式 我直接以表格的形式呈现好了： 元字符 说明 . 代表任意字符 [ ] 匹配内部的任一字符或子表达式 [^] 对字符集和取非 - 定义一个区间 \\ 对下一字符取非（通常是普通变特殊，特殊变普通） * 匹配前面的字符或者子表达式0次或多次 *? 惰性匹配上一个 + 匹配前一个字符或子表达式一次或多次 +? 惰性匹配上一个 ? 匹配前一个字符或子表达式0次或1次重复 {n} 匹配前一个字符或子表达式 {m,n} 匹配前一个字符或子表达式至少m次至多n次 {n,} 匹配前一个字符或者子表达式至少n次 {n,}? 前一个的惰性匹配 ^ 匹配字符串的开头 \\A 匹配字符串开头 $ 匹配字符串结束 [\\b] 退格字符 \\c 匹配一个控制字符 \\d 匹配任意数字 \\D 匹配数字以外的字符 \\t 匹配制表符 \\w 匹配任意数字字母下划线 \\W 不匹配数字字母下划线 代码 简单带错误信息的获取网页内所有URL的爬虫 1234567891011121314151617181920212223242526272829303132333435363738 #获取URL的包import urllib#获取字符集编码方式import chardet#正则表达式import re#Request 对象req = urllib.request.Request(\"http://meng.uno/\")data = Nonetry: #得到Response response = urllib.request.urlopen(req,data) #读出response == 请求文件的全部字符 html = response.read() #获取这个response的编码方式 charset = chardet.detect(html) print(\"编码方式：\",charset) #以这种编码方式解码打印 html = html.decode(charset.get(\"encoding\")) print(html) urls = re.findall('href=\\\"https*://w*\\.*meng\\.uno/.*?\\\"', html,re.S) uris = re.findall('href=\\\"/[^/].*?[^\\.]\\\"',html, re.S) for item in urls: print(item[6:-1]) for item in uris: if \".html\" in item: print(\"http://www.meng.uno\"+item[6:-1]) elif '.' in item: continue else: print(\"http://www.meng.uno\"+item[6:-1])except urllib.error.HTTPError as e: if hasattr(e, 'code'): print(\"HTTPError\") print(e.code) elif hasattr(e, 'reason'): print(\"URLError\") print(e.reason) 模拟真实环境的爬虫 12345678910111213141516171819 import urllib #访问网址url = 'http://www.whatismyip.com.tw/'#这是代理IPproxy = &#123;'https':'110.73.48.189:8123'&#125;#创建ProxyHandlerproxy_support = urllib.request.ProxyHandler(proxy)#创建Openeropener = urllib.request.build_opener(proxy_support)#添加User Angentopener.addheaders = [('User-Agent','Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36')]#安装OPenerurllib.request.install_opener(opener)#使用自己安装好的Openerresponse = urllib.request.urlopen(url)#读取相应信息并解码html = response.read().decode(\"utf-8\")#打印信息print(html) 通过队列获取网站所有URL的爬虫 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 #python系统关于队列的包import queue#获取URL的包import urllib#获取字符集编码方式import chardet#正则表达式import reinitial_page = \"http://www.meng.uno\"url_queue = queue.Queue()seen = set()seen.add(initial_page)url_queue.put(initial_page)def extract_urls(url): req = urllib.request.Request(url) #得到Response response = urllib.request.urlopen(req) #读出response == 请求文件的全部字符 html = response.read() #获取这个response的编码方式 charset = chardet.detect(html) #以这种编码方式解码打印 html = html.decode(charset.get(\"encoding\")) urls = re.findall('href=\\\"https*://w*\\.*meng\\.uno/.*?\\\"', html,re.S) uris = re.findall('href=\\\"/[^/].*?[^\\.]\\\"',html, re.S) tempseen = set() for item in urls: tempseen.add(item[6:-1]) for item in uris: if \".html\" in item: tempseen.add(\"http://www.meng.uno\"+item[6:-1]) elif '.' in item: continue else: tempseen.add(\"http://www.meng.uno\"+item[6:-1]) return tempseen while(True): #一直进行直到海枯石烂 if url_queue.qsize()&gt;0: current_url = url_queue.get() #拿出队例中第一个的url print(current_url) #把这个url代表的网页存储好 for next_url in extract_urls(current_url): #提取把这个url里链向的url if next_url not in seen: seen.add(next_url) url_queue.put(next_url) else: break 这里先简单解释，以后有实际项目会再补充！","categories":[{"name":"Python","slug":"Python","permalink":"http://meng.uno/categories/Python/"},{"name":"爬虫","slug":"Python/爬虫","permalink":"http://meng.uno/categories/Python/爬虫/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://meng.uno/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://meng.uno/tags/爬虫/"}]},{"title":"CPAchecker","slug":"cpachecker","date":"2018-02-11T14:08:59.000Z","updated":"2018-02-11T14:15:48.025Z","comments":true,"path":"posts/c5d9877c/","link":"","permalink":"http://meng.uno/posts/c5d9877c/","excerpt":"","text":"CPAchecker is a tool for configurable software verification which means expressing different program analysis and model checking approaches in one single formalism. The main algorithm is configurable to perform a reachability analysis on arbitrary combinations of existing configurable program analysis (CPA). One application of CPAchecker is the verification of Linux device drivers. CPA provides a conceptual basis for expressing different verification approaches in the same formal setting. The CPA formalism provides an interface for the definition of program analyses, which includes the abstract domain, the post operator, the merge operator, and the stop operator. Consequently, the corresponding tool implementation CPAchecker provides an implementation framework that allows the seamless integration of program analyses that are expressed in the CPA framework. The comparison of different approaches in the same experimental setting becomes easy and the experimental results will be more meaningful. Architecture The above picture is the overview of CPAchecker’s architecture. The central data structure is a set of control-flow automata (CFA), which consist of control-flow locations and control-flow edges. A location represents a program-counter value, and an edge represents a program operation, which is either an assume operation, an assignment block, a function call, or a function return. Before a program analysis starts, the input program is transformed into a syntax tree, and further into CFAs. The framework provides interfaces to SMT solvers and interpolation procedures, such that the CPA operators can be written in a concise and convenient way. From the picture, we know that they use MathSAT as an SMT solver, and CSIsat and MathSAT as interpolation procedures. They also use JavaBDD as a BDD package, and provide an interface to an Octagon Library as well. The CPA Algorithm is the center of this project and the detailed design is shown as follows. The CPA algorithm (shown at the top in the above figure) takes as input a set of control-flow automata (CFA) representing the program, and a CPA, which is in most cases a Composite CPA. The interfaces correspond one-to-one to the formal framework. The elements in the gray box (top right) represent the abstract interfaces of the CPA and the CPA operations. The two gray boxes at the bottom of the figure show two implementations of the interface CPA, one is a Composite CPA that can combine several other CPAs, and the other is a Leaf CPA. Build and Test Owing to the long development history, this project is very prefect which means you could use its binary directly, build from the source and even use their jar-ball in Java applications. To experience it, I will build it from the source and use it in the command-line. We need to install “jdk”, “ant”, “svn” and “subversion” before we build it. Then enter the root directory and run “ant”. Wait a moment and this is the result. To test this project, we need to write a C/C++ code without “#include &lt;headers&gt;”. I choose a simple one (QuickSort) shown in the attachment. The result contains a log file, a statistics file and a report which is in “html” format.","categories":[{"name":"Software Verification","slug":"Software-Verification","permalink":"http://meng.uno/categories/Software-Verification/"},{"name":"CPA","slug":"Software-Verification/CPA","permalink":"http://meng.uno/categories/Software-Verification/CPA/"},{"name":"CPAchecker","slug":"Software-Verification/CPA/CPAchecker","permalink":"http://meng.uno/categories/Software-Verification/CPA/CPAchecker/"}],"tags":[{"name":"CPA","slug":"CPA","permalink":"http://meng.uno/tags/CPA/"},{"name":"CPAchecker","slug":"CPAchecker","permalink":"http://meng.uno/tags/CPAchecker/"}]},{"title":"Linux Test Project","slug":"ltp","date":"2018-02-11T13:29:33.000Z","updated":"2018-02-11T14:04:49.151Z","comments":true,"path":"posts/bfb74f68/","link":"","permalink":"http://meng.uno/posts/bfb74f68/","excerpt":"","text":"I found this project from the references of other papers, and I thought it was good, so I plan to run it. As we can see from its name, Linux Test Project (LTP) has a goal to deliver test suites to the open source community that validate the reliability, robustness, and stability of Linux. This project wants to support Linux development by making unit testing more complete and minimizing user impact by building a barrier to keep bugs from making it to the user. There are two important testing techniques which are supported by giving developers an ever growing set of tools to help identify any operational problems in their code: Design and Code Inspections. I knew that Yggdrasil and Hyperkernel which I have run successfully belong to the last category. LTP doesn’t have a benchmark which means they don’t compare different kernel of Linux. In LTP, we need to know: Test case: A single action and verification which has a result PASS/FAIL. Test suite: Containing one or more test cases. Test tags: Pairing a unique identifier with a test program and a set of command line options. We also need to know the ways of reporting the results of a test case. There are two main ways which are contained in LTP: Exit status: If a test program encounters unexpected or incorrect results, exit the test program with a non-zero exit status, i.e. exit(1). Conversely, if a program completes as expected, return a zero exit status, i.e. exit(0). Standard output: Tools can be used to analyze the results, if they are written in a standard way. Build and Run To build this project, we need to run the following executions: 123456 $ git clone https://github.com/linux-test-project/ltp.git$ cd ltp$ make autotools$ ./configure$ make$ make install Before these, we need to ensure “git, autoconf, automake, m4” are installed. If not, we can use “apt-get” to get them. The output of “make” is shown as following. After building this project, let’s run it personally. If we want to run all the test suites, we just need run “./runltp” in the “opt/ltp/” directory. However, I will run a single test suite to verify this project only with “./runltp -f syscalls” execution. The picture above is the output of “abort01” test case. From it we can see that the test method is “Exit status test” and it passes all the situations. If a test case needs datafiles to work, these would be put in a subdirectory named datafilesand installed in the testcases/data/$TCID directory Analyze Test Cases We could find LTP in “/opt/ltp” and the test suites are installed in the “/opt/ltp/runtest/” directory. The following picture is a screenshot of it. In a single file, such as “syscalls” file, there exist many single test cases which are like the follows. From this picture, those words, like “abort01”, represent different test cases which are laid in “/opt/ltp/testcases/bin/” directory. Each test case is a binary written either in portable Shell or C such as “abort01” which is from “abort01.c” which lays in the “ltp/testcases/kernel/syscalls/abort” directory. The test gets a configuration via environment variables and/or command line parameters, it prints additional information into the stdout and reports overall success/failure via the exit value. Write A Test Suite To make things simple, I will use LTP standard interface, not add custom reporting functions and use LTP build system. The following are my steps (These steps are very simple, so I didn’t list any screenshot): Add a new file “meng” to “ltp/runtest/” directory; Write some test cases’ names, such as “abort01 accept01”; Run “make” and “make install”; Enter “/opt/ltp/” directory; Run “./runltp -f meng”; Get the result as the picture. (You can also find the full logs from “meng_output.txt” file in the attachment) Write A Test Case As I said before, we can use C language or Shell to write a test case, however, in this section, I will just use C language to write a simple one which may make me have a deep understanding of this project. I used the “man-pages” to find the untested system calls, however, my linux version maybe a little old (2015 release, version 16.04), so that I can’t find a untested one which is excluded by the newest LTP. I will write a test for verifying system call “file rename”. First, I create a new file “meng.c” in the “ltp/testcases/kernel/syscalls/meng/” directory. Then I need to write the codes. The next thing I need to do is to include “tst_test.h” (There are also another headers, however, this one is basic). We need to write “main(), setup(), clean()” functions and the detailed realizations are in the “meng.c” which is in the attachment (I give some notes of the code in the “meng.c” file as well). What’s more, we need to create a “Makefile” in the same directory and write the compiling information. The compiled file is like this. Last, I will add this test case to the “meng” test suite and see the result (You can find the full output in “meng_syscall_output.txt” in the attachment). From the above picture, we can see that the verification is “pass” which means that not only the “rename” system call is correct, but also my code is right.","categories":[{"name":"Linux","slug":"Linux","permalink":"http://meng.uno/categories/Linux/"},{"name":"Linux Test","slug":"Linux/Linux-Test","permalink":"http://meng.uno/categories/Linux/Linux-Test/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://meng.uno/tags/Linux/"},{"name":"Linux Test","slug":"Linux-Test","permalink":"http://meng.uno/tags/Linux-Test/"}]},{"title":"A Melody Composer for both Tonal and Non-Tonal Languages","slug":"paperreport-hkust-dm","date":"2018-02-11T04:03:24.000Z","updated":"2018-02-11T04:39:53.403Z","comments":true,"path":"posts/2251dcee/","link":"","permalink":"http://meng.uno/posts/2251dcee/","excerpt":"","text":"Summary Abstract This paper contains some improvements on an algorithmic melody composer called “T-music”. “T-music” is an algorithm which can compose a melody for users’ input lyrics by mining the relationship between the melodies and lyrics. These relationships are known as frequent patterns (FPS) . The ameliorations are two ways to enhance the methods of mining frequent patterns form instrumental compositions and an optimal way of using FPS mined from songs in one language to compose a melody for the input things in another language. Propse The propose is to get an algorithm which take lyrics as input and a good melody as outcome in order to help those people who have little music background to compose songs. In view of the fact that there is already a pretty well method, T-music, the authors’ tasks are making some improvements on the basis of the original algorithm. Deficiencies of original algorithm At the first place, I need to borrow a figure from the paper as follows to express my understanding of the original T-music method. As the picture shows that the system architecture of T-music can be divided as two phases which are “Frequent Pattern Mining” and “Melody Composition”. I will report this method following the flow of the algorithm. Mining the FPS from “Song Database” and storing them in the “Frequent Pattern Database”: Obtaining tone sequences from “Song Database” by reading the “Language Dictionary”; Generating s-sequence from a melody, a pitch sequence and a duration sequence; Mining the FPS from s-sequence; Storing the FPS to “Frequent Pattern Database”. Composing a melody for the “Lyrics” based on FPS in the “Frequent Pattern Database”: Obtaining the tone sequence of the lyrics by reading the “Language Dictionary”; Adding some “Music Parameters” such as some music rules; Generating “Melody” by the process “Melody Composition” using FPS. There are some deficiencies of the original T-music algorithm as follows. It can only mine FPS from songs in which lyrics must be present. What’s more, the original one can’t use the FPS mined from a language to compose melody in another language. However, we can’t always get the ideal songs data which have lyrics embedded easily. What we can get from the Internet are those instrumental compositions in which lyrics are absent. Also, we want to achieve that composing melody in a language with the FPS mined from another language which can make the algorithm more efficient. Improvements What the authors have done provided two ways to mine Frequent Patterns from instrumental compositions and an optimal mapping method for composing a melody using FPS in different language with the input lyrics. The first way is “Method emphasizing the original FPS”. I will use the following picture to express my comprehension. Firstly, mining the FPS from songs and storing them in “FP database (General)”. Secondly, mining the frequent pitch trends from “Instrumental compositions with style database” and storing them in “Frequent pitch trends (Style)” and then using it as a selector to select those FPS storing the matches in “FP database (Style)”. The second way is “Method emphasizing the newly mined frequent pitch trends”. I will also introduce it using the screenshot from the paper. The FPS based on those of the first way was subdivided. The frequent pitch trends are mined as usually. The most difference is that one pitch trend may match a set of several tone trends. The optimal mapping method is shown as follows. Firstly, using the same method gets a “FP database” in one language. Then, generating several tone sequences for each tone trend in this “FP database”. There are some lemmas proofed on the paper to decide the specific number of the mapping. Improvements In this section, I will analysis some excellent algorithms, important thoughts or some key points. Some of them may look small or nothing special, but each has its function. Using the “Trend” representation If I were doing this job, I could have chosen the simple “absolute” representation, just because this is the most intuitive frequent pattern we can get from songs. After careful consideration, just as the author explains that same melodies which start at different pitches may sound similar to us. Then, I understand that it is a big wisdom to use the “trend” representation which uses a FP to extract the general rules of a set of FPS with different pitches, simplifying a large number of calculations and making the result more obvious. Using “Frequent pitch trends (Style)” as a selector Though we know that “T-music” uses “the FPS between the tone port and the pitch part” and agree the mining method used on mining the frequent pattern which contains a tone trend and a pitch trend, there must be some correlation between “Tone trend” and “Pitch trend”. Since the instrumental compositions don’t contain lyrics, we couldn’t mine a whole frequent pattern from them. However, we can also mine part of the frequent pattern from them which is “Pitch trend”. For we have so much instrumental compositions which means we can get enough “Pitch trend” and we already know the correlation between “Tone trend” and “Pitch trend”, we can estimate the frequency of the original frequent pattern and eliminate part of them which have a zero frequency. Using the subsequences of original frequent pattern According to the Apriori property that all nonempty subsets of frequent item set must also be frequent, the authors artfully break the original FPS into smaller form and then making them combine more FPS which can be selected from the original FP database. By doing this, we can get more frequent patterns from the identical data which means our mining algorithm is more efficient. Using multi-map as a data structure This data structure allows the task of retrieving a value by a key quickly and returns more than one frequent pattern with a support. From it, we can get a tuple in top-k tuples with some selection strategies and ensure that a pattern with a very large support isn’t always selected because it doesn’t mean that it is always the best choice. Employing the divide and conquer idea Considering to compose a melody of a very long lyric, we may need to divide the original tone trend into several shorter tone trends, apply the same procedure on them and then return the concatenation of the results of the sub-problems. It is a simple idea of solving such problem, but we can't resist its correctness and effectiveness. Limitations I just list some areas that I think need improvements or I think it can be added slightly on the basis of the original research. Applying word segmentation Though the paper has mentioned the use of word segmentation, there is just a word and no detailed explanation. I think I should express my own idea here. Firstly, the word segmentation here isn’t the same of those applied in the fields of natural language processing (NLP). As we all known, the latter has so many strict norms to follow, however, in the lyrics, the norms aren’t very same. Why we do this in the input lyrics is because we want to determine the length of durations between every two words, which is different from the propose in the NLP which just wants to add pause at the same length of time between words and words. Handling the tone trend with a length of 1 In this paper, the authors just simply set the pitch trend to be the input tone trend where, I think, may need improvement. Firstly, we all know that “the tone trend with a length of 1” couldn’t appear individually. It is usually because we matched the tone sequences before it or after it. I think if we consider dividing the original sequence into overlapping parts using the similar idea of divide and conquer idea, the question may disappear. Mining the relationship between “tone trend” and “pitch trend” The authors just determine the relationship based on statistics in whether the original T-music method or the improved edition, store the regulars on a multi-map and when using the frequent pattern, the method just randomly selects a tuple from top-k tuples from the multi-map. Therefore, no matter which one we choose, it is just the original sequence in the FP-database. If there is a very large database which contains a large number of every frequent pattern, it may have a remarkable effect without complex computations. However, we can’t ensure it or we just want to improve our algorithm with little support of so many records. Let’s look at the following samples which has the form as same as those in the multi-map and assume that the same tone trend only has the three tuples. 123 &lt;1,1,2,2,1,0&gt; —&gt; (&lt;1,1,2,0,-1,-2&gt;, 10)&lt;1,1,2,2,1,0&gt; —&gt; (&lt;1,1,2,0,-2,-1&gt;, 9) &lt;1,1,2,2,1,0&gt; —&gt; (&lt;1,0,2,0,-2,-1&gt;, 5) As we can see, they have the same tone trend and different pitch trends with different values of a support. If we just use the method described in the paper, we may get the result of the 1st, the 2nd, or the 3rd. However, is it the best one? Maybe not, I think. I mean maybe &lt;1,1,2,0,-2,-1&gt; is better. I think we need to add some correlation analyses to the pitch trends which have the same tone trends. Expanding Research After reading this paper, I have some ideas for further research and some of them are listed as follows. Adding location variables I mean, as we all known, a same lyric may have different melodies when it is at the beginning or at the end of a song. Of course, if we just want to use a simple sentence as its input, this consideration is rather superfluous. However, if the input lyric is long enough, it is very important then. Generating a melody with a longer note This thought is mentioned in the end of the paper as well. We may have noticed that the normal notes will be longer than the syllables of lyrics, at least at the end of each sentence. We may need to modify the match method to add the frequent pattern which contains group of pitch trends sequences and its corresponding longer tone trends sequences. Applying syntactic analysis The following is my exploratory opinion of the original T-music. If I have many songs with lyrics, I will mine the frequent patterns of syntactic analysis and add them to the “s-sequence” mentioned in this paper. Thus I will reform the original multi-map as follows. 1 (&lt;pitch trend pattern&gt;, &lt;syntax pattern&gt;) —&gt; (&lt;tone trend pattern&gt;, support) When we match the input lyrics, we need to not only match the “pitch trend pattern” from the FP-database but also contrast the “syntax pattern” and then make the best decision. Expanding to speech recognization I have a simple idea of speech recognization using the same method mentioned in this paper. If I could collect enough voice information spoken by the same person, I would mine the frequent patterns of his intonation habit from the voice data and then using them to judge whether another voice is his or not. Expanding to password security In order to prevent the password being stolen, all websites are making efforts on password diversity. I think the method of mining frequent pattern can be applied to protect users’ password as well. For the same string of ciphers, different people may type it out in different speeds with different intermission on every two letters. I, for example, usually use the combination of my name and birthday as a password and when I type it out there is a longer break between the last letter of my name and the first number of my birthday. If we use the same way to mine the frequent patterns form enough times records of someone, we may use the frequent patterns to judge whether it is the right person or not who is typing the password. Generating “good problems” I often encounter some tricky programming problems and as we all known, “StackOverflow” is the biggest website which can offer you relevant solutions when you ask a question on it. However, we all want to get the best answer as soon as possible so we may need to put forward “good questions”. I think the thought of this paper can be applied to this question. We can first collect enough “good questions” from the website and then mine the syntactic frequent patterns of each question by categories. Finally, we can generate such “good questions” by adding the knowledge of sentence construction and providing some keywords needed. Related Research This paper is about mining frequent patterns which is a subfield of data mining. I will express my understanding mixing information retrieved from the Internet in this field. With the rise of big data, so many research topics about data is more and more frequent such as forecasting passenger flow and passenger flow directions during the Spring Festival and predicting the composition of Chinese college entrance examination this year. Data mining means the process of extracting valuable information and patterns from large amounts of data and these new discovery rules, patterns, information and concepts have potential value. It usually contains the association rules, classification, estimation, clustering and so on. As for association analysis, its propose is to discover interesting links hidden in large data sets and the patterns discovered are usually represented in association rules or frequent item sets just as this paper shown. There are several efficient and scalable frequent item set mining methods such as Apriori algorithm and FP-growth which needs to construct FP-tree. As for classification and prediction, I think it is a more stirring area. Think of this, a marketing manager needs data analysis to help guess whether or not a customer with a given profile will buy a new computer and then the marketing manager would like to predict how much a given customer will spend during a sale, what an attractive job!","categories":[{"name":"Paper Report","slug":"Paper-Report","permalink":"http://meng.uno/categories/Paper-Report/"},{"name":"Data mining","slug":"Paper-Report/Data-mining","permalink":"http://meng.uno/categories/Paper-Report/Data-mining/"}],"tags":[{"name":"Paper Report","slug":"Paper-Report","permalink":"http://meng.uno/tags/Paper-Report/"},{"name":"Data Mining","slug":"Data-Mining","permalink":"http://meng.uno/tags/Data-Mining/"}]},{"title":".length与length()的区别","slug":"2length","date":"2018-02-10T13:58:04.000Z","updated":"2018-02-10T14:52:50.489Z","comments":true,"path":"posts/61c2f1f1/","link":"","permalink":"http://meng.uno/posts/61c2f1f1/","excerpt":"","text":"当我们需要使用数组或者字符串长度时，习惯了使用IDE自动补全的我们是否知道.length与length()的区别喻原因呢？ 上面问题的答案是： 数组使用.length属性 字符串使用length()方法 下面我来回答原因。 为什么数组有.length属性？ 在Java中，数组是容器对象，其中包含了固定数量的同一类型的值，一旦数组创建，其长度就是固定的了，于是，其长度可以作为一个属性。 为什么字符串需要length()方法？ Java中的String，实际上是一个char类型数组，而char[]已经有了.length属性，所以在实现String时就没必要再定义重复的属性了，于是需要定义一个方法来返回其长度。","categories":[{"name":"Java开发Tips","slug":"Java开发Tips","permalink":"http://meng.uno/categories/Java开发Tips/"},{"name":"String","slug":"Java开发Tips/String","permalink":"http://meng.uno/categories/Java开发Tips/String/"},{"name":"Object","slug":"Java开发Tips/String/Object","permalink":"http://meng.uno/categories/Java开发Tips/String/Object/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://meng.uno/tags/Java/"}]},{"title":"Java异常结构层次图","slug":"java-exceptions-hierarchy","date":"2018-02-09T14:11:15.000Z","updated":"2018-02-10T14:51:35.021Z","comments":true,"path":"posts/1164dab2/","link":"","permalink":"http://meng.uno/posts/1164dab2/","excerpt":"","text":"在Java中，异常分为checked与unchecked，他们都在一个分类层次中，如下图。 其中，红色的异常是checked异常，意味着在一个方法中，他们throw后必须catch或者declare。 另一种颜色的为unchecked异常，他们的异常不需要被recover。","categories":[{"name":"Java开发Tips","slug":"Java开发Tips","permalink":"http://meng.uno/categories/Java开发Tips/"},{"name":"Exception","slug":"Java开发Tips/Exception","permalink":"http://meng.uno/categories/Java开发Tips/Exception/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://meng.uno/tags/Java/"},{"name":"Exception","slug":"Exception","permalink":"http://meng.uno/tags/Exception/"}]},{"title":"二分查找的效率","slug":"binsearch","date":"2018-02-08T09:20:00.000Z","updated":"2018-02-10T13:05:27.172Z","comments":true,"path":"posts/fff444e8/","link":"","permalink":"http://meng.uno/posts/fff444e8/","excerpt":"","text":"查找是比较常见的工作，今天我通过对比几种在数组中查找一个确定的值的例子来向大家展示二分查找的魅力。 数组查找元素的几种方法 使用List 123 public static boolean useList(String[] arr, String targetValue) &#123; return Arrays.asList(arr).contains(targetValue);&#125; 使用Set 1234 public static boolean useSet(String[] arr, String targetValue) &#123; Set&lt;String&gt; set = new HashSet&lt;String&gt;(Arrays.asList(arr)); return set.contains(targetValue);&#125; 使用for-loop 1234567 public static boolean useLoop(String[] arr, String targetValue) &#123; for(String s: arr)&#123; if(s.equals(targetValue)) return true; &#125; return false;&#125; 使用二分 1234567 public static boolean useArraysBinarySearch(String[] arr, String targetValue) &#123; int a = Arrays.binarySearch(arr, targetValue); if(a &gt; 0) return true; else return false;&#125; 时间复杂性 代码 使用如下代码来验证不同数据规模（5，1k，10k）的查找任务下四种方法的时间复杂性。（二分查找需要对数据排序，排序时间未计算在内。） 123456789101112131415161718192021222324252627282930 public static void main(String[] args) &#123; String[] arr = new String[] &#123; \"CD\", \"BC\", \"EF\", \"DE\", \"AB\"&#125;; //use list long startTime = System.nanoTime(); for (int i = 0; i &lt; 100000; i++) &#123; useList(arr, \"A\"); &#125; long endTime = System.nanoTime(); long duration = endTime - startTime; System.out.println(\"useList: \" + duration / 1000000); //use set startTime = System.nanoTime(); for (int i = 0; i &lt; 100000; i++) &#123; useSet(arr, \"A\"); &#125; endTime = System.nanoTime(); duration = endTime - startTime; System.out.println(\"useSet: \" + duration / 1000000); //use loop startTime = System.nanoTime(); for (int i = 0; i &lt; 100000; i++) &#123; useLoop(arr, \"A\"); &#125; endTime = System.nanoTime(); duration = endTime - startTime; System.out.println(\"useLoop: \" + duration / 1000000);&#125; &quot;5&quot;结果 123 useList: 13useSet: 72useLoop: 5 &quot;1k&quot;结果 随机生成数据 123456 String[] arr = new String[1000]; Random s = new Random();for(int i=0; i&lt; 1000; i++)&#123; arr[i] = String.valueOf(s.nextInt());&#125; 结果 1234 useList: 112useSet: 2055useLoop: 99useArrayBinary: 12 &quot;10k&quot;结果 1234 useList: 1590useSet: 23819useLoop: 1526useArrayBinary: 12 结论 通过以上结果，我们可以发现二分搜索确实很高效，而且当数据量变大时，其时间增长幅度还比较小。 以后，我们就可以使用Arrays.binarySearch()来高效查找某元素了。","categories":[{"name":"Java开发Tips","slug":"Java开发Tips","permalink":"http://meng.uno/categories/Java开发Tips/"},{"name":"Search","slug":"Java开发Tips/Search","permalink":"http://meng.uno/categories/Java开发Tips/Search/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://meng.uno/tags/Java/"},{"name":"算法复杂性","slug":"算法复杂性","permalink":"http://meng.uno/tags/算法复杂性/"},{"name":"二分查找","slug":"二分查找","permalink":"http://meng.uno/tags/二分查找/"}]},{"title":"Java Substring() 的实现","slug":"substring","date":"2018-02-08T07:43:08.000Z","updated":"2018-02-09T10:46:20.937Z","comments":true,"path":"posts/f3057e6c/","link":"","permalink":"http://meng.uno/posts/f3057e6c/","excerpt":"","text":"写过Java的人应该都用过substring(int bedinIndex, int endIndex)方法。我发现这个简单的方法在实现上居然经过了一次大的变革。 substring()的用途 代码: 123 String origin = \"asdfg\"; origin = origin.substring(1,3);System.out.println(origin); 输出: 1 sd 我们发现它能将原始字符串中从下标为beginIndex到endIndex-1之间的子串取出。那它是怎么实现的呢？ substring()的实现 Java中的字符串有三个域：char value[], int offset以及int count，它们分别存储字符串的值，起始下标与长度。 JDK6版本 在这个版本中，每次执行substring()方法时并不会新建新的string，仅仅只是将上述三个域中的offset，count做必要的修改。返回对象仍指向原来的数据。 这样一来，缺点就比较明显：当原始字符串比较长，而截取的子串比较短时，在后续的使用中就会浪费大量的空间。 JDK7+版本 在上一个版本基础上，这个方法进行了改进，每次使用这个方法都会新建一个string对象，并将其返回。","categories":[{"name":"Java开发Tips","slug":"Java开发Tips","permalink":"http://meng.uno/categories/Java开发Tips/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://meng.uno/tags/Java/"}]},{"title":"Java异常处理","slug":"java-exceptions-work","date":"2018-02-01T14:21:52.000Z","updated":"2018-02-10T14:51:35.019Z","comments":true,"path":"posts/7526d370/","link":"","permalink":"http://meng.uno/posts/7526d370/","excerpt":"","text":"在Java中，调用某方法，就必须处理被调用方法抛出的异常，同时超类也可以用来捕获或者处理子类异常。 调用方法必须处理被调用方法抛出的异常 下面是一个处理异常的程序。我们可以测试一下，如果在一个方法中抛出一个异常，不仅是该方法，而且所有调用该方法的方法都必须声明或抛出异常。 123456789101112131415 public class exceptionTest &#123; private static Exception exception; public static void main(String[] args) throws Exception &#123; callDoOne(); &#125; public static void doOne() throws Exception &#123; throw exception; &#125; public static void callDoOne() throws Exception &#123; doOne(); &#125;&#125; 超类可以用来捕获或处理子类异常 可以使用如下代码验证。 123456789101112131415161718192021 class myException extends Exception&#123; &#125; public class exceptionTest &#123; private static Exception exception; private static myException myexception; public static void main(String[] args) throws Exception &#123; callDoOne(); &#125; public static void doOne() throws myException &#123; throw myexception; &#125; public static void callDoOne() throws Exception &#123; doOne(); throw exception; &#125;&#125; 这也就是为什么catch子句只有一个父类在语法上安全的原因。","categories":[{"name":"Java开发Tips","slug":"Java开发Tips","permalink":"http://meng.uno/categories/Java开发Tips/"},{"name":"Exception","slug":"Java开发Tips/Exception","permalink":"http://meng.uno/categories/Java开发Tips/Exception/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://meng.uno/tags/Java/"},{"name":"Exception","slug":"Exception","permalink":"http://meng.uno/tags/Exception/"}]},{"title":"Analysis For Hyperkernel","slug":"hv6","date":"2018-01-29T13:43:03.000Z","updated":"2018-02-10T14:56:55.140Z","comments":true,"path":"posts/55c9299d/","link":"","permalink":"http://meng.uno/posts/55c9299d/","excerpt":"","text":"Homepage: https://locore.cs.washington.edu/hyperkernel/ Code: https://github.com/locore/hv6 State-machine Specification State-machine specification means the system function will first verify the old procedure until the procedure is runnable and then return a new procedure and write to the system image. All of these must run in the user level. This specification consists of two parts: a definition of abstract kernel state, and a definition of trap handlers (e.g., system calls) in terms of abstract state transitions. They use fully automated technique to find bugs and this method is full functional verification if program is free of loops and state is finite. The “hv6/hv6/spec/kernel/spec/specs.py” file contains the system calls which use this kind of specification. From the picture, we can see that they use Z3 to prove the correction of the “old” procedure and if it can transfer to a new state or it is runnable, it will return the new procedure so that it can be proved true. Declarative Specification The authors also provide a declarative specification of the high level properties that the state-machine specification should satisfy. The verifier will check that these high level properties are indeed satisfied, helping increase the programmer’s confidence in the correctness of the state-machine specification. To improve confidence in its correctness, there is a higher-level declarative specification to better capture programmer intuition about kernel behavior, in the form of a conjunction of crosscutting properties that hold across all trap handlers.","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://meng.uno/categories/操作系统/"},{"name":"系统验证","slug":"操作系统/系统验证","permalink":"http://meng.uno/categories/操作系统/系统验证/"}],"tags":[{"name":"System","slug":"System","permalink":"http://meng.uno/tags/System/"},{"name":"Verification","slug":"Verification","permalink":"http://meng.uno/tags/Verification/"}]},{"title":"怎么处理噪声","slug":"handle-noise","date":"2018-01-27T14:35:33.000Z","updated":"2018-02-17T02:10:40.282Z","comments":true,"path":"posts/a12d1477/","link":"","permalink":"http://meng.uno/posts/a12d1477/","excerpt":"","text":"处理噪声是一个在机器学习学习过程中，总会被问到的问题。噪声可以出现在输入X，亦可以出现在输出Y中。 X中缺失值 使用来自所有可用数据的特征的平均值 忽略实例 使用来自类似项目的平均值 使用另一个机器学习算法来预测值 Bagging 或者 Boosting","categories":[{"name":"AI","slug":"AI","permalink":"http://meng.uno/categories/AI/"},{"name":"机器学习","slug":"AI/机器学习","permalink":"http://meng.uno/categories/AI/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://meng.uno/tags/机器学习/"},{"name":"噪声","slug":"噪声","permalink":"http://meng.uno/tags/噪声/"}]},{"title":"Analysis for Yggdrasil","slug":"yggdrasil","date":"2018-01-16T14:31:00.000Z","updated":"2018-02-11T14:48:52.840Z","comments":true,"path":"posts/5ed9f695/","link":"","permalink":"http://meng.uno/posts/5ed9f695/","excerpt":"","text":"Yggdrasil is a toolkit for verifying file system with push-button verification via crash refinement. As for push-button verification, it means that Yggdrasil needs no manual annotations or proofs. As for crash refinement, it is amenable to fully automated SMT reasoning. The whole verification is something like the State-Machine Specification in the project “Hyperkernel”. The whole system architecture is shown as follows. From this picture, we know that Yggdrasil needs three inputs: a specification of the expected behavior, an implementation and consistency invariants which indicate whether a file system image is in a consistent state or not. For better run-time performance, Yggdrasil optionally performs optimizations. If there is a bug, Yggdrasil produces a counterexample to help identify and fix the cause. It requires no manual annotations or proofs about the implementation code. Once the verification passes, Yggdrasil emits C code, which is then compiled and linked using a C compiler to produce an executable file system, as well as a “fsck” checker. The above is the entire overall content of this project. The authors also introduced every part of this project. I will analyze it by following the paper. Single-level File System (YminLFS) In this project, every file system must contain three parts: an abstract data structure, a set of operations and a state equivalence predicate which defines whether a given implementation satisfies the specification. So the authors first defines a file system which contains these features. Then it runs the verification. Yggdrasil uses the Z3 solver to prove a two-part crash refinement. The first part deals with crash-free executions which requires the implementation and specification are similar in the absence of crashes, which means if both YminLFS and FSSpec start in equivalent and consistent states, they end up in equivalent and consistent states (just like state-machine). This project defines equivalence using the equivalent predicate and defines consistency using the consistency invariants as the above pictures show. The second part deals with crash executions which requires the implementation to exist no more crash states than the specification, which means each possible state of the YminLFS implementation must be equivalent to some crash state of FSSpec. What’s more, Yggdrasil provides a greedy optimizer that tries to remove every disk flush and re-verify the code. Multi-level File System (Yxv6) We could directly prove crash refinement between the entire file system specification and implementation in a single-level file system, however, we couldn’t use the same method in a complex multi-level file system. First, let’s look at the structure of Yxv6 journaling file system. This is the 5 layers of abstraction and every layer contains a specification and a implementation. The authors use this project to prove crash refinement for each layer and upper layers then use the specifications of lower layers. The lowest layer of the stack is a specification of an asynchronous disk. This specification comprises the asynchronous disk model which is to implement YminLFS. Application-level (“Ycp”) Ycp has a formal specification which means if the copy operation succeeds, the result is the same as “cp”, however, if it fails, the file system is unchanged. To achieve this propose, the implementation of Ycp is something similar to Yxv6 file system specification. There are 3 atomicity patterns which are “create a temporary file”, “write the source data to it” and “rename it to atomically create the target file”. After doing such an analogy, verifying this operation is similar to verify the single-level file system.","categories":[{"name":"System Verification","slug":"System-Verification","permalink":"http://meng.uno/categories/System-Verification/"},{"name":"Yggdrasil","slug":"System-Verification/Yggdrasil","permalink":"http://meng.uno/categories/System-Verification/Yggdrasil/"}],"tags":[{"name":"Yggdrasil","slug":"Yggdrasil","permalink":"http://meng.uno/tags/Yggdrasil/"},{"name":"System Verification","slug":"System-Verification","permalink":"http://meng.uno/tags/System-Verification/"}]},{"title":"KVM Unit Tests","slug":"kvm-unit-test","date":"2018-01-15T14:19:40.000Z","updated":"2018-02-11T14:48:52.840Z","comments":true,"path":"posts/50351d5d/","link":"","permalink":"http://meng.uno/posts/50351d5d/","excerpt":"","text":"Kernel-based Virtual Machine (KVM) is a virtualization infrastructure for the Linux kernel that turns it into a hypervisor. KVM requires a processor with hardware virtualization extensions. This project, as its name suggests, is to provide unit tests for KVM. The unit tests are tiny guest operating systems that generally execute only tens of lines of C and assembler test code in order to obtain its PASS/FAIL/SKIP result. Unit tests provide KVM and virtual hardware functional testing by targeting the features through minimal implementations of their use per the hardware specification. The simplicity of unit tests make them easy to verify they are correct, easy to maintain, and easy to use in timing measurements. Unit tests are also often used for quick and dirty bug reproducers. Build and Run Building this project is very easy, we just need to enter the directory and run “./configure; make”. If there isn’t any mistake, it means this project is successfully built. As can be seen from its name, it is a testing program so running it means running some tests on KVM. In addition, as other verification systems, it also has some single test cases and a whole test suite. What has to be aware is we need to install “kvm” or “qemu-kvm” before testing, otherwise, the tests will just “SKIP” because it is just for testing KVM. First, I will run a single test case which is in the “x86/” directory named “syscall.flat”. The result is as follows. Then, I will run a test suite. The following picture is part of the result. I found that there are 3 status of the test results which are PASS, FAIL and SKIP. From the picture, we can see that not all tests are PASS, which means this version of KVM may have many points to be improved. Analyze the Test To write a test case/suite, we first need to analyze an example. From the file “run_tests.sh”, we could find that it runs each test in “x86/unittests.cfg”. This is a section of this file. From it, we could know that when the test suite runs to here, it will find test case “apic.flat” and run it in the x86_64 architecture within 30 seconds. The result of every test case is printed to the screen by the “runtime.bash” script. What’s more, we could find the detailed information of every test case from “logs/” directory. After analyzing a test suite, let’s look at a single test case. I will choose the “syscall.flat” as an example. Let’s see the main function. There are two subfunctions which is consistent with the first screenshot. Now I will focus on a single function as the following picture shows. It just tests some single function calls and report the results. Write A Test Because I can’t know about KVM clearly for such a short period of time, here I just write a simple test, in order to experience how to write a test case. After compiling and running it, we could get this expected output. Now I could put my test case to the test suite, adding such code to the “unittests.cfg” file. Also, it must be PASS as expected. Analyze the Framework In the beginning, let’s analyze the directory structure. ./api/: there are three API categories 1) libc, 2) functions typical of kernel code, and 3) kvm-unit-tests specific. ./lib/: general architecture neutral services for the tests. ./x86/: the sources of the tests and the created images of X86 architecture. ./logs/: the output information. ./scripts/: helper scripts for building and running tests. others: configure script, top-level Makefile, and run_tests.sh. The framework has the following components: Test building support Shared code for test setup and API Test running support Test building is done through makefiles and some supporting bash scripts. Test setup code includes, for example, early system init, MMU enablement, and UART init. The API provides some common libc functions, as well as some low-level helper functions commonly seen in kernel code and some kvm-unit-tests specific APIs. Test running is provided with a few bash scripts, using a unit tests configuration file as input. Generally tests are run from within the source root directory using the supporting scripts, but tests may optionally be built as standalone tests as well.","categories":[{"name":"KVM","slug":"KVM","permalink":"http://meng.uno/categories/KVM/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"http://meng.uno/tags/KVM/"}]},{"title":"Analysis for DynamoRIO","slug":"rio","date":"2018-01-13T13:57:16.000Z","updated":"2018-02-11T14:04:49.152Z","comments":true,"path":"posts/a331aaad/","link":"","permalink":"http://meng.uno/posts/a331aaad/","excerpt":"","text":"DynamoRIO is a dynamic binary piling/translation platform. Through it, you can manipulate the running code of a program, that is, it can simulate running a program and allow you to transform and control any place of the running code. It is used for dynamic analysis, optimization and translation of programs. DynamoRIO is a cooperation project between HP and MIT. Dynamo comes from HP’s laboratory, RIO (Runtime Introspection and Optimization) comes from MIT’s computer science laboratory. The history is shown as follows. Architecture DynamoRIO’s architecture is like this. It is between the operating system and the application so that it can get the system calls and the applications’ code easily. This picture is the Toolchain Control Points. The process flow is as follows. The original program goes through the “basic block builder”, “trace selector”, “basic block cache” and “trace cache” to get the emulation propose. Efficiency DynamoRIO is separated from the code of applications by the “context switch” as shown in the picture above. The applications’ code is copied to the instruction cache. The code in these caches will execute as native code. Until a jump instruction is encountered, the applications’ “machine state” will be saved, and the control will turn back to DynamoRIO to find the basic block where the jump instruction is located. DynamoRIO is much faster than pure emulations by “code cache”. There are several improvements in this project. The picture above is the first one — Basic Block Cache. If you copy each basic block into a code cache and run it natively, it greatly reduces the overhead of interpreting, however, we still need to explain each jump instruction, and then return to DynamoRIO to find the target instruction. If a target instruction already exists in the code cache and is referred to by a direct jump instruction, DynamoRIO can directly jump to the target instruction in the code cache to avoid the overhead of the context switch, which is called “Linking Direct Branches”. The next improvement is “Linking Indirect Branches” since a conditional branch instruction can not be linked like a direct jump instruction because it has more than one goal and needs to make decisions and find the list’s jump target. Some basic blocks, which are often executed sequentially, are combined into one execution stream to reduce the number of branches and increase the locality of the program. It reduces some overhead of indirect branch search, because it has put indirect brach in this trace as well. This is also the last improvement — Trace Building. Transparency It has three transparency principles which are “As few changes as possible”, “Hide necessary changes” and “Separate resources”. Changes in these areas are few: application code, stored addresses, threads and application data. Changes in these fields are hidden: application addresses, address space, error transparency and code cache consistency. This picture shows the principle 3 well. DynamoRIO's own code also uses share libraries when loading applications, which may cause some conflicts if the application also uses the same library. The solution is that, DynamoRIO doesn’t use the library directly, calling system call on Linux and calling system call via windows win32 API profile. The heap memory allocated by DynamoRIO itself is distinguished from the heap memory requested by the application. In addition, DynamoRIO uses its own I/O routines for input and output to avoid conflicts with the applications’ I/O buffers. What’s more, since the use of shared locks can also cause conflicts between DynamoRIO and applications, it also has synchronization transparency. To avoid conflicts with applications, DynamoRIO doesn’t create its own thread, instead spawns threads in the application process to distinguish between its own status and applications’ status via a “Context Switch” as the first picture shows. Further more, it chooses to leave the stack of application processes intact, creating a private stack of each thread. Comprehensive All data streams must go through handlers generated by the dispatcher. The data flow is like this. Customization DynamoRIO has developed some event driven APIs that allow developers to customize instrument instructions. Using it, you can achieve some proposes such as: memory checking, performance testing, system call tracking, code coverage calculation.","categories":[{"name":"RIO","slug":"RIO","permalink":"http://meng.uno/categories/RIO/"},{"name":"DynamoRIO","slug":"RIO/DynamoRIO","permalink":"http://meng.uno/categories/RIO/DynamoRIO/"}],"tags":[{"name":"DynamoRIO","slug":"DynamoRIO","permalink":"http://meng.uno/tags/DynamoRIO/"},{"name":"RIO","slug":"RIO","permalink":"http://meng.uno/tags/RIO/"}]},{"title":"Zsh","slug":"zsh","date":"2018-01-11T02:22:44.000Z","updated":"2018-02-11T03:08:26.198Z","comments":true,"path":"posts/d911b12b/","link":"","permalink":"http://meng.uno/posts/d911b12b/","excerpt":"","text":"不少程序员都觉得Mac的一大优势就是其Shell，也有很多人觉得Mac与Linux在Shell上很相似。不错，但是Mac还是略胜一筹或者说高一个量级。今天，我将向大家介绍一个Mac特有的Shell（Linux也可以安装，但是不是系统自带。）—— Zsh。 切换到Zsh 使用cat /etc/shells指令，我们可以看看自己的系统有哪些Shells，下面是我的Mac的结果： 1234567 /bin/bash/bin/csh/bin/ksh/bin/sh/bin/tcsh/bin/zsh/usr/local/bin/fish 使用这个指令切换到Zsh：chsh -s /bin/zsh。（想使用其他Shell也是同样的指令哦。） 这是，我们的Shell配置文件就为.zshrc了。 我觉得从这里我们应该可以知道，为什么之前的Shell配置文件要以.bash_profile命名了吧。因为Mac默认Shell是Bash。 迁移Bash配置 我使用Bash有好几年了，那些配置都是一些环境变量啊什么的，如果在Zsh的配置里再写一遍，无疑是一件很费时又低效的事。那有没有什么快捷的方式呢？当然有！ 通过如下指令：source ~/.bash_profile就可以将.bash_profile里的配置全部引入到.zshrc中了。同理，如果你想自己写配置，也可以通过这种方式引入。（后文你将看到一个第三方工具就是这么做的。） 安装oh my zsh 通过wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh指令安装。 这时我们发现在.zshrc文件中，多了两行： 12 export ZSH=/Users/NAME/.oh-my-zshsource $ZSH/oh-my-zsh.sh 自定义Shell主题 使用oh my zsh主要的原因是使用其提供的漂亮的主题，主题目录在.oh-my-zsh/themes/下，选择主题ZSH_THEME=&quot;robbyrussell&quot;。这时我的Shell主题就是robbyrussell了。 打开robbyrussell.zsh-theme文件，我们可以看见几条配置。 我将其中的PROMPT修改为： PROMPT='${ret_status} %{$fg[cyan]%}%d %{$reset_color%} $(git_prompt_info)%{$fg_bold[red]%}&gt;%{$fg_bold[yellow]%}&gt;%{$fg_bold[green]%}&gt; ' 这时我的Shell就变成了这样： 可以发现我的定制有：显示绝对路径，&gt;&gt;&gt;等。 还有很多主题与配置，大家可以自己尝试。 定制Shell Zsh还有个功能就是“别名”。不知道大家有没有这样的经历，需要打开.plist这样的文件，如果用普通编辑器打开会非常界面不友好，而用Xcode打开则完美可观。那怎么在控制台直接用Xcode打开文件呢？（其他软件同理） 我在.zshrc中添加：alias xcode=&quot;/Applications/Xcode.app/Contents/MacOS/Xcode&quot;，之后我就可以使用xcode X来用Xcode打开X文件了。 我们也可以为某种类型文件设置默认打开方式：alias -s html=atom（当我们键入.html文件时，会自动用Atom打开）。 安装插件 oh my zsh为Zsh提供了100+插件，如果我们需要安装某插件，只需要在.zshrc文件中的plugins=()中添加，用空格隔开，只需要填插件名字，默认添加了git。 在这里我向大家介绍几种网上很常见的插件： git当你处于一个 git 受控的目录下时，Shell 会明确显示 「git」和 branch，如上图所示，另外对 git 很多命令进行了简化，例如 gco=’git checkout’、gd=’git diff’、gst=’git status’、g=’git’等等，熟练使用可以大大减少 git 的命令长度，命令内容可以参考~/.oh-my-zsh/plugins/git/git.plugin.zsh。 osxtab 增强，quick-look filename 可以直接预览文件，man-preview grep 可以生成 grep手册 的pdf 版本等。 autojump像他的名字一样，提供自动补全等很多功能，大家自己去尝试吧。 注意：安装autojump建议使用Homebrew brew install autojump 然后按照提示将一句类似这个 [ -f /usr/local/etc/profile.d/autojump.sh ] &amp;&amp; . /usr/local/etc/profile.d/autojump.sh 的句子插入到.zshrc文件中即可。","categories":[{"name":"Shells","slug":"Shells","permalink":"http://meng.uno/categories/Shells/"}],"tags":[{"name":"Zsh","slug":"Zsh","permalink":"http://meng.uno/tags/Zsh/"}]},{"title":"Deep Learning上手工具","slug":"tools4DP","date":"2018-01-10T14:43:43.000Z","updated":"2018-02-17T02:11:39.642Z","comments":true,"path":"posts/99be2c50/","link":"","permalink":"http://meng.uno/posts/99be2c50/","excerpt":"","text":"现在Deep Learning太火了，以至于没有任何计算机基础的人都想使用它，那么对于新手，甚至连Python代码都写不好的DL爱好者，有什么上手工具么？选择合适的工具可以帮助学习更快，很巧的是，有很多不同的工具可供选择，下图列出了常用的工具。 谷歌开发的Tensorflow，微软的CNTK以及Theano都是为深度学习而开发的库，它们促进了使用GPU计算。他们并不难，但与Keras相比，他们仍然非常复杂。Keras只是使用底层深度学习库的界面。使用Keras就像玩乐高一样简单。我建议初学者从Keras开始，因为我们可以快速了解深度学习可以做些什么，并积极进行一些有趣的项目。","categories":[{"name":"AI","slug":"AI","permalink":"http://meng.uno/categories/AI/"},{"name":"Deep Learning","slug":"AI/Deep-Learning","permalink":"http://meng.uno/categories/AI/Deep-Learning/"}],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://meng.uno/tags/Deep-Learning/"}]},{"title":"CryptoMinisat","slug":"CryptoMinisat","date":"2018-01-10T13:50:36.000Z","updated":"2018-02-11T14:04:49.150Z","comments":true,"path":"posts/7d26fe8/","link":"","permalink":"http://meng.uno/posts/7d26fe8/","excerpt":"","text":"Inspired by other verification system projects, I want to further explore the means of verification they used such as SMT solver, SAT solver, Coq and so on. I'll start with this report from an advanced SAT solver — CryptoMinisat. (I have written a report about STP which is a SMT solver.) The Boolean Satisfiability Problem (SAT for short) is the problem of determining if there exists an interpretation that satisfies a given boolean formula. In other words, it asks whether the variables of a given boolean formula can be consistently replaced by the values TRUE or FALSE in such a way that the formula evaluates to TRUE. If this is the case, the formula is called satisfiable. Otherwise, the formula is unsatisfiable. SAT solvers have recently been enjoying a boom in the application front: more and more applications can and do make use of SAT solvers to accomplish tasks ranging from the fairly trivial to the very complex. The benefit of the incredible improvements in the design of efficient SAT solvers those recent years is now reaching our lives: The Intel Core7 processor for instance has been designed with the help of SAT technology, while the device drivers of Windows 7 are being certified thanks to an SMT solver (based on a SAT solver). Build and Test This is the 5th version of CryptoMinisat which means the install instruction is very prefect now. To build and test this project, all we have to do is following the instruction. Firstly, we need to install many dependencies. Then, it is very simple to build by “make”. The following is part of the output. Testing this project is very easy by the script written by the authors. Typing “make test” and waiting for a moment, we will get this output which means the tests are correct. Run This Project This is a very mature project which can be run from the terminal or used as a C++/Python library. In this report, I just choose the first way. As I said before, this project is a SAT solver which means it could find out the situations which fulfill the input or return error. The grammar is very simple just like this. The first line means this input has 2 variables and 4 clauses. Every line is a clause which is ended by “0”. Using the third line as an example, it says that 2 is TRUE and 3 is FALSE. I use this file as an input and run it in the terminal. The result is shown as follows. It means 1 is TRUE, 2 and 3 are FALSE is the only solution to this problem. This is another example and the result. It means there isn’t a solution to this problem. How It Works There are many improvements and techniques included in this project. It uses “Minisat” as its core and uses Gaussian Elimination on top-level. This is another part of its techniques. Variable elimination and replacement, strengthening and subsumption; Gate-based clause shortening and removal; No time or memory-outs on weird CNFs; Variable renumbering and variable number hiding. due to this, XOR clauses are cut and the added variables are always consistently displayed; Temporary results are stored in SQLite which supports high speed update; XOR recovery.","categories":[{"name":"solver","slug":"solver","permalink":"http://meng.uno/categories/solver/"},{"name":"SAT","slug":"solver/SAT","permalink":"http://meng.uno/categories/solver/SAT/"}],"tags":[{"name":"CryptoMinisat","slug":"CryptoMinisat","permalink":"http://meng.uno/tags/CryptoMinisat/"},{"name":"SAT","slug":"SAT","permalink":"http://meng.uno/tags/SAT/"},{"name":"solver","slug":"solver","permalink":"http://meng.uno/tags/solver/"}]},{"title":"Trinity","slug":"trinity","date":"2018-01-05T14:37:53.000Z","updated":"2018-02-11T14:48:52.839Z","comments":true,"path":"posts/664baed9/","link":"","permalink":"http://meng.uno/posts/664baed9/","excerpt":"","text":"As we all known, system call testing is very important to a system. System call fuzzers aren't a particularly new idea. A few projects began from the mid-2000s with the aim of bringing more sophistication to the fuzz-testing process. One of them, Scrashme, was started in 2006. Work on that project languished for a few years, and only picked up momentum starting in late 2010, when the authors began to devote significantly more time to its development. In December 2010, Scrashme was renamed to Trinity which is this project. Trinity is an intelligent system call fuzzer since it incorporates specific knowledge about each system call which is tested. Its thought is to reduce the time spent running &quot;useless&quot; tests, so reaching deeper into the tested code and increasing the chances of testing a more interesting case that may result in an unexpected error. Build and Run We can get the source code from GitHub, compile the code and invoke Trinity with a command line as simple as “./trinity”. Building this project is very simple, we just need to enter the directory and “./configure; make”. It's so simple that the authors didn't write it out. The result of a successful “make” is like this: Now let’s run it. I will test a system call “madvise” as an example. From the above picture, we can see that there are 384 32 bits system calls and 333 64 bits system calls tested in this project (not all in this test case). The log information of the main test process and its children processes are stored separately like this. This project also has many other test modes which I didn’t test here. Trinity has been rather successful at finding bugs if we fully test it. It said that the authors of this project had sometimes left systems running for hours or days in order to discover failures. Analyze the Test Here is the segment of the code of system call “madvise”. This is a structure definition, from which we can see Trinity has some understanding of the arguments for each system call. This is why it brings intelligence to its tests. The “.num_args” means that this system call need 3 parameters. These parameters are “arg1, arg2, arg3” whose names and types are defined as the picture shows. I found the architecture of Trinity from its website. From this picture, we know that the “trinity-main” process kicks off a number of child processes (It is 4 in this picture) that perform the system call tests. There is a shared memory region used to record various pieces of global information, such as open file descriptor numbers, total system calls performed, and number of system calls that succeeded and failed. The shared memory region also records various information about each of the child processes as the picture shown in the “Build and Run” section. The “trinity-watchdog” process ensures that the test system is still working correctly which is similar to the function of “Zookeeper” to “Hadoop”, I think. Write A Test First, we need to select a system call for testing. I choose “getcpu” system call here from “syscalls.h” file. (We need to delete the original test file because all system call listed in “syscalls.h” are tested.) Then I write a new file to “/trinity/syscalls/” directory named “meng.c” and the contents are as follows. The type of parameters can be found at “syscall.h” as follows. After compiling the file and running, here is part of the result. In the future, I may add some system calls which it didn’t test till now to this project. However, you can see that it is very difficult for us to really test a system call which we used everyday using this project because Trinity randomly invokes system calls currently and real programs demonstrate common patterns for making system calls.","categories":[{"name":"Fuzzer","slug":"Fuzzer","permalink":"http://meng.uno/categories/Fuzzer/"}],"tags":[{"name":"Trinity","slug":"Trinity","permalink":"http://meng.uno/tags/Trinity/"},{"name":"Fuzzer","slug":"Fuzzer","permalink":"http://meng.uno/tags/Fuzzer/"}]},{"title":"Boogie","slug":"boogie","date":"2018-01-03T14:43:12.000Z","updated":"2018-02-11T14:48:52.838Z","comments":true,"path":"posts/4f0a9591/","link":"","permalink":"http://meng.uno/posts/4f0a9591/","excerpt":"","text":"Boogie is an intermediate verification language (IVL), intended as a layer on which to build program verifiers for other languages. It is also the name of the verification tool that takes Boogie programs as input. It can accept the input of a Boogie program and generate verification conditions that are passed to an SMT solver such as Z3 used by my test. Build and Run Building this project is very simple, however, we may need to install many other tools such as “Mono” (I use a MacBook to build this project) and “NuGet”. The information of successfully building is like this. There are two kinds of verifications said by the authors: Driver tests and Unit tests, however, I couldn’t find the python script for the latter, so I just run the driver tests. Driver Tests In this kind of tests, we need to use “lit” and “OutputCheck”. We could run all the tests by “lit .”. The result is shown as follows. We also could run a single test by giving “lit” a specific folder or file. The picture is a test of a folder. Analyze the Test The picture is a function written by Boogie, from which we can see that the Boogie language is something like C language. In addition, in every Boogie file, every function is separated. If there are some errors occurred, there will be a “.expect” file outputted like this to tell us why they are wrong. Write A Test We can write a new file or just add our function to a existed file. The following is my test: This is the result: I plan to analyze this project deeply, however, its code is very old so it maybe a little difficult for me to do this. I just do these tests on this projects now. Maybe I will analyze the whole project some day. From this project, I can learn what is an intermediate verification language (IVL) and how it works. I found that there were many tools adapting this strategy, including the VCC and HAVOC verifiers for C and the verifiers for Dafny, Chalice, and Spec#.","categories":[{"name":"Language","slug":"Language","permalink":"http://meng.uno/categories/Language/"}],"tags":[{"name":"Boogie","slug":"Boogie","permalink":"http://meng.uno/tags/Boogie/"},{"name":"Language","slug":"Language","permalink":"http://meng.uno/tags/Language/"}]},{"title":"Simple Theorem Prover SMT solver","slug":"stp","date":"2018-01-03T13:42:58.000Z","updated":"2018-02-11T14:04:49.153Z","comments":true,"path":"posts/cd3afb7d/","link":"","permalink":"http://meng.uno/posts/cd3afb7d/","excerpt":"","text":"I found it could be generated as program analysis tools, theorem provers, automated bug finders and so on which means it is a very crucial research. STP is a constraint solver aimed at solving constraints of bit vectors and arrays. It can read CVC, SMT-LIB1 and SMT-LIB2 formats files. It also could be used by Python, SMT-LIBv2 and even C library. STP preprocesses the input through the application of mathematical and logical identities, and then eagerly translates constraints into a purely propositional logic formula that it feeds to an off-the-shelf SAT solver. STP views memory as untyped bytes. It provides only three data types: booleans, bitvectors, and arrays of bitvectors. A bitvector is an unsigned, fixed-length sequence of bits. For example, “0010” is a constant, 4-bit bitvector representing the constant 2. Build and Run We can build this project on Linux or Docker, however, you know, Google isn’t well supported in China, so I can’t use “repo” execution which needed by Docker. In this document, I will use a quick install. Firstly, we need to install many dependencies. Then, since STP uses “minisat” as its SAT solver by default, we need to install it first. It is very simple to do this by “cmake”. The following is part of the output. Then we could start to install STP (To get the code, we need to use “git clone” but not download it directly). This project depends on various external tools to do testing. Here we install “lit” and do some individual tests and use “GoogleTest” to write some unit tests. Analyze Individual Test An individual test is like this. In this screenshot, we can see that this file is judging “b = (c || b)” and “((c || b) = b) &lt; c &lt; b”. We could find that an individual test file may contain these components: “; line”: comments; “set-info”: set some configuration information for running this file; “declare-fun”: definite some functions and their return types; “assert”: like C lang, do some judgement; “exit”: return. Analyze Unit Test We can simply run unit test by giving “lit” the individual tests directory or run “make C-api-tests” to build the C-api tests as unit tests. The Cpp file is like this. From this picture, we can see that a C-api test contains many simple verifications. Analyze the Code Structure From the above picture, I give the following simple understandings to this project. “Interface”: Define a C interface to achieve the file ins and outs; “Sat”: Copy from “minisat” to call SAT solver. “AST”: Implement the abstract syntax tree for parsed solver inputs; “Util”: Store some header files for small tasks; “Printer”: Appoint some output formats; “Simplifier”: Simplify algorithms for AST; “Parser”: Store some parsers for the CVC, SMT-LIB1, SMT-LIB2 inputs; “STPManager”: Hold all components together.","categories":[{"name":"solver","slug":"solver","permalink":"http://meng.uno/categories/solver/"},{"name":"SMT","slug":"solver/SMT","permalink":"http://meng.uno/categories/solver/SMT/"}],"tags":[{"name":"solver","slug":"solver","permalink":"http://meng.uno/tags/solver/"},{"name":"STP","slug":"STP","permalink":"http://meng.uno/tags/STP/"},{"name":"SMT","slug":"SMT","permalink":"http://meng.uno/tags/SMT/"}]},{"title":"跨领域分词国内外研究现状","slug":"word-seg-history","date":"2017-12-22T12:15:00.000Z","updated":"2018-02-13T14:06:49.673Z","comments":true,"path":"posts/e38d3f1c/","link":"","permalink":"http://meng.uno/posts/e38d3f1c/","excerpt":"","text":"国内研究 国内研究中文分词的科研单位主要有：中科院、清华、北大、北京语言学院、东北大学、MSRA、IBM研究院以及哈工大等。 国内主要的成熟的分词系统：ICTCLAS（汉语词法分析系统）、海量信息、盘古分词、结巴分词、BosonNLP以及**哈工大语言云（LTP-Cloud）**等。 国内在中文分词算法的研究上进展颇丰，参与的科研机构也比较多，使用的方法也比较杂乱，从[1]—[19]可以看出。国内分词算法上的进展主要有：2005年，哈工大[13]在分词阶段以基于词的n-gram方法为核心。先将词按照词典初步切分，并从训练语料统计得到3-gram信息，动态规划计算哪条切分路径最优。但在命名实体识别、新词识别、消除分词歧义部分使用ME模型。2007年，赵海等人[19]研究了基于子串标注的分词算法，在Bakeoff-2005测试集上准确度较高。2009年，[3]利用一种基于N元语法的汉语自动分词系统, 将分词与标注结合起来, 用词性标注来参与评价分词结果。[34]提出了一种字词联合解码的分词方法，算法中使用了字、词信息，充分发挥由字构词识别未登录词的能力。2010年，[35]提出基于词边界分类的分词方法，该方法对字符之间的边界进行分类，判断是否为词的边界，从而达到分词目的。[36]将基于字的生成模型与基于字的判别模型进行联合。2014年，[29]对[28]的模型做了重要改进，引入了标签向量来更精细地刻画标签之间的转移关系，其改进程度类似于引入Markov特征到最大熵模型之中。2015年，为了更完整精细地对分词上下文建模，[30]提出了一种带有自适应门结构的递归神经网络(GRNN)抽取n-gram特征，其中的两种定制的门结构（重置门、更新门）被用来控制n-gram信息的融合和抽取。2016年，[31]将GRNN和LSTM联合起来使用。该模型中，先用双向LSTM提取上下文敏感的局部信息，然后在滑动窗口内将这些局部信息用带门结构的递归神经网络融合起来，最后用作标签分类的依据。[32]提出了一种基于转移的模型用于分词，并将传统的特征模版和神经网络自动提取的特征结合起来，在神经网络自动提取的特征和传统的离散特征的融合方法做了尝试。2017年，[33]通过简化网络结构，混合字词输入以及使用早期更新（early update）等收敛性更好的训练策略，设计了一个基于贪心搜索(greedy search)的快速分词系统。该算法与之前的深度学习算法相比不仅在速度上有了巨大提升，分词精度也得到了进一定提高。 在领域自适应方面相关研究比较少，2008年，[45]利用并发展针对单个汉字的构词能力和构词模式公式, 计算词的构词能力和词的构词模式, 并以此作为新词发现的规则, 对科技领域做了新词发现和新技术发现的实验。2012年，[41]通过将外部词典信息融入统计分词模型 (使用CRF 统计模型)来实现领域自适应性。在确定一个领域并给出这个领域的文献数据集合的前提下，[44]主要从这两个步骤进行新词发现：首先对特定领域的文献集合进行分词处理，在进行分词处理方面使用了基于统计的N-Gram方法，较为有效地找出了词典中所不存在地新词汇；第二个步骤为新的专业词汇的抽取，这是一个根据已有专业词汇来发现未知专业词汇的过程，目的从第一步中所产生的新的词汇中抽取出新的属于目标领域的专业词汇，在这个步骤中，使用了Apriori方法。2013年，[40]实现了基于生语料的领域自适应分词模型和双语引导的汉语分词，并提出融合多种分词结果的方法，通过构建格状(Lattice)结构并使用动态规划算法得到较佳汉语分词结果。2015年，[39]提出Active Learning与n-gram统计特征相结合，通过对目标领域文本与已有标注语料差异统计分析，选择含有最多未标记过得语言现象的小规模语料优先进行人工标注的方法，此法验证在科技文献上有所提高。[43]提出使用卡方统计 量以及边界熵提升未登录词的处理能力，并结合自学习和协同学习策略进一步改善字标注分词方法在领域适应性方面的性能。2016年，[42]提出一种条件随机场与领域词典相结合的方法提高领域自适应性，并根据构词规则提出了固定词串消解，动词消解，词概率消解三种方法消除歧义。 国外研究 国外研究中文分词的主要科研机构有：斯坦福、SUTD、UC Berkeley、CMU、CityU等。 国外成熟的分词系统有：Core NLP（斯坦福 NLP Group）、Zpar（SUTD）、Basis Technology、Open NLP (Apache 基金会)等。 国外分词算法上的进展：2003年之前，主要集中在词典与人工规则相结合，词典与概率统计规则相结合。2005年，开始使用基于字序列标注的分词方法，该方法始于[20]，第一次将严格的串标注学习应用于分词在[21]和[22]之后。[23]与[24]的出现，基于CRF模型崭露头角，在此之后，CRF多个变种构成了深度学习时代之前的标准分词模型。基于词的随机过程建模导致一个CRF变种，即semi-CRF(半条件随机场)模型的直接应用。2006年，基于字序列标注的方法已经开始盛行，核心模型仍然是ME与CRF，同年，[25]发表semi-CRF的第一个分词实现。[26]提出了一种基于子词（subword）的标注学习，基本思路是从训练集中抽取高频已知词构造子词词典。2007年，ME的方法已经开始退出舞台，CRF越来越成为主流。2010年，核心方法还是基于CRF模型，后处理是SVM-HMM模型。2011年，当子串的抽取和统计度量得分计算扩展到训练集之外，[27]实际上提出了一种扩展性很强的半监督分词方法，实验也验证了其有效性。2013年，[28]提出神经网络中文分词方法，首次验证了深度学习方法应用到中文分词任务上的可行性。 在领域自适应上，由耶鲁大学教授提出的Active Learning得到了较为广泛的使用。 待补充 参考文献 [1] 马晏. 基于评价的汉语自动分词系统的研究与实现[D]. 清华大学, 1991. [2] 张国兵, 李淼. 一种基于局部歧义词网格的快速分词算法[J]. 计算机工程与应用, 2008, 44(12):175-177. [3] 石佳, 蔡皖东. 基于N元语法的汉语自动分词系统研究[J]. 微电子学与计算机, 2009, 26(7):98-101. [4] 韩莹, 王茂发, 陈新房,等. 汉语自动分词词典新机制—词值哈希机制[J]. 计算机系统应用, 2013, 22(2):233-235. [5] 蒋才智, 王浩. 基于memcached的动态四字双向词典机制[J]. 计算机应用研究, 2011, 28(1):152-154. [6] 刘超, 王卫东. 基于双哈希词典机制中文分词的研究[J]. 信息技术, 2016, 40(11). [7] 刘挺, 吴岩, 王开铸. 串频统计和词形匹配相结合的汉语自动分词系统[J]. 中文信息学报, 1998, 12(1):17-25. [8] 唐涛. 面向特定领域的中文分词技术的研究[D]. 沈阳航空航天大学, 2012. [9] 卢志茂, 刘挺, 郎君,等. 神经网络和贝叶斯网络在汉语词义消歧上的对比研究[J]. 高技术通讯, 2004, 14(8):15-19. [10] 廖先桃, 于海滨, 秦兵,等. HMM与自动规则提取相结合的中文命名实体识别[C]// 全国学生计算语言学研讨会. 2004. [11] 程志刚. 基于规则和条件随机场的中文命名实体识别方法研究[D]. 华中师范大学, 2015. [12] 祝继锋. 基于SVM和HMM算法的中文机构名称识别[D]. 吉林大学, 2017. [13] ZHUORAN WANG, TING LIU. Chinese Unknown Word Identification Based on Local Bigram Model[J]. International Journal of Computer Processing of Oriental Languages, 2012, 1(3):185-196. [14] 原媛, 彭建华, 张汝云. 基于统计的汉语词义消歧研究[J]. 信息工程大学学报, 2007, 8(4):501-504. [15] 肖建涛. 基于最大熵原理的汉语词义消歧与标注语言模型研究[D]. 北京机械工业学院 北京信息科技大学, 2007. [16] 张旭. 一个基于词典与统计的中文分词算法[D]. 电子科技大学, 2007. [17] 佟德琴. 基于字词联合解码的中文分词研究[D]. 大连理工大学, 2011. [18] 赵海, 揭春雨, 宋彦. 基于字依存树的中文词法-句法一体化分析[C]// 中国计算机语言学研究前沿进展. 2009. [19] 赵海, 揭春雨. 基于有效子串标注的中文分词[J]. 中文信息学报, 2007, 21(5):8-13. [20] Nianwen Xue. Chinese Word Segmentation as Character Tagging. Computational Linguistics and Chinese Language Processing, 8(1), 2003, pp. 29–48. [21] Hwee Tou Ng and Jin Kiat Low. Chinese part-of-speech tagging: One-at-a-time or all-at-once? word-based or character-based? In Conference on Empirical Methods in Natural Language Processing, 2004, pp. 277–284. [22] Jin Kiat Low, Hwee Tou Ng, and Wenyuan Guo. A maximum entropy approach to Chinese word segmentation. In Proceedings of the SIGHAN Workshop on Chinese Language Processing, 2005, pp. 448–455. [23] Huihsin Tseng, Pichuan Chang, Galen Andrew, Daniel Jurafsky, and Christopher Manning. A conditional random field word segmenter for SIGHAN bakeoff 2005. In Proceedings of the SIGHAN workshop on Chinese language Processing, vol. 171, 2005. [24] Fuchun Peng, Fangfang Feng, and Andrew McCallum. Chinese segmentation and new word detection using conditional random fields. In Proceedings of the international conference on Computational Linguistics, 2004, pp. 562–569. [25] Galen Andrew. A hybrid Markov/semi-Markov conditional random field for sequence segmentation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2006, pp. 465– 472. [26] Ruiqiang Zhang, Genichiro Kikui, and Eiichiro Sumita. Subword-based tagging for confidence-dependent Chinese word segmentation. In Proceedings of the Annual Meeting of the Association for Computational Linguistics and the international conference on Computational Linguistics, 2006, pp. 961–968. [27] Hai Zhao and Chunyu Kit. Integrating Unsupervised and Supervised Word Segmentation: the Role of Goodness Measures. Information Sciences, 181(1), 2011, pp. 163–183. [28] Xiaoqing Zheng, Hanyang Chen, and Tianyu Xu. Deep learning for Chinese word segmentation and POS tagging. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2013, pp.647–657. [29] Wenzhe Pei, Tao Ge, and Baobao Chang. Max-margin tensor neural network for Chinese word segmentation. In Proceedings of the Annual Meeting of the Association for Computational Linguistics, 2014, pp. 293–303. [30] Xinchi Chen, Xipeng Qiu, Chenxi Zhu, and Xuanjing Huang. Gated recursive neural network for Chinese word segmentation. In Proceedings of the Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, 2015a, pp. 1744–1753. [31] Jingjing Xu and Xu Sun. Dependency-based gated recursive neural network for Chinese word segmentation. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), 2016, pp. 567–572. [32] Meishan Zhang, Yue Zhang, and Guohong Fu. Transition-based neural word segmentation. In Proceedings of the Annual Meeting of the Association for Computational Linguistics, 2016, pp. 421–431. [33] Deng Cai, Hai Zhao, Zhisong Zhang, Yuan Xin, Yongjian Wu, and Feiyue Huang. Fast and accurate neural word segmentation for Chinese. In Proceedings of the Annual Meeting of the Association for Computational Linguistics, 2017. [34] 宋彦, 蔡东风, 张桂平,等. 一种基于字词联合解码的中文分词方法[J]. 软件学报, 2009, 20(9):2366-2375. [35] 李寿山, 黄居仁. 基于词边界分类的中文分词方法[J]. 中文信息学报, 2010, 24(1):3-7. [36] Wang K, Su K Y, Su K Y. A character-based joint model for Chinese word segmentation[C]// International Conference on Computational Linguistics. Association for Computational Linguistics, 2010:1173-1181. [37] 王娟, 曹庆花, 黄精籼,等. 基于受限领域的中文分词系统[J]. 信息系统工程, 2011(11):106-106. [38] 张少阳. 领域自适应中文分词系统的研究与实现[D]. 沈阳航空航天大学, 2017. [39] 许华婷, 张玉洁, 杨晓晖,等. 基于Active Learning的中文分词领域自适应[J]. 中文信息学报, 2015, 29(5):55-62. [40] 苏晨, 张玉洁, 郭振,等. 适用于特定领域机器翻译的汉语分词方法[J]. 中文信息学报, 2013, 27(5):184-190. [41] 张梅山, 邓知龙, 车万翔,等. 统计与词典相结合的领域自适应中文分词[J]. 中文信息学报, 2012, 26(2):8-12. [42] 朱艳辉, 刘璟, 徐叶强,等. 基于条件随机场的中文领域分词研究[J]. 计算机工程与应用, 2016, 52(15):97-100. [43] 韩冬煦, 常宝宝. 中文分词模型的领域适应性方法[J]. 计算机学报, 2015, 38(2):272-281. [44] 李明. 针对特定领域的中文新词发现技术研究[D]. 南京航空航天大学, 2012. [45] 王文荣, 乔晓东, 朱礼军. 针对特定领域的新词发现和新技术发现[J]. 现代图书情报技术, 2008, 24(2):35-40.","categories":[{"name":"毕设","slug":"毕设","permalink":"http://meng.uno/categories/毕设/"},{"name":"研究现状","slug":"毕设/研究现状","permalink":"http://meng.uno/categories/毕设/研究现状/"}],"tags":[{"name":"分词","slug":"分词","permalink":"http://meng.uno/tags/分词/"},{"name":"跨领域","slug":"跨领域","permalink":"http://meng.uno/tags/跨领域/"}]},{"title":"Software Verification Approaches","slug":"software-verification","date":"2017-12-11T13:19:48.000Z","updated":"2018-02-11T14:04:49.152Z","comments":true,"path":"posts/55e262ef/","link":"","permalink":"http://meng.uno/posts/55e262ef/","excerpt":"","text":"Network Function Virtualization (NFV) In the beginning, we need to know NFV which through the establishment of VNF (Virtualized Network Function) to achieve some network functions on a common server, switches, memory and other hardware devices, making these network functions on a common hardware device run, do not need to configure a new dedicated network elements, can greatly enhance the flexibility of the network deployment, and lower investment costs. In the process of realization of network functionality through NFV technology, VNF in the form of software running on the hardware, by way of example and to achieve termination VNF allocation and deallocation of resources. In order to avoid VNF packet forgery in transit and in storage and tampering, increasing the signature files in the software package VNF, the receiving end after receiving the VNF software package by verifying signature files for VNF package for secure authentication to ensure VNF packet during transmission security; in addition, the receiving end before VNF instantiated need for storage VNF package for secure authentication to ensure VNF package in the store security, which increased VNF instantiation delay, reduce the VNF instantiated performance. Systems-Theoretic Process Analysis (STPA) STPA is for identifying harmful circumstances which could lead to accidents and generating detailed safety requirements which must be implemented in the design to prevent the occurrence of these unsafe scenarios in the system. STPA is a top-down process and it addresses many types of hazards of components and their interactions like design errors, software flaws and component interaction failures. One of the advantages of STPA is that it can be applied at any stage of the system development process. STPA is performed by four main steps: Before conducting an STPA analysis, the safety analysts should establish fundamentals of the analysis (e.g. accidents, the associated hazards) and construct the control structure diagram. For each control action in the control diagram, the safety analysts must identify the potentially unsafe control actions of the system that could lead to a hazardous state. A unsafe control action is a control action that violates system safety constraints. Use the identified hazardous control actions to create safety requirements and constraints. Determine how each potentially hazardous control action, identified in step 2., could occur by augmenting the control structure diagram with a process model. Software Model Checking (SMC) SMC is an automatic technique based on a verification model which explore all possible software states in a brute-force manner to prove properties of their execution. The model checking process involves the target software to be formally modeled in the input language of a model checker and specifications (properties) to be formalized in a temporal logic. Many safety-critical software systems are being written in ANSI-C. Therefore, there exist a number of software model checker tools which are used to verify code conducted a comparison and evaluation of existing model checking tools for C code. This comparison showed that the SPIN model checker, a general-purpose model checker, uses an efficient algorithm to reduce the state explosion problem. Safety Analysis Combining STPA and SMC This method can derive software safety requirements at the system level and to verify them at the code level. This approach is divided into three kinds of activities: Deriving software safety requirements using STPA; Formalizing of safety requirements and Verifying software against its safety requirements at the code level. The structure is like this: Fault Tree Analysis (FTA) FTA is a top-down, deductive failure analysis in which an undesired state of a system is analyzed using Boolean logic to combine a series of lower-level events. The propose is to understand how systems can fail, to identify the best ways to reduce risk or to determine event rates of a safety accident or a particular system level failure. This method can divide into 5 steps: Define the undesired event to study; Obtain an understanding of the system; Construct the fault tree; Evaluate the fault tree; Control the hazards identified.","categories":[{"name":"Software Verification","slug":"Software-Verification","permalink":"http://meng.uno/categories/Software-Verification/"}],"tags":[{"name":"Software Verification","slug":"Software-Verification","permalink":"http://meng.uno/tags/Software-Verification/"}]},{"title":"Some Throughts on Big Graphs Research","slug":"big-graphs-throught","date":"2017-12-08T13:26:46.000Z","updated":"2018-02-11T14:04:49.149Z","comments":true,"path":"posts/52d6fa6b/","link":"","permalink":"http://meng.uno/posts/52d6fa6b/","excerpt":"","text":"Redesign the Frameworks Used for Big-Graphs Mining. Nowadays, researches on Big-graphs are only using those open source distributed systems such as Hadoop, Spark and so on. I don’t mean they are bad, but I think we could redesign some new frameworks based on they. If I do this research, I will first redesign some data structure such as Inverted files for those distributed systems. Mine Frequent Subgraphs by Adding Some Parameters. Mining frequent subgraphs is very crucial to SNS network graphs. In these networks, a user is often associated with location information (e.g., positions of her hometown and check-ins). These networks are collectively known as spatial graphs. However, it isn’t mean those who are in a same location are in the same subgraph. For example, if I am in Singapore, I may also care China more Singapore, so I belong to the subgraph of China instead of others. In this circumstance, we need add more parameters to our mining methods to get the right mining result. Temporal and Streaming Systems for Dynamic Graphs Despite the plurality of graph systems, majority of them support processing static graphs only. In reality, however, many graph applications today need to handle changes to the graphs over time. Many challenges remain in this sub-field. For example, most temporal and streaming graph systems cannot efficiently handle frequent vertex and edge deletions, as deletions often break the nice properties that enable incremental computation in these systems. Certainly, maybe I will do some research in this area to support efficient analysis of dynamic graphs. Data Structure for Storing the Big-Graphs Most graph analysis systems assume that the graph is already generated in the requisite format for ingesting into the system. In practice, however, usually the graphs must first be extracted from non-graph data stores using a pre-processing step that generates the lists of nodes and edges. In many cases, graph analysis may form one component of a deep analysis pipeline, that also involves non-graph analytics operations; in such cases also, we may need to convert the data among different representations. The costs of such pre-processing or conversion steps can be significant, and in some cases, the cost of extracting graphs may dominate the actual computation that follows (e.g., if edges are generated by computing similarities between node attributes).","categories":[{"name":"Big Graphs","slug":"Big-Graphs","permalink":"http://meng.uno/categories/Big-Graphs/"}],"tags":[{"name":"Big Graphs","slug":"Big-Graphs","permalink":"http://meng.uno/tags/Big-Graphs/"}]},{"title":"浅析VR/AR+：医疗","slug":"vr-ar-medicine","date":"2017-11-18T13:07:15.000Z","updated":"2018-02-14T11:13:32.514Z","comments":true,"path":"posts/c1dd0093/","link":"","permalink":"http://meng.uno/posts/c1dd0093/","excerpt":"","text":"VR/AR介绍 虚拟现实技术（VR）是一种可以创建和体验虚拟世界的计算机仿真系统，它利用计算机生成一种模拟环境，是一种多源信息融合的、交互式的三维动态视景和实体行为的系统仿真使用户沉浸到该环境中。 VR是仿真技术的一个重要方向，是仿真技术与计算机图形学人机接口技术多媒体技术传感技术网络技术等多种技术的集合，是一门富有挑战性的交叉技术前沿学科和研究领域。VR主要包括模拟环境、感知、自然技能和传感设备等方面。模拟环境是由计算机生成的、实时动态的三维立体逼真图像。感知是指理想的VR应该具有一切人所具有的感知。除计算机图形技术所生成的视觉感知外，还有听觉、触觉、力觉、运动等感知，甚至还包括嗅觉和味觉等，也称为多感知。自然技能是指人的头部转动，眼睛、手势、或其他人体行为动作，由计算机来处理与参与者的动作相适应的数据，并对用户的输入作出实时响应，并分别反馈到用户的五官。传感设备是指三维交互设备。 而增强现实技术（AR）是一种实时地计算摄影机影像的位置及角度并加上相应图像、视频、3D模型的技术，这种技术的目标是在屏幕上把虚拟世界套在现实世界并进行互动。AR最早是于1990年提出的，之后随着电子产品运算能力的提升，其应用也是用途愈广。尤其是近两年来AR技术可谓是备受关注！现在的市场中由于可穿戴设备的出现，以及手机性能的进一步提升，AR技术也是持续升温。 AR是一种将真实世界信息和虚拟世界信息“无缝”集成的新技术，是把原本在现实世界的一定时间空间范围内很难体验到的实体信息（视觉信息,声音,味道,触觉等），通过电脑等科学技术，模拟仿真后再叠加，将虚拟的信息应用到真实世界，被人类感官所感知，从而达到超越现实的感官体验。真实的环境和虚拟的物体实时地叠加到了同一个画面或空间同时存在。不仅展现了真实世界的信息,而且将虚拟的信息同时显示出来，两种信息相互补充、叠加。在视觉化的AR实现中，用户利用头盔显示器，把真实世界与电脑图形多重合成在一起，便可以看到真实的世界围绕着它。 在接下来的叙述中，我将在第二部分分析VR/AR对于医生角度的应用，第三部分分析在病人角度的应用，第四部分是在医疗教育方面的应用，其他相关的研究我将在第五部分陈述，现阶段研究的不足将在第六部分分析，最后两部分是一点我的个人感想和本文结论。 对于医生的应用 模拟手术 虚拟手术作为一个虚拟现实领域的重要研究方向，正成为科学家们的关注焦点。它是集现代医学、计算机图形学、计算机视觉、生物力学、材料学、机器人等诸多学科为一体的新型交叉研究领域。医生可以通过虚拟现实技术来模拟、指导医学手术所涉及的各种过程，包括手术计划制定、手术排练演习、手术教学、手术技能训练、术中引导手术、术后康复等。 80%的手术失误是人为因素引起的，因此手术训练极其重要。以前医生手术训练都只能在病人身上做，所以经常说有名的医生都是踏过多少人的血液才走过来的，这样付出的代价实在太大。在VR/AR技术飞速发展并广泛应用的今天，模拟手术在医生训练过程中非常重要的应用就是，医生可以在不接触实际病人的前提下模拟各种手术场景，模拟的场景可能比真实遇到的情况还要多，这样模拟训练的效果实际上就超过了真实的练刀。一方面，模拟训练可以在任何地方、任何时间反复模拟，深化印象，这个优点在实际病人身上是不可能也不允许做的，因为病人的资源是有限的。模拟手术就是把每个可能的手术场景都呈现在你的面前，每个人得到的机会都是无穷次的，医生可以反复看、反复练，并且对病人没有伤害。如果从这点来讲，一个经过模拟训练的医生再给病人做手术时，他的学习周期就会很短很短，这个实际上是对病人利益的极大保护。当前模拟手术在中国也已经有了，像强生公司、科汇公司的外科培训中心已经有腹腔镜的模拟，也有介入手术的模拟，当然还有达芬奇手术的模拟，但这种模拟还不是真实场景的，也就是说未来在VR技术里面，可以完全进入到手术室，然后在真实的场景里面进行模拟手术，那就更加接近于现实。 大家应该知道在体育运动里，比如足球、体操，都有慢动作回放，有动作捕捉去分析运动员动作是否做到位了，失误的原因是什么。这个技术同样可以用到外科手术里。通过运动捕捉或者手势识别和VR技术，在外科大夫进行学习或尝试以后，可以复原手术，看到手术的过程，如果有失误，原因是什么。这种回放能极大的帮助医生改进他们的技术。 远程干预/指导 世界上首例实验性远程手术已经在1999年成功地进行。虚拟手术与远程干预将能够使在手术室中的外科医生能实时地获得远程专家的交互式会诊。交互工具可以使顾问医生把靶点投影于患者身上来帮助指导主刀外科医生的操作，甚或通过遥控帮助操纵仪器。这能使专家们技能的发挥不受空间距离的限制。如果VR技术在这一方面继续发展的话，可能会出现以后医生不用到医院上班，无论在任何地方都可以实施手术。缓解了当今医院基础设施不足的现状。同时，有些相同的手术，某专家可以通过VR技术远程指导，这样就打破了一个时间段只能进行一项手术的限制，大大提高医疗的效率。 精确操作 如上文已经提到的达芬奇机器人，还有很多像这种医生能够远程控制其操作的手术设备，通过使用这些设备，能够在实际的手术中，避免因为医生长时间工作造成的身体情况变化而带来的手术质量参差不起的问题（例如某医生一天手术过多，太过劳累，这样后来的手术必然会质量下降）。如果使用了VR技术，远程控制诸如达芬奇机器人一样的手术设备，不管医生自己身体状况如何，只要控制到位，那些手术设备是不会因为工作时间长就产生不适的，这样也能保证手术质量优秀。同时，一个医生只有两只手，所以有些手术需要助手，而使用那些设备之后，一个医生可以控制很多只手，这样就能够协调统一，对手术质量有百利而无一害。 协助执行日常任务 医生需要经常查看病人的病情，而在现在的医疗设施情况下，对于一个医生，可能得通过“查房”一间一间地去病房里与病人交流，而且交流记录难免会记忆不清或者甚至搞混了。有了VR技术虚拟医生协助真实医生实现这些复杂的工作，效率必然会大大提高。医生甚至都不用出办公室，只需要观察相应的VR反馈就可以基本实现之前的“查房”任务。这样一来就可以大大减轻医生的负担，必然会对医生的日常工作效率产生积极的影响。这些虚拟医生与病人交流的数据可以保存用来对之后的反馈对比，当然可以用其他机器学习的方法来进行一些预测之类的计算。并且基于大数据，可能这些虚拟医生对单个病人情况的分析会比真实的医生更专业，因为医生也不是能对每个症状都了如指掌的。 有些病人（例如老人和小孩等）可能在认识自己病情上有欠缺，例如忘记吃药，每次吃多少药等，在传统的方案中，要么有专人提醒，要么在显眼的地方做上标记提醒，总之效率不高或者费时费人力。当我们在某种小的设备上加上VR/AR提醒，以一个三维立体的形象的形式来提醒病人，既省时又省人力，效率相对还比较高。 获得医药信息 医生可能不能记住每种药物的作用，以及每种药物的使用方式，假如能通过VR技术将每种药的使用信息都记录下来，通过相关的设备，让医生在给病人开药的时候头脑里能对这种药的所有情况都回顾一遍，同时还可以与几种相似的药做对比，找出最好的组合，避免偶尔的误用药。 获取用户机体信息 在现在正常的医学治疗步骤中，医生想要检查病人某部位的病变情况，只能使用诸如CT、CTA等基于切片的二维人体部位图像，这种图像相对来讲专业要求度较高，对人体伤害较大，同时准确性也不能得到保障。将VR应用于此种工作，我们可以得到人体某部位的三维立体真实大小的模型，这样一来医生的判断会更加准确而且这种图识别起来相对不需要那么复杂的专业知识。 血管照明（辅助手术） 这算是一种比较专业地说法，和辅助手术概念比较类似，简而言之就是通过PC应用软件帮助医务人员在手术中能够查看隐藏的血管。此前，心脏病专家借助谷歌眼镜疏通了一位49岁男患者阻塞的右冠状动脉。冠状动脉成像（CTA）和三维数据呈现在智能眼镜的显示器上，根据这些实时放大图像，医生可以方便地将血液导流到动脉。不同于传统手术，AR的介入就像一个”AR放大镜”，直接放大手术创口，患者的彩超、MRI、CT图像等将直接映在手术部位，让医生能够看到肉眼难以分辨的细微情况，获得“透视”功能，大大提高手术操作的效率和舒适度。 损伤评估 在传统的医疗实践中，如果病人就诊，医生为了确定病人病情只能通过明显的外表特征或者患者的口头表述来确定，而这样的手法往往会带来误判或者病情程度判断不清等问题，特别是那种很难表述清楚的内科疾病。运用虚拟现实技术，我们可以针对不同的疾病设定不同的诊断场景，让用户在特定场景中将应该表现出来的病症全部表现出来，这样一来有利于增大诊断的准确性。 对于病人的应用 智能康复系统 基于Kinnect等运动捕捉设备所设计出的很多结合VR/AR技术的智能康复系统，这些系统能够很好的帮助病人进行相应的康复训练。在之前我所看到的一个例子中， 病人只需要带上相应的可穿戴传感器就可以将自己的动作传到相应的计算机进而在计算机显示屏上显示用户的动作以及在显示屏中出现的影像之间的交互。在我所看到的实例中，他们只是能做到在场景中增加一些物体（例如长方体等），让病人在虚拟的环境中模拟各种体力锻炼。这样一来，我们就不需要实际花费很多的金钱来布置训练场景，而且VR所形成的场景还可以很轻易得更换，不用为维护实际的场景而花费很多精力。 调查显示，以色列的研究人员开发出一套“电脑辅助康复环境系统”，通过模拟划船、打球、慢跑等各种情景，来帮助残障人士改善平衡能力，恢复身体的运动机能。足部神经受损的博罗夫斯基就在接受“电脑辅助康复环境系统”的治疗。现在系统模拟的是“海上冲浪”，大屏幕上显示的是冲浪的场景，博罗夫斯基脚下的踏板会根据设置好的程序相应的摇动，他必须通过调节身体的姿势来保持平衡。同时，连接在他身上的传感器还能把各种身体体征数据传回电脑，以便医生调整训练强度和难度。丰富的影像和新颖的训练方式，让患者像在做游戏一样，更能提高患者本身的主动性和积极性，加强训练效果，缩短住院时间，加快康复过程。无论从时间、人力还是金钱上讲，VR/AR技术的使用必然会在康复系统上带来一场新的革命。 帮助治疗某些疾病 有些疾病（例如某种危险情况恐惧症），需要病人在再临其境时才可能克服，但如果让患者在现实中的危险环境再次体验，可能会有安全性问题，而且相同的场景很难真实地完美还原。如果使用VR技术，就可以在基本不耗费后期资源的情况下反复体验相同的场景，在现实中，用户也不会有任何的伤害，而且可调节范围比较广，毕竟是电脑虚拟程序，恐怖程度、危险指数等都可以随心所欲地变化，与现实相比真的是有巨大的优势。 截肢者中最常见的烦恼就是幻肢痛——患者感到被切断的肢体仍在，且在该处发生疼痛。疼痛多在断肢的远端出现，疼痛性质有多种，如电击、切割、撕裂或烧伤等。对幻肢痛的发生原理，目前尚无统一意见，西医亦乏有效疗法。很有可能大脑对肢体仍然存有意识，即使它已经不存在了。尽管这样的问题发生存在一定的频率，但至今没有一种有效地方法适用于所有的截肢者。在使用VR技术治疗过程中研究人员使用头戴式耳机和一个传感器将患者带入虚拟的世界，患者可以感受到自己的肢体还在，并可以控制虚拟肢体从事某项工作或游戏。这样就能很好的解决这一疾病，有研究表明对这种疾病VR治疗作用十分显著。 VR对创伤后应激障碍也同样有很好的治疗作用。在对从伊拉克和阿富汗返回患有创伤后应激障碍的士兵所进行的VR治疗过程中，VR设备会将会把士兵带回中东的一个小镇，让他们再次“经历”战争和死亡，使其在适当的压力下逐渐学会处理，控制自己的情绪。虽然很多人对于这种治疗方式存在争议，支持者说使用虚拟现实技术与其他的治疗方式相结合会达到非常很理想的治疗效果。 VR可以帮助治疗的心理障碍并不仅仅局限于创伤后应激障碍。还有些心理问题（例如自闭症、害羞等），是一个杀人于无形的凶手，目前呈现向低龄化蔓延的趋势。虚拟现实可能也会成为这个问题的解决方案之一。如果有人能既为患者保守秘密有能很好的与用户交流，对治疗这些疾病肯定是有很大的好处的，但是现实中不可能存在这样的一个完美的“倾听者”，即使有，价钱也是不菲的。如果VR/AR能够起到这样的作用那必然会是又一大医学进展。 很多心理治疗师和精神专家常用的方式是通过在治疗过程中去引导患者回忆或者想象场景，以此来达到治疗的目的。VR的好处在于它能够让这种环境场景变得可视化和标准化。因此在心理治疗领域，比如说创伤应急、障碍症、恐惧症、自闭症、恐高症、幽闭症、公开演讲恐惧症、密集恐惧症等都可以通过VR技术的环境再现以达到治疗的目的。再比如说，焦虑症、注意力缺陷以及精神分裂症也可以通过VR来虚拟特定的人或是特效来改善相关的一些症状。 虚拟问诊 在国内外，好的医生都是十分欠缺的，然而相同的疾病缺屡见不鲜，可以说很多小病完全可以在还是在早期的时候就通过及时就诊可以避免出现的，在之前的这么多年，很多搜索引擎也都在做相关的疾病问答系统，可悲的是大多受金钱诱惑，为金钱奴役，不干正事反而虚假宣传。VR技术的出现，必然在医疗问答方面带来很大的革新，患者可以通过VR设备与虚拟的医生直接进行交谈，不仅避免了文字表述不清的问题，而且也避免受网页上那么多的虚假广告的诱惑，更是给人一种如见真实医生的舒适的感觉，而且VR医生会比现实中医生更有耐心，更专职为你一人服务。 缓解疼痛 读到这样一个故事，“2017年年初，美国的一位脂肪瘤患者开刀时，因为平时血压过高，医生只为她注射了少量镇静剂。医生为她戴上了VR设备，在手术过程中患者一直在玩一个埃及探险的游戏。手术过程中，监测仪器显示患者的一切生命体征参数，都非常平稳。在整个手术过程中，患者的血压不仅没有提升，反而下降了。手术完成后，患者表示她几乎没有感到疼痛。”我觉得有了这个实例，我不需要过多的解释，已经能够很好的说明VR在缓解病人疼痛上的作用了吧。无独有偶，接受重度烧伤治疗是一段痛苦的经历。伤口清理和绷带变化都会引发疼痛，即便使用吗啡等麻醉药物，仍有86%的病人会感到或多或少的疼痛，并且大量使用还会对身体造成一定伤害。1996年，华盛顿大学人机界面技术实验室（HITLab）研究人员发现孩子们在玩游戏时是越来越全神贯注后，想出了为治疗烧伤提供VR游戏，假设沉浸在游戏中会为病人带来积极疗效，他们会更专注于游戏，而减轻对疼痛的注意力。据调查，社会行为医学2011年发布的调查展示了浸入式游戏作为止痛剂的强大作用。并且现在这项技术已经被美国军方使用，帮助受伤的士兵接受治疗。 当然在平时的生活中，VR也是能够起到很好的。当我们沉浸在一个虚拟的美好的游戏环境中时，我们可以忘记暂时的伤痛，这是一个常识，也是VR能在这一方面得到巨大应用的一个原因。 戒瘾 当今社会的另一大“疾病”，不是身体上的，更大多数是心理上的，例如网瘾、烟瘾甚至毒瘾。在以前的戒瘾所，采取的唯一方式就是物理上的隔离，在VR技术快速发展的今天，我们完全可以通过VR将患者的精力集中到正确的角度上，不仅可以将效果提高，而且省时省力。查阅资料发现，我国相关法律已经开始涉足使用VR进行戒毒活动了。 当然，其实在这里VR可能成为一把双刃剑，可能能将用户的注意力从其他那些及其不正常的生活习惯中解救出来，但是可能又会让用户陷入“VR瘾”中，现在我们还无法证明这个“VR瘾”和其他的“网瘾”、“烟瘾”等孰轻孰重，所以此法需要慎重使用。 VR/AR与视觉结合 VR本身就是可以直接作用于人的视觉，视觉治疗方案与VR技术很容易匹配。现在升学、工作压力，导致大部分人都有眼部疾病或视觉障碍。VR在治疗眼部的疾病，比如儿童的斜视、近视以及立体视力的缺陷上有很好的效果。虽然在不久之前就有对近视等疾病的物理治疗方案，但是大多费时费力，而且没有听说有什么可观的进展。但是VR/AR的到来就完全不同了，大大提高了效率而且效果明显提高。同时可以制作一种VR设备用来缓解疲劳的眼球，当我们工作或者学习很长时间之后，可以用它来对眼球“做做操”。虽然我们都明白久看之后需要远眺一会，或者看看绿色的动西，但是迫于现实，我们可能很难做到（例如哈尔滨的冬天没有绿树。），但是这一切都可以用VR设备来实现。 缓解术前压力 接受手术的患者到了陌生环境，难免会有应激反应。他们可能觉得在手术室外等候，麻药还没有生效的时候，他们有强烈的紧张感和恐惧感，甚至有了濒临死亡的体验。现在想一想，这种体验对每个人来说都是非常不好的。虽然术前医生和患者有充足时间做沟通，但是单纯靠用嘴讲、用图、甚至手画示意图，都是一件非常累的事情，因为手术的复杂性和专业性，包括一些专有名词，对患者来说真的是选择性记忆，他们有可能听了上半句，就忘了下半句，甚至把最主要的东西漏掉，支离破碎地理会医生的意思，即使再出色的现场描述也比不过真实环境的真实还原。如果运用VR技术，在手术开始前给患者放一段容易让他放松的内容，让他在进手术室之前，大致了解手术室和手术过程是什么样子的，就能消除他对未知环境的恐惧。我相信这对患者来说是人文的关怀，这在提高医学服务水平里面可以得到有效的应用。 隐私保护 现在我国的搜索引擎在医疗上很不受人看好的一个主要原因就是其泄露用户隐私的现象太严重，所以很少有人真正愿意相信搜出来的东西。加入VR/AR元素进入我们的生活，我们可以与虚拟形象进行完全不用担心泄露隐私的情况下的交流。 医疗教育的应用 手术教学 伴随互联网的继续发展，如果医学手术教育能够通过VR/AR技术实现，至少在解剖学课程上可以实现意想不到的效果。在相关的设计中，例如心脏的VR模型可以做的特别逼真，让学生可以把心脏托在手里面，随时都可以转圈、打开肌肉看，血流都可以看，这就可以大大缩短医学生的学习周期（而且可以打破时间、地点的限制来学习）。尤其对于外科医生来讲，外科医生很重要的工作就是解剖。局部解剖以前医学生只能通过书本来学习，看到的都是平面的东西，脑子里很少有立体的概念，无法产生互动，进而需要很长的时间来消化知识，甚至很多时候大多数医学生并不能形成很好的立体的模型在脑子中，所以这就是很多庸医出现的根源。VR/AR技术的出现使得医学生在真正操刀做手术之前，就能获得局部解剖的经验，能够有效提高手术的安全性和成功率。而如果医学生通过VR/AR技术实现解剖模拟，学习速度会大大加快，同时降低学习的成本。当然AR在医学教育的应用并不仅仅是在解剖学上面，在生理生化方面都是可以通过VR技术模拟场景的。如果我们可以获得很形象的信息的话，对医生的知识拓展和学习速度都会急剧加快。 据早在1993年的统计里，全球市场上出现的805个虚拟现实应用系统中就有49个应用于医学，主要应用在虚拟人体、医学图像学、药物分子研究等方面。大家都知道，在传统的医学教育中，如人体标本解剖和各种手术实训，大都受到标本、场地等限制，实训费用高昂。而且医学生不能通过反复在病人身上进行操作来提高临床实践能力、临床实践具有较大风险。而VR的直观和体验特性却可以很好地解决以上问题。目前在医学教育上应用较多的有虚拟人体解剖学、手术训练教学、虚拟实验室、虚拟医院等。类别也从内容、软件到硬件，甚至还有从事交叉研发的，比如，Oculus涉足了内容、硬件和软件等方面，微软HoloLens则是软硬件结合等。 利用VR技术来做外科手术培训另一个重要的特点是，大大节约了成本。在外科领域，医疗知识每隔6~8年就要翻一番，所以外科大夫在专业教育上尤其是在继续教育上需要不断追求对新技术的学习，这种新技术的学习成本是高昂的，方法是复杂的。而VR技术可以在某种程度上帮助大家学习或者熟悉这种新技术。 教学用具改革 传统解剖学挂图和大部分多媒体课件上应用的教学图片都是二维模式，缺少直观的、立体的体验，造成了解剖学习的困难。模型、标本虽具有立体结构，但形式单一、僵硬，不能满足多角度、多层次的教学和实训需求。而虚拟人体解剖图，可在显示人体组织器官解剖结构的同时，显示其断面解剖结构，并可以任意旋转，提供器官或结构在人体空间中的准确定位、三维测量数据和立体图像。此前，美国加州健康科学西部大学（波莫纳）开设了一个虚拟现实学习中心，该中心拥有四种VR技术、zSpace显示屏、Anatomage虚拟解剖台、Oculus Rift和iPad上的斯坦福大学解剖模型，旨在帮助学生利用VR学习牙科、骨科、兽医、物理治疗和护理等知识。 相关研究进展 尽管业内不少人将2016/2017年称之为“VR发展元年”，若追溯VR发展的历史，早在1932年，Aldous Huxley在其推出的科幻小说《美丽新世界》中即对虚拟现实概念进行了描述。而直到1968年计算机科学家Ivan Sutherland开发了“达摩克利斯之剑”，使得VR设备具备了基本的雏形。随后，VR设备开始应用在一些专精领域，如宇航员的训练活动中。直到1987年，任天堂推出了Famicom3D System眼镜之后，Virtual Boy等设备将VR概念正式带入民用领域。而随着近些年来，视频技术以及移动硬件领域的不断发展，民用VR平台也根据使用者的不同呈现出了分化的状态，包括以游戏平台作为计算平台的专属VR平台、以PC作为计算平台的综合体感VR平台、以及以移动设备作为计算与显示窗口的VR眼镜。 硬件厂商方面，在对各类VR设备的研发加大投入力度，VR头盔，眼镜，以及附属的传感器设备在过去的一年中纷纷涌现。 视频平台方面，除了传统视频上传方式外，各大视频平台均开放了“全景视频”的上传接口，用于鼓励视频制作团队为平台增加全景类视频的内容量。但由于目前全景视频的制作与存储成本非常高，能够完成全景视频录制与制作的团队并不多，所以目前多数存留在VR平台端的视频实际为3D的“沉浸式”的视频内容。除此之外，部分平台采取聚合方式，将目前市面上鲜见的VR视频内容加以收集整理，集中呈现在用户面前。而技术方案提供方虽然距离用户较远，却是目前推进整个VR行业发展的最为重要的一方，技术方案将成型的算法，图像引擎等输出给视频平台或硬件厂商，以增强用户在两方的使用体感。 存在的问题 VR在医疗应用方面，相比用作练习、模拟来讲还是很欠缺的。AR in China 最近期的统计，如今国内从事AR应用开发的企业有200多家，其中80%倾向和已开发游戏类应用，剩余的也多偏向影视、购物等生活类应用。而专注在医健领域的应用，根据公开信息推测目前不超过10家。而在海外，据 CBInsights、CrunchBase、AngelList 网站的综合数据查询，目前有30家左右初创公司正专注在AR医疗应用领域。其中9家初创公司获得融资，总融资额达5.52亿美元，获投率达到了30%。AR在医健领域的应用还处于蓝海探索期。 纯粹的VR在医疗领域还是有很大欠缺的。在现在的VR辅助手术中，医生只能利用AR技术的一些优势，并不能完全交给VR来做，还需要加上传统方法，一边做手术一边对着电脑屏幕比对着看。 VR用于治疗方式的缺点是患者的想象和回忆难于把控，所以效果很难评估。 而且现在的VR在显示和精确度方面还是有很大的提升空间的。特别实在医疗领域，准确度至关重要。 对于医生而言，还有适应问题，这些新技术对于有经验的外科医生及其他专业医护人员来讲，“适应”是最大的挑战。 虽然VR技术在医学上应用后能够减少现实中的直接的隐私泄露，但是如果VR数据泄露将导致比现在信息泄露更严重的后果，毕竟VR可以记录整个人的信息而不仅仅是文字信息。 VR的一个很大的问题就是基础硬件设备的体验问题。如果要让医生或者被治疗者长时间呆在虚拟环境中，很容易产生一些生理不适的症状。 虽然说VR在医学上的应用很丰富，尤其是在心理治疗方面颇有成效。但是考虑到治疗的针对性和VR内容制作难度等各种问题，这种辅助治疗方法在现阶段很难进行大规模的应用。 医疗行业需要的是严谨的专业知识和态度，所以对于内容的要求也就相应的提高。如果要开发出一套模拟的人体用来交互培训，需要的是具备医学加上合理内容开发的复合型人才。而且考虑到医学诊断的高精度要求，许多器官或者组织的建模都要非常精细，不能有一丝的马虎，而现在的VR医疗应用更多的还是停留在头戴式VR视频方面。 其他要面临的困难还有：治疗和评估标准没有相关的评估标准、应用系统的交互性和易用性还不够完美。虚拟现实系统设备及其外设性价比例失衡，设备相对比较昂贵,致使大规模应用的时机还不够成熟。 个人感想 虽然最近VR/AR技术越来越火，相关研究也相当多，涉及的行业也是相当全面，但是在现在的情况下，绝大多数成就集中在仿真、游戏上，在医疗领域还是存在很多问题，还有很长的路要走。但希望不要又只能火两年而已。 在医疗工作的各个领域推广VR技术的应用，可以节省大量的时间与资源，从而更快捷、更安全的挽救生命。国际上由于虚拟现实技术的发展而发展起来的医疗电子设备正以每年10%的速度增长。随着计算机、多媒体技术、传感技术、通讯技术的发展以及各国对虚拟现实技术的日益重视，相信这一技术在医学上的应用在将来会取得更大的发展，它的发展前景非常诱人。可以预言，虚拟现实技术在医学中更广泛、更深入的应用将会给传统医疗带来革命性的变化。 在我们国家，新一轮的医疗体制改革如火如荼，传统的医疗体系已经岌岌可危，惟有引入新的信息技术才能适应时代要求。而且，新的医疗体制改革凸现了“社区医疗”的概念。“社区医疗”在全球医疗信息化中对应其第三个阶段，区域医疗信息网络（GMIS），是继医院管理系统（HMIS）、临床医疗信息系统（CIS）之后的阶段。美国所有医疗机构均实现了信息化管理，而中国尚处在初级阶段。将来中国的趋势必然是走向医疗信息化（e-Health）。为了实现这一战略目标，虚拟现实技术就是最佳的操作工具。因此，虚拟现实技术将在中国的“医改”过程中以及今后医疗事业的发展中扮演更加积极、重要的角色。 医疗VR是一个给人无限遐想的领域，它不再只存在于科幻小说爱好者的想象中，而是已经走进了临床研究者和现实生活中的医疗工作者的视野。虽然这是一个全新的领域，还不为大众所知，但是医疗VR技术是对患者的生活和医生的工作都可以产生积极影响的应用。我相信VR必将为医学领域带来一场大变革。 结论 VR/AR作为目前比较新潮的技术，在医学领域作用空前。其在医疗上无论从医生角度、患者角度还是医学教育角度都有着十分巨大的作用。现在相关的科学研究也发展迅速，当然也是存在很多的不足，尤其是我们国家在这方面的研究还很欠缺。在今后的一段时间内，我国的VR开发者还是应该多学习和借鉴国外的先进经验，同时保持在这方面的热情，相信在不久的将来，VR/AR定会在医学领域大大地大放异彩。 参考文献 刘建武, 叶志前, 陆金芳. 虚拟现实在医学中的应用进展[J]. 国际生物医学工程杂志, 2000(6):321-324. 王海舜, 潘利庆. 虚拟现实技术在医学中的应用[J]. 计算机应用, 1998, 22(6):49-54. 刘聚卑, 庄天戈. 虚拟现实在医学上的应用[J]. 北京生物医学工程, 2000, 19(1):47-54. 谭珂, 郭光友, 王勇军,等. 虚拟现实技术在医学手术仿真训练中的应用[J]. 解放军医学院学报, 2002, 23(1):77-79. 范立冬, 李曙光, 张治刚. 虚拟现实技术在医学训练中的应用[J]. 创伤外科杂志, 2008, 10(6):568-570. 谭海珠, 杨棉华, 陈丹芸,等. 虚拟现实技术在医学中的发展与应用[J]. 中华医学教育探索杂志, 2005, 4(6):410-412. 张晗 虚拟现实技术在医学教育中的应用探讨[J]. 西北医学教育, 2010, 18(1):48-51. 孙秀伟, 阎丽, 李彦锋. 虚拟现实技术(VR)在医疗中的应用展望[J]. 临床医学工程, 2007(5):17-20. 吴奇, 程薇曦. 虚拟现实技术在医学手术中的实现与应用[J]. 重庆医学, 2008, 37(21):2489-2491. 李舫, 宋志坚. HMD式光学穿透技术在医学增强现实中的研究进展[J]. 中国数字医学, 2012, 07(1):14-20. 孙国臣, 余新光, 陈晓雷,等. 基于多模态功能神经导航的虚拟现实及增强现实技术在神经外科教学中的应用[J]. 中国医学教育技术, 2015(1):66-69. 李潜. 增强现实技术为医学教育开拓无限未来[J]. 电脑知识与技术, 2012, 08(2):481-482. 张军毅. 医学增强现实建模及可视化研究[D]. 首都医科大学, 2008. 赵娜, 杨谊平. 增强现实技术与手术模拟[J]. 中华医学丛刊, 2004(4):58-59. Wang S, Parsons M, Stonemclean J, et al. Augmented Reality as a Telemedicine Platform for Remote Procedural Training.[J]. Sensors, 2017, 17(10):2294. Noll C, Jan U V, Raap U, et al. Mobile Augmented Reality as a Feature for Self-Oriented, Blended Learning in Medicine: Randomized Controlled Trial[J]. Jmir Mhealth &amp; Uhealth, 2017, 5(9):e139. Mero M, Susin A, Aplicada D M. Deformable 3D Objects for a VR medical application[J]. 2007. Crossan A, Brewster S, Reid S, et al. Multi-session VR Medical Training: The HOPS Simulator[J]. People and Computers XVI - Memorable Yet Invisible, 2002:213--226. Bezerra A. Evaluation of VR medical training applications under the focus of professionals of the health area[C]// ACM Symposium on Applied Computing. ACM, 2009:821-825. JLM Vazquez, BK Wiederhold, I Miller, et al. Virtual Reality Assisted Anesthesia (VRAA) during Upper Gastrointestinal Endoscopy: Report of 115 Cases— Analysis of Physiological Responses, 2017","categories":[{"name":"人机交互","slug":"人机交互","permalink":"http://meng.uno/categories/人机交互/"},{"name":"AR","slug":"人机交互/AR","permalink":"http://meng.uno/categories/人机交互/AR/"},{"name":"VR","slug":"人机交互/AR/VR","permalink":"http://meng.uno/categories/人机交互/AR/VR/"}],"tags":[{"name":"VR","slug":"VR","permalink":"http://meng.uno/tags/VR/"},{"name":"AR","slug":"AR","permalink":"http://meng.uno/tags/AR/"},{"name":"医疗","slug":"医疗","permalink":"http://meng.uno/tags/医疗/"}]},{"title":"中文分词小赛数据","slug":"nlpc","date":"2017-10-30T08:02:41.000Z","updated":"2018-02-17T02:11:10.782Z","comments":true,"path":"posts/649482ba/","link":"","permalink":"http://meng.uno/posts/649482ba/","excerpt":"","text":"纪念一下大四组织的一次中文分词小比赛。 分项数据 训练数据： 链接: https://pan.baidu.com/s/1sl9JLqX 密码: 8am6 测试数据： 链接: https://pan.baidu.com/s/1eSeYhfO 密码: cnw2 相关参考答案： 链接: https://pan.baidu.com/s/1c2tVto0 密码: 3rpt 有切分歧义的100个句子：链接: https://pan.baidu.com/s/1gfJ7Duz 密码: 8mmx 所有数据 所有文件下载：链接: https://pan.baidu.com/s/1gfJ7Duz 密码: 8mmx 测试结果 相关PPT：http://www.meng.uno/nlpc.pdf","categories":[{"name":"AI","slug":"AI","permalink":"http://meng.uno/categories/AI/"},{"name":"NLP","slug":"AI/NLP","permalink":"http://meng.uno/categories/AI/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"http://meng.uno/tags/NLP/"}]},{"title":"JavaScript操作DOM","slug":"js_dom","date":"2017-03-05T08:03:01.000Z","updated":"2018-02-09T10:46:20.926Z","comments":true,"path":"posts/2c47a986/","link":"","permalink":"http://meng.uno/posts/2c47a986/","excerpt":"","text":"创建节点 除了可以使用createElement创建元素，也可以使用createTextNode创建文本节点。document.body指向的是&lt;body&gt;元素，document.documentElement则指向&lt;html&gt;元素。 123456 //创建节点 var createNode = document.createElement(\"div\"); var createTextNode = document.createTextNode(\"hello world\"); createNode.appendChild(createTextNode); document.body.appendChild(createNode); document.documentElement.appendChild(createNode); 插入节点 可以使用appendChild，insertBefore，insertBefore接收两个参数，第一个是插入的节点，第二个是参照节点，如insertBefore(a,b)，则a会插入在b的前面 123456 //插入节点 var createNode = document.createElement(\"div\");var createTextNode = document.createTextNode(\"hello world\");createNode.appendChild(createTextNode);var div1 = document.getElementById(\"div1\");document.body.insertBefore(createNode,div1); 替换和删除元素 从replaceChild和removeChild的字面意思看，就是删除子节点，因此调用者，需要包含子节点div1，不然调用会报错。返回的节点是替换的或删除的元素，被替换/删除的元素仍然存在，但document中已经没有他们的位置了。 1234 //替换元素 var replaceChild = document.body.replaceChild(createNode,div1);//删除元素 var removeChild = document.body.removeChild(div1); 节点的属性 firstChild:第一个子节点 lastChild:最后一个子节点 childNodes:子节点集合，获取其中子节点可 someNode.childNodes[index]或 someNode.childNodes.item(index) nextSibling:下一个兄弟节点 previousSibling：上一个兄弟节点 parentNode：父节点 123456 &lt;ul id=\"ul\"&gt;&lt;li&gt;sdsssssss&lt;/li&gt;&lt;li&gt;qqqq&lt;/li&gt;&lt;li&gt;wwww&lt;/li&gt;&lt;li&gt;eeee&lt;/li&gt;&lt;/ul&gt; 12345678910111213141516 //节点属性 var ul = document.getElementById(\"ul\"); var firstChild = ul.firstChild; console.log(firstChild.innerHTML); var lastChild = ul.lastChild; console.log(lastChild.innerHTML); var length = ul.childNodes.length; console.log(length); var secondChild = ul.childNodes.item(1); console.log(secondChild.innerHTML); var forthChild = ul.childNodes.item(2).nextSibling; console.log(forthChild.innerHTML); var thridChild = forthChild.previousSibling; console.log(thridChild.innerHTML); var parentNode = forthChild.parentNode; console.log(parentNode.innerHTML); 文档片段 好处在于减少dom的渲染次数，可以优化性能。 12345678910 //文本片段 var fragment = document.createDocumentFragment(); var ul = document.getElementById(\"ul\"); var li = null; for (var i = 4; i &gt;= 0; i--) &#123; li = document.createElement(\"li\"); li.appendChild(document.createTextNode(\"item \"+i)); fragment.appendChild(li); &#125; ul.appendChild(fragment); 克隆元素 someNode.cloneNode(true):深度克隆，会复制节点及整个子节点 someNode.cloneNode(false):浅克隆，会复制节点，但不复制子节点 123 //克隆var clone = ul.cloneNode(true);document.body.appendChild(clone); 注意： childNodes.length存在跨浏览器的问题 可以看到有关列表的html片段没有用 123456 &lt;ul id=\"ul\"&gt;&lt;li&gt;sdsssssss&lt;/li&gt;&lt;li&gt;qqqq&lt;/li&gt;&lt;li&gt;wwww&lt;/li&gt;&lt;li&gt;eeee&lt;/li&gt;&lt;/ul&gt; 这种书写格式而是使用没有换行的格式书写，是因为在不同的浏览器中，获取ul.childNodes.length的结果有差异： 在ie中，ul.childNodes.length不会计算li之间的换行空格，从而得到数值为4 在ff、chrome,safari中，会有包含li之间的空白符的5个文本节点，因此ul.childNodes.length为9 若要解决跨浏览器问题，可以将li之间的换行去掉，改成一行书写格式。 cloneNode存在跨浏览器的问题 在IE中，通过cloneNode方法复制的元素，会复制事件处理程序，比如，var b = a.cloneNode(true).若a存在click,mouseover等事件监听，则b也会拥有这些事件监听。 在ff,chrome,safari中，通过cloneNode方法复制的元素，只会复制特性，其他一切都不会复制 因此，若要解决跨浏览器问题，在复制前，最好先移除事件处理程序。","categories":[{"name":"前端","slug":"前端","permalink":"http://meng.uno/categories/前端/"}],"tags":[{"name":"前端","slug":"前端","permalink":"http://meng.uno/tags/前端/"}]},{"title":"STL简介","slug":"stl","date":"2017-02-12T12:18:15.000Z","updated":"2018-02-18T10:38:20.010Z","comments":true,"path":"posts/5ae627d/","link":"","permalink":"http://meng.uno/posts/5ae627d/","excerpt":"","text":"STL简介 STL（Standard Template Library，标准模板库)是惠普实验室开发的一系列软件的统称。它是由Alexander Stepanov、Meng Lee和David R Musser在惠普实验室工作时所开发出来的。现在虽说它主要出现在C++中，但在被引入C++之前该技术就已经存在了很长的一段时间。 STL的代码从广义上讲分为三类：algorithm（算法），container（容器）和 iterator（迭代器），几乎所有的代码都采用了模板类和模版函数的方式，这相比于传统的由函数和类组成的库来说提供了更好的代码重用机会。在C++标准中，STL被组织为下面的13个头文件：&lt;algorithm&gt;、&lt;deque&gt;、&lt;functional&gt;、&lt;iterator&gt;、&lt;vector&gt;、&lt;list&gt;、&lt;map&gt;、&lt;memory&gt;、&lt;numeric&gt;、&lt;queue&gt;、&lt;set&gt;、&lt;stack&gt;和&lt;utility&gt;。 算法 大家都能取得的一个共识是函数库对数据类型的选择对其可重用性起着至关重要的作用。 举例来说，一个求方根的函数，在使用浮点数作为其参数类型的情况下的可重用性肯定比使用整型作为它的参数类性要高。而C++通过模板的机制允许推迟对某些类型的选择，直到真正想使用模板或者说对模板进行特化的时候，STL就利用了这一点提供了相当多的有用算法。它是在一个有效的框架中完成这些算法的——你可以将所有的类型划分为少数的几类，然后就可以在模版的参数中使用一种类型替换掉同一种类中的其他类型。 STL提供了大约100个实现算法的模版函数，比如算法for_each将为指定序列中的每一个元素调用指定的函数，stable_sort以你所指定的规则对序列进行稳定性排序等等。这样一来，只要我们熟悉了STL之后，许多代码可以被大大的化简，只需要通过调用一两个算法模板，就可以完成所需要的功能并大大地提升效率。 算法部分主要由头文件&lt;algorithm&gt;，&lt;numeric&gt;和&lt;functional&gt;组成。&lt;algorithm&gt;是所有STL头文件中最大的一个（尽管它很好理解），它是由一大堆模版函数组成的，可以认为每个函数在很大程度上都是独立的，其中常用到的功能范围涉及到比较、交换、查找、遍历操作、复制、修改、移除、反转、排序、合并等等。&lt;numeric&gt;体积很小，只包括几个在序列上面进行简单数学运算的模板函数，包括加法和乘法在序列上的一些操作。&lt;functional&gt;中则定义了一些模板类，用以声明函数对象。 容器 在实际的开发过程中，数据结构本身的重要性不会逊于操作于数据结构的算法的重要性，当程序中存在着对时间要求很高的部分时，数据结构的选择就显得更加重要。 经典的数据结构数量有限，但是我们常常重复着一些为了实现向量、链表等结构而编写的代码，这些代码都十分相似，只是为了适应不同数据的变化而在细节上有所出入。STL容器就为我们提供了这样的方便，它允许我们重复利用已有的实现构造自己的特定类型下的数据结构，通过设置一些模版类，STL容器对最常用的数据结构提供了支持，这些模板的参数允许我们指定容器中元素的数据类型，可以将我们许多重复而乏味的工作简化。 容器部分主要由头文件&lt;vector&gt;, &lt;list&gt;, &lt;deque&gt;, &lt;set&gt;, &lt;map&gt;, &lt;stack&gt; 和 &lt;queue&gt;组成。 对于常用的一些容器和容器适配器（可以看作由其它容器实现的容器），可以通过下表总结一下它们和相应头文件的对应关系。 数据结构 描述 实现头文件 向量(vector) 连续存储的元素 &lt;vector&gt; 列表(list) 由节点组成的双向链表，每个结点包含着一个元素 &lt;list&gt; 双队列(deque) 连续存储的指向不同元素的指针所组成的数组 &lt;deque&gt; 集合(set) 由节点组成的红黑树，每个节点都包含着一个元素，节点之间以某种作用于元素对的谓词排列，没有两个不同的元素能够拥有相同的次序 &lt;set&gt; 多重集合(multiset) 允许存在两个次序相等的元素的集合 &lt;set&gt; 栈(stack) 后进先出的值的排列 &lt;stack&gt; 队列(queue) 先进先出的执的排列 &lt;queue&gt; 优先队列(priority_queue) 元素的次序是由作用于所存储的值对上的某种谓词决定的的一种队列 &lt;queue&gt; 映射(map) 由{键，值}对组成的集合，以某种作用于键对上的谓词排列 &lt;map&gt; 多重映射(multimap) 允许键对有相等的次序的映射 &lt;map&gt; 迭代器 下面要说的迭代器从作用上来说是最基本的部分，可是理解起来比前两者都要费力一些。软件设计有一个基本原则，所有的问题都可以通过引进一个间接层来简化，这种简化在STL中就是用迭代器来完成的。概括来说，迭代器在STL中用来将算法和容器联系起来，起着一种黏和剂的作用。几乎STL提供的所有算法都是通过迭代器存取元素序列进行工作的，每一个容器都定义了其本身所专有的迭代器，用以存取容器中的元素。 迭代器部分主要由头文件&lt;utility&gt;,&lt;iterator&gt;和&lt;memory&gt;组成。&lt;utility&gt;是一个很小的头文件，它包括了贯穿使用在STL中的几个模板的声明，&lt;iterator&gt;中提供了迭代器使用的许多方法，而对于&lt;memory&gt;的描述则十分的困难，它以不同寻常的方式为容器中的元素分配存储空间，同时也为某些算法执行期间产生的临时对象提供机制,&lt;memory&gt;中的主要部分是模板类allocator，它负责产生所有容器中的默认分配器。","categories":[{"name":"Language","slug":"Language","permalink":"http://meng.uno/categories/Language/"},{"name":"STL","slug":"Language/STL","permalink":"http://meng.uno/categories/Language/STL/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://meng.uno/tags/C/"},{"name":"STL","slug":"STL","permalink":"http://meng.uno/tags/STL/"}]},{"title":"HIT操作系统实验总结","slug":"oslab","date":"2017-01-04T12:50:26.000Z","updated":"2018-02-09T10:46:20.931Z","comments":true,"path":"posts/86743755/","link":"","permalink":"http://meng.uno/posts/86743755/","excerpt":"","text":"哈工大《操作系统》六次实验每次需要修改的文件见：修改文件列表 本实验总结源自github项目： MIC 操作系统引导 bootsect.s 实现屏幕输出 修改打印的字符串（空白也算作一个字符） 读入setup.s代码（包括：设置驱动器、磁头，读取setup.s的磁道和扇区，并跳到相应位置开始执行） setup.s （和bootsect.s中部分代码相同）打印相关信息 （原代码已经可以部分打印硬件信息）需要在相关位置嵌入msg实现打印提示信息功能 build.c 将bootsect.s、setup.s、system.s编译、链接生成Image文件 系统调用 unistd.h文件：添加系统调用功能号 sys.h声明新的系统调用处理函数；添加系统调用处理程序索引值到指针数组表中 system_call.s中增加系统调用总数 makefile添加新的系统调用所在文件的编译链接规则（依赖关系） 进程运行轨迹的跟踪与统计 process.c 涉及到fork()和wait()系统调用 主要实现了一个函数——cpuio_bound() 用fork()建立若干个同时运行的子程序 父P等待所有子P退出后才退出，每个子P性质通过cpuio_bound()控制性质 fork.c fork系统调用函数 main.c 内核的入口函数main()，对它的修改是增加日志创建语句，并将log文件关联到文件描述符log文件记录进程状态转换轨迹 kernel 主要寻找进程状态转换点： printk.c sched.c exit.c 信号量的实现和应用 sem_open 打开信号量 sem_wait 信号量P操作——value-- sem_post 信号量V操作——value++ sem_unlink 释放信号量 地址映射与共享 shm.c shmget()：得到一个共享内存标识符或创建一个共享内存对象并返回共享内存标识符 shmat()：连接共享内存标识符为shmid的共享内存，连接成功后把共享内存区对象映射到调用进程的地址空间，随后可像本地空间一样访问 sem.c 实现信号量的四种操作，与实验四相同 字符显示的控制 keyboard.S 添加对字符F12的输入判断 console.c 添加输出到控制台的字符控制 file_dev.c 添加输出到文件的字符控制","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://meng.uno/categories/操作系统/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://meng.uno/tags/操作系统/"}]},{"title":"手写数字识别（SVM）","slug":"svm_number_recog","date":"2016-12-17T04:08:13.000Z","updated":"2018-02-17T02:12:08.406Z","comments":true,"path":"posts/7dac38a/","link":"","permalink":"http://meng.uno/posts/7dac38a/","excerpt":"","text":"调用第三方库 在此我选用的是sk-learn的关于svm的库，其关于此次实验的svm函数定义为： svm.SVC(C=8.0, kernel='rbf', gamma=0.1) svm.SVC()函数的几个重要参数在其官方的介绍文档中有如下的解释： C :误差项的惩罚参数，浮点型，可选 (默认=1.0)； kernel : 指定核函数类型，字符型，可选 (默认=‘rbf’)，如果使用自定义的核函数，需要预先计算核矩阵； gamma : 浮点型, 可选 (默认=0.0)，’rbf’核函数的系数，需要注意的是，此处的gamma与课本中的sigma是互为倒数的关系（所以其可以为0）。 因为是调用别人的库（应该说完全是别人的功劳），所以在实现上没有什么可以说的。 代码 123456789101112131415161718192021222324252627282930313233 #!/usr/bin/env python3# -*- coding: utf-8 -*-\"\"\"Created on Thu Dec 1 13:30:21 2016@author: kuangmeng使用SVM分类器，从MNIST数据集中进行手写数字识别的分类程序\"\"\"import cPickleimport gzipfrom sklearn import svmimport timedef load_data(): \"\"\" 返回包含训练数据、验证数据、测试数据的元组的模式识别数据 \"\"\" f = gzip.open('data.gz', 'rb') training_data, validation_data, test_data = cPickle.load(f) f.close() return (training_data, validation_data, test_data)def Svm(): print (\"开始时间：\",time.strftime('%Y-%m-%d %H:%M:%S')) training_data, validation_data, test_data = load_data() # 传递训练模型的参数，这里用默认的参数 clf = svm.SVC(C=10.0, kernel='rbf', gamma=0.10,cache_size=8000,probability=False) # 进行模型训练 clf.fit(training_data[0], training_data[1]) # 测试集测试预测结果 predictions = [int(a) for a in clf.predict(test_data[0])] num_correct = sum(int(a == y) for a, y in zip(predictions, test_data[1])) print (\"%s 中的 %s 测试正确。\" % (num_correct, len(test_data[1]))) print (\"结束时间：\",time.strftime('%Y-%m-%d %H:%M:%S'))if __name__ == \"__main__\": Svm() 自己编程实现 在自己编程实现过程中，我也借鉴了很多其他人写的很成熟的方案，最终从数据结构、逻辑结构以及特征计算等方面得到比较合理的一组答案。 逻辑结构 本次实验的程序分为“训练”和“测试”两部分，两部分分别进行的工作如下： 训练 加载数据 初始化模型 更新标签 初始化预测误差 迭代每个样本（用KT优化） 得到每个样本的模型 对步骤5的解释： 对于svm我们要求解a（数组），如果 a的所有分量满足svm对偶问题的KKT条件，那么这个问题的解就求出来了，我们svm模型学习也就完成了。如果没有满足KKT，那么我们就在 a中找两个分量 ai和 aj，其中 ai 是违反KKT条件最严重的分量，通过计算，使得 ai 和 aj满足KKT条件，直到a的所有分量都满足KKT条件。而且这个计算过程是收敛的，因为每次计算出来的新的两个分量，使得对偶问题中要优化的目标函数值更小。因为每次求解的那两个分量，是要优化问题在这两个分量上的极小值，所以每一次优化，都会使目标函数比上一次的优化结果的值变小。 测试 加载数据 对每个数据预测 计算正确率与相关信息逻辑结构 特征计算 仿照KKT的优化方法，在本次试验中，我将每张图片作为一个数据。由此得到对每一个测试样本的预测（如果在某个分类的计算时结果为正，则说明该测试样本属于该类别，结果为0则不属于此类别）。 其他杂项 核函数选择：按照传统，选择的是RBF核函数，函数形式与教材完全相同； 数据来源：来源自网友整理之后的数据（测试数据与训练数据没有均分）； SMO优化算法： 取初始值a(0)=0，令K=0； 选取优化变量a1(k) , a2(k) , 针对优化问题，求得最优解 a1(k+1) , a2(k+1) 更新 a(k) 为 a(k+1) ； 在精度条件范围内是否满足停机条件，即是否有变量违反KKT条件，如果违反了，则令k=k+1，跳转2，否则4； 求得近似解â =a(k+1) 其中第3步中，是否违反KKT条件，对于a(k)的每个分量按照以下的违反KKT条件的公式进行验算即可。 变量选取分为两步，第一步是选取违反KKT条件最严重的ai，第二步是根据已经选取的第一个变量，选择优化程度最大的第二个变量。 违反KKT条件最严重的变量可以按照这样的规则选取，首先看0&lt;ai&lt;C的那些分量中，是否有违反KKT条件的，如果有，则选取yig(xi)最小的那个做为a1。如果没有则遍历所有的样本点，在违反KKT条件的分量中选取yig(xi)最小的做为a1。 当选择了a1后，如果a1对应的E1为正，选择Ei最小的那个分量最为a2，如果E1为负，选择Ei最大的那个分量最为a2，这是因为anew2依赖于|E1−E2|。 如果选择的a2，不能满足下降的最小步长，那么就遍历所有的支持向量点做为a2进行试用，如果仍然都不能满足下降的最小步长，那么就遍历所有的样本点做为a2试用。如果还算是不能满足下降的最小步长，那么就重新选择a1。 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237 #!/usr/bin/env python3# -*- coding: utf-8 -*-\"\"\"Created on Sun Dec 4 14:24:53 2016@author: kuangmeng\"\"\"import timeimport osimport mathclass model: def __init__(self): self.a = [] self.b = 0.0 class DATA: def __init__(self): self.samples = [] # 样本数据 self.tests = [] # 测试数据 self.models = [] # 训练的模型 self.forecasterror = [] # 预测知与真实y之差Ei self.modelnum = 0 # 当前正使用或训练的模型 self.cache= [] # 缓存kernel函数的计算结果 self.sigma = 10 # sigma def init_models(self): for i in range(0, 10): m = model() for j in range(len(self.samples)): m.a.append(0) self.models.append(m) def init_cache(self): i = 0 for x in self.samples: print (\"正在计算第\",i+1,\"个样本的RBF核\") self.cache.append([]) j = 0 for z in self.samples: if i &gt; j: self.cache[i].append(self.cache[j][i]) else: self.cache[i].append(RBF(x,z)) j += 1 i += 1 class image: def __init__(self): self.data = [] self.num = 0 self.label = [] self.filename = \"\"gv = DATA()# RBF核函数def RBF(j, i): if j == i: return math.exp(0) sigma = gv.sigma ret = 0.0 for m in range(len(j.data)): for n in range(len(j.data[m])): ret += math.pow(int(j.data[m][n]) - int(i.data[m][n]), 2) ret = math.exp(-ret/sigma) return ret#加载测试与训练数据def loaddata(dirpath, name): files = os.listdir(dirpath) for file in files: img = image() img.data = images(dirpath + file) img.num = int(file[0]) img.filename = file name.append(img)#图片分列 def images(path): img = [] file = open(path, \"r\") for line in file: line = line[:-2] img.append(line) return img #更新样本标签，正在训练啥就将啥的标签定为1，其他的定为-1 def update_samples_label(num): for img in gv.samples: if img.num == num: img.label.append(1) else: img.label.append(-1) #初始化DATA.forecasterrordef init_forecasterror(): gv.forecasterror = [] for i in range(len(gv.samples)): diff = 0.0 for j in range(len(gv.samples)): if gv.models[gv.modelnum].a[j] != 0: diff += gv.models[gv.modelnum].a[j] * gv.samples[j].label[gv.modelnum] * gv.cache[j][i] diff += gv.models[gv.modelnum].b diff -= gv.samples[i].label[gv.modelnum] gv.forecasterror.append(diff)#更新DATA.forecasterror def update_forecasterror(i, new_ai, j, new_bj, new_b): for idx in range(len(gv.samples)): diff = (new_ai - gv.models[gv.modelnum].a[i])* gv.samples[i].label[gv.modelnum] * gv.cache[i][idx] diff += (new_bj - gv.models[gv.modelnum].a[j])* gv.samples[j].label[gv.modelnum] * gv.cache[j][idx] diff += new_b - gv.models[gv.modelnum].b diff += gv.forecasterror[idx] gv.forecasterror[idx] = diff# g(x)def predict(m): pred = 0.0 for j in range(len(gv.samples)): if gv.models[gv.modelnum].a[j] != 0: pred += gv.models[gv.modelnum].a[j] * gv.samples[j].label[gv.modelnum] * RBF(gv.samples[j],m) pred += gv.models[gv.modelnum].b return preddef save_models(): for i in range(10): fn = open(\"models/\" + str(i) + \"_a.model\", \"w\") for ai in gv.models[i].a: fn.write(str(ai)) fn.write('\\n') fn.close() fn = open(\"models/\" + str(i) + \"_b.model\", \"w\") fn.write(str(gv.models[i].b)) fn.close()def load_models(): for i in range(10): fn = open(\"models/\" + str(i) + \"_a.model\", \"r\") j = 0 for line in fn: gv.models[i].a[j] = float(line) j += 1 fn.close() fn = open(\"models/\" + str(i) + \"_b.model\", \"r\") gv.models[i].b = float(fn.readline()) fn.close()#### T: tolerance 误差容忍度(精度)# times: 迭代次数# 优化方法：SMO# C: 惩罚系数# modelnum: 模型序号0到9# step: aj移动的最小步长###def train(T, times, C, modelnum, step): time = 0 gv.modelnum = modelnum update_samples_label(modelnum) init_forecasterror() updated = True while time &lt; times and updated: updated = False time += 1 for i in range(len(gv.samples)): ai = gv.models[gv.modelnum].a[i] Ei = gv.forecasterror[i] #计算违背KKT的点 if (gv.samples[i].label[gv.modelnum] * Ei &lt; -T and ai &lt; C) or (gv.samples[i].label[gv.modelnum] * Ei &gt; T and ai &gt; 0): for j in range(len(gv.samples)): if j == i: continue kii = gv.cache[i][i] kjj = gv.cache[j][j] kji = kij = gv.cache[i][j] eta = kii + kjj - 2 * kij if eta &lt;= 0: continue new_aj = gv.models[gv.modelnum].a[j] + gv.samples[j].label[gv.modelnum] * (gv.forecasterror[i] - gv.forecasterror[j]) / eta # f 7.106 L = 0.0 H = 0.0 a1_old = gv.models[gv.modelnum].a[i] a2_old = gv.models[gv.modelnum].a[j] if gv.samples[i].label[gv.modelnum] == gv.samples[j].label[gv.modelnum]: L = max(0, a2_old + a1_old - C) H = min(C, a2_old + a1_old) else: L = max(0, a2_old - a1_old) H = min(C, C + a2_old - a1_old) if new_aj &gt; H: new_aj = H if new_aj &lt; L: new_aj = L if abs(a2_old - new_aj) &lt; step: # print (\"j = %d, is not moving enough\" % j) continue new_ai = a1_old + gv.samples[i].label[gv.modelnum] * gv.samples[j].label[gv.modelnum] * (a2_old - new_aj) # f 7.109 new_b1 = gv.models[gv.modelnum].b - gv.forecasterror[i] - gv.samples[i].label[gv.modelnum] * kii * (new_ai - a1_old) - gv.samples[j].label[gv.modelnum] * kji * (new_aj - a2_old) # f7.115 new_b2 = gv.models[gv.modelnum].b - gv.forecasterror[j] - gv.samples[i].label[gv.modelnum]*kji*(new_ai - a1_old) - gv.samples[j].label[gv.modelnum]*kjj*(new_aj-a2_old) # f7.116 if new_ai &gt; 0 and new_ai &lt; C: new_b = new_b1 elif new_aj &gt; 0 and new_aj &lt; C: new_b = new_b2 else: new_b = (new_b1 + new_b2) / 2.0 update_forecasterror(i, new_ai, j, new_aj, new_b) gv.models[gv.modelnum].a[i] = new_ai gv.models[gv.modelnum].a[j] = new_aj gv.models[gv.modelnum].b = new_b updated = True print (\"迭代次数: %d, 修改组合: i: %d 与 j:%d\" %(time, i, j)) break# 测试数据def test(): record = 0 record_correct = 0 for img in gv.tests: print (\"正在测试：\", img.filename) for modelnum in range(10): gv.modelnum = modelnum if predict(img) &gt; 0: print (\"测试结果：\",modelnum) record += 1 if modelnum == int(img.filename[0]): record_correct += 1 break print (\"相关记录数量:\", record) print (\"正确识别数量:\", record_correct) print (\"正确识别比例:\", record_correct/record) print (\"测试数据总量:\", len(gv.tests))if __name__ == \"__main__\": print (\"开始时间：\",time.strftime('%Y-%m-%d %H:%M:%S')) training = True loaddata(\"train/\", gv.samples) loaddata(\"test/\", gv.tests) print (\"训练数据个数：\",len(gv.samples)) print (\"测试数据个数：\",len(gv.tests)) if training == True: gv.init_cache() gv.init_models() print (\"模型初始化成功！\") print (\"当前时间：\",time.strftime('%Y-%m-%d %H:%M:%S')) T = 0.0001 C = 10 step = 0.001 gv.sigma = 1 if training == True: for i in range(10): print (\"正在训练模型:\", i) train(T, 10, C, i, step) save_models() else: load_models() for i in range(10): update_samples_label(i) print (\"训练完成时间：\",time.strftime('%Y-%m-%d %H:%M:%S')) test() print (\"测试完成时间：\",time.strftime('%Y-%m-%d %H:%M:%S'))","categories":[{"name":"AI","slug":"AI","permalink":"http://meng.uno/categories/AI/"},{"name":"模式识别","slug":"AI/模式识别","permalink":"http://meng.uno/categories/AI/模式识别/"}],"tags":[{"name":"模式识别","slug":"模式识别","permalink":"http://meng.uno/tags/模式识别/"}]},{"title":"多项式拟合曲线——最小二乘法","slug":"least_square_method","date":"2016-12-17T03:59:39.000Z","updated":"2018-02-17T02:10:59.079Z","comments":true,"path":"posts/1af17fd9/","link":"","permalink":"http://meng.uno/posts/1af17fd9/","excerpt":"","text":"直接上代码，最小二乘法比较简单，在拟合效果上也相当不错： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364 # -*- coding: utf-8 -*-import matplotlib.pyplot as pltimport numpyimport randomf = plt.figure()draw = f.add_subplot(111)#拟合函数的次数限制times=9tail=times+1x = numpy.arange(-2,2,0.1)y = [((xi-1)*(xi*xi-1)+0.5)*numpy.cos(xi) for xi in x]#所有使用到的全局变量声明i=0xlabel=[]ylabel=[]A=[]B=[]tempA=[]tempB=[]X=[]Y=[]#-----------------------------#生成数据，加入cos函数，作为噪声！for xi in x: r=float(random.randint(80,100))/100 xlabel.append(xi*r) ylabel.append(y[i]*r) i+=1draw.plot(xlabel,ylabel,color='b',linestyle='',marker='*')length=len(xlabel)for i in range(0,tail): tempA=[] for j in range(0,tail): temp=0.0 for k in range(0,length): d=1.0 for m in range(0,j+i): d=d*xlabel[k] temp+=d tempA.append(temp) A.append(tempA)for i in range(0,tail): temp=0.0 for k in range(0,length): d=1.0 for j in range(0,i): d=d*xlabel[k] temp+=ylabel[k]*d B.append(temp) #X为可行解X=numpy.linalg.solve(A,B)print('可行解a(x的系数)的矩阵表示为：[a0,---,a%d]'%(times))print(X)for i in range(0,length): temp=0.0 for j in range(0,tail): d=1.0 for k in range(0,j): d*=x[i] d*=X[j] temp+=d Y.append(temp)draw.plot(x,Y,color='r',linestyle='-',marker='.')","categories":[{"name":"AI","slug":"AI","permalink":"http://meng.uno/categories/AI/"},{"name":"机器学习","slug":"AI/机器学习","permalink":"http://meng.uno/categories/AI/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://meng.uno/tags/机器学习/"}]},{"title":"主成分分析（PCA）","slug":"pca","date":"2016-12-17T03:52:21.000Z","updated":"2018-02-17T02:11:23.106Z","comments":true,"path":"posts/6c0d033f/","link":"","permalink":"http://meng.uno/posts/6c0d033f/","excerpt":"","text":"实验要求 实验目标 实现一个PCA模型，能够对给定数据进行降维（即找到其中的主成分） 实验过程 首先人工生成一些数据（如三维数据），让它们主要分布在低维空间中，如首先让某个维度的方差远小于其它维度，然后对这些数据旋转。生成这些数据后，用你的PCA方法进行主成分提取。 找一个人脸数据（小点样本量），用你实现PCA方法对该数据降维，找出一些主成分，然后用这些主成分对每一副人脸图像进行重建，比较一些它们与原图像有多大差别（用信噪比衡量）。 实验准备 降维的必要 多重共线性--预测变量之间相互关联。多重共线性会导致解空间的不稳定，从而可能导致结果的不连贯。 高维空间本身具有稀疏性。一维正态分布有68%的值落于正负标准差之间，而在十维空间上只有0.02%。 过多的变量会妨碍查找规律的建立。 仅在变量层面上分析可能会忽略变量之间的潜在联系。例如几个预测变量可能落入仅反映数据某一方面特征的一个组内。 降维的目的 减少预测变量的个数 确保这些变量是相互独立的 提供一个框架来解释结果 降维的方法 主成分分析 因子分析 用户自定义复合 有关PCA PCA概念 主成分分析 （ Principal Component Analysis ， PCA ）或者主元分析。是一种掌握事物主要矛盾的统计分析方法，它可以从多元事物中解析出主要影响因素，揭示事物的本质，简化复杂的问题。计算主成分的目的是将高维数据投影到较低维空间。给定 n 个变量的 m 个观察值，形成一个 n * m 的数据矩阵， n 通常比较大。对于一个由多个变量描述的复杂事物，人们难以认识，那么是否可以抓住事物主要方面进行重点分析呢？如果事物的主要方面刚好体现在几个主要变量上，我们只需要将这几个变量分离出来，进行详细分析。但是，在一般情况下，并不能直接找出这样的关键变量。这时我们可以用原有变量的线性组合来表示事物的主要方面， PCA 就是这样一种分析方法。 PCA作用范围 PCA 主要用于数据降维，对于一系列例子的特征组成的多维向量，多维向量里的某些元素本身没有区分性，比如某个元素在所有的例子中都为1，或者与1差距不大，那么这个元素本身就没有区分性，用它做特征来区分，贡献会非常小。所以我们的目的是找那些变化大的元素，即方差大的那些维，而去除掉那些变化不大的维，从而使特征留下的都是“精品”，而且计算量也变小了。 对于一个K维的特征来说，相当于它的每一维特征与其他维都是正交的（相当于在多维坐标系中，坐标轴都是垂直的），那么我们可以变化这些维的坐标系，从而使这个特征在某些维上方差大，而在某些维上方差很小。 PCA的算法步骤 设有m条n维数据。 将原始数据按列组成n行m列矩阵X 将X的每一行（代表一个属性字段）进行零均值化，即减去这一行的均值 求出协方差矩阵C=1/mXX’ 求出协方差矩阵的特征值及对应的特征向量 将特征向量按对应特征值大小从上到下按行排列成矩阵，取前k行组成矩阵P Y=PX即为降维到k维后的数据 实验环境 Spyder 作为Python开发的集成开发环境； 编程语言：Python 3.5 操作系统：macOS Sierra 小结 PCA的应用分析 对于一个训练集，100个对象模板，特征是10维，那么它可以建立一个100*10的矩阵，作为样本。求这个样本的协方差矩阵，得到一个10*10的协方差矩阵，然后求出这个协方差矩阵的特征值和特征向量，应该有10个特征值和特征向量，我们根据特征值的大小，取前四个特征值所对应的特征向量，构成一个10*4的矩阵，这个矩阵就是我们要求的特征矩阵，100*10的样本矩阵乘以这个10*4的特征矩阵，就得到了一个100*4的新的降维之后的样本矩阵，每个特征的维数下降了。当给定一个测试的特征集之后，比如1*10维的特征，乘以上面得到的10*4的特征矩阵，便可以得到一个1*4的特征，用这个特征去分类。所以做PCA实际上是求得这个投影矩阵，用高维的特征乘以这个投影矩阵，便可以将高维特征的维数下降到指定的维数。 在进行基因表达数据分析时，一个重要问题是确定每个实验数据是否是独立的，如果每次实验数据之间不是独立的，则会影响基因表达数据分析结果的准确性。对于利用基因芯片所检测到的基因表达数据，如果用 PCA 方法进行分析，可以将各个基因作为变量，也可以将实验条件作为变量。当将基因作为变量时，通过分析确定一组“主要基因元素”，它们能够很好地说明基因的特征，解释实验现象；当将实验条件作为变量时，通过分析确定一组“主要实验因素”，它们能够很好地刻画实验条件的特征，解释基因的行为。 PCA作为基础的数学分析方法，其实际应用十分广泛，比如人口统计学、数量地理学、分子动力学模拟、数学建模、数理分析等学科中均有应用，是一种常用的多变量分析方法。 PCA优缺点 优点： 以方差衡量信息的无监督学习，不受样本标签限制； 各主成分之间正交，可消除原始数据成分间的相互影响； 可减少指标选择的工作量； 用少数指标代替多数指标，利用PCA降维是最常用的算法； 计算方法简单，易于实现。 缺点： 主成分解释其含义往往具有一定的模糊性，不如原始样本完整； 贡献率小的主成分往往可能含有对样本差异的重要信息； 特征值矩阵的正交向量空间是否唯一有待讨论； 属于无监督学习。 代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465 #!/usr/bin/env python3# -*- coding: utf-8 -*-\"\"\"Created on Tue Nov 29 15:51:25 2016@author: kuangmeng\"\"\"import numpy as npimport matplotlib.pyplot as plt#全局变量定义区XLabel = list()YLabel = list()phi = [0., 0.]#自己定义的矩阵转换函数def Transport(matrix): temp = list() for i in range(len(matrix[0])): temp.append(list()) for j in range(len(matrix)): temp[i].append(matrix[j][i]) return temp#加载文件（可以通过更改文件名来加载不同的测试数据）data_set = open('testSet.txt', 'r')for line in data_set.readlines(): data_line = line.strip().split() tmpx = float(data_line[0]) tmpy = float(data_line[1]) phi[0] += tmpx phi[1] += tmpy XLabel.append(tmpx) YLabel.append(tmpy)phi[0] = phi[0]/100.0phi[1] = phi[1]/100.0data_set.close()#加载结束temp_x = list()for i in range(100): temp_x.append([XLabel[i]-phi[0], YLabel[i]-phi[1]])temp_x_ = Transport(temp_x)sigma = np.dot(temp_x_, temp_x)D,V= np.linalg.eig(sigma)for i in range(2): for j in range(2): V.real[i][j] *= -1temp_v_ = Transport(V.real)tr1 = list()tr1.append(XLabel)tr1.append(YLabel)tr1 = Transport(tr1)xr1 = np.dot(tr1, temp_v_[0])xr2 = np.dot(phi, temp_v_[1])xr = tr1# print xrfor i in range(len(XLabel)): xr[i][0] = np.dot(xr1[i], V.real[0][0])+np.dot(xr2, V.real[0][1]) xr[i][1] = np.dot(xr1[i], V.real[1][0])+np.dot(xr2, V.real[1][1])# print xrplt.plot(XLabel, YLabel, 'r+')temp_xr = Transport(xr)plt.plot(temp_xr[0], temp_xr[1], 'b*')for i in range(len(XLabel)): plt.plot([XLabel[i],xr[i][0]], [YLabel[i],xr[i][1]])plt.axis([-8,6,-5,5])plt.xlabel = 'x'plt.ylabel = 'y'plt.show()","categories":[{"name":"AI","slug":"AI","permalink":"http://meng.uno/categories/AI/"},{"name":"机器学习","slug":"AI/机器学习","permalink":"http://meng.uno/categories/AI/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://meng.uno/tags/机器学习/"}]},{"title":"使用EM算法优化的GMM","slug":"gmm","date":"2016-12-17T03:16:53.000Z","updated":"2018-02-17T02:10:30.701Z","comments":true,"path":"posts/177fbbcc/","link":"","permalink":"http://meng.uno/posts/177fbbcc/","excerpt":"","text":"先上代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113 # -*- coding: utf-8 -*-import numpy as npimport matplotlib.pyplot as matimport matplotlib.mlab as mlab#EM算法def EM(dataSet,K): (N, M) = np.shape(dataSet) W = np.zeros([N, K]) P= N/K for k in range(K): W[np.floor(k*P):np.floor((k+1)*P), k] = 1 A,M,S = Mstep(dataSet,W) return W, A, M, S#M的跨度def Mstep(data,W): (N, M) = np.shape(data) K = np.size(W,1) Nk = np.sum(W,0) A = Nk/np.sum(Nk) Mm = data.T.dot(W).dot(np.diag(np.reciprocal(Nk))) S = np.zeros([M,M,K]) for k in range(K): datMean = data.T - Mm[0:,k][None].T.dot(np.ones([1,N])) S[:,:,k] = (datMean.dot(np.diag(W[0:,k])).dot(datMean.T))/Nk[k] return A,Mm,S#E的跨度def Estep(data,A,M,S): N = np.size(data,0) K = np.size(A) W = np.zeros([N,K]) for k in range(K): for i in range(N): W[i,k] = A[k]*multivariate(data[i,:][None].T, \\ M[:,k][None].T,S[:,:,k]) W = W*np.reciprocal(np.sum(W,1)[None].T) return Wdef multivariate(x, m, s): if len(x) == len(m) and (len(x), len(x)) == s.shape: det = np.linalg.det(s) const = 1.0/(np.math.pow((2*np.pi), float(len(x))/2) * np.math.pow(det, 1.0/2)) x_m = np.matrix(x - m) inv_ = np.linalg.inv(s) result = np.math.pow(np.math.e, -0.5 * (x_m.T * inv_ * x_m)) return const * result else: return -1#GMM主程序def GMM(): # 加载文件 input_file = open('points.dat') lines = input_file.readlines() Data = np.array([line.strip().split() for line in lines]).astype(np.float) (x, y) = np.shape(Data) mat.draw() mat.pause(0.01) mat.subplot(111) mat.plot(x, y, 'b*') learn = Data[np.math.ceil(x*0.8):x, 0:] train = Data[:np.math.floor(x*0.8), 0:] trainnum = 16 (W, Alpha, Mu, Sigma) = EM(train,trainnum) m = np.arange(-4.0, 4.0, 0.1) n = np.arange(-4.0, 4.0, 0.1) ax, ay = np.meshgrid(m, n) i = 0 prev = -9999 mat.clf() while(True): if(False): SigmaSum = np.sum(Sigma,2) for k in range(trainnum): Sigma[:,:,k] = SigmaSum W = Estep(train,Alpha,Mu,Sigma) Alpha,Mu,Sigma = Mstep(train,W) # trains = logLike(train,Alpha,Mu,Sigma) N,M = np.shape(train) P = np.zeros([N,len(Alpha)]) for k in range(len(Alpha)): for j in range(N): P[j,k] = multivariate(train[j,:][None].T,Mu[0:,k][None].T,Sigma[:,:,k]) trains = np.sum(np.log(P.dot(Alpha))) i = i + 1 #画图，训练和测试样本 mat.subplot(211) mat.scatter(train[0:,0],train[0:,1]) mat.hold(True) for k in range(0, trainnum): az = mlab.bivariate_normal(ax, ay, Sigma[0, 0, k], Sigma[1, \\ 1, k], Mu[0,k], Mu[1,k], Sigma[1, 0, k]) try: mat.contour(ax, ay, az) except: continue mat.hold(False) # Render these mat.draw() mat.pause(0.01) mat.subplot(212) mat.scatter(learn[0:,0],learn[0:,1]) mat.hold(True) for k in range(0, trainnum): az = mlab.bivariate_normal(ax, ay, Sigma[0, 0, k], Sigma[1, \\ 1, k], Mu[0,k], Mu[1,k], Sigma[1, 0, k]) try: mat.contour(ax, ay, az) except: continue mat.hold(False) if(i&gt;150 or abs(trains - prev)&lt; 0.01): break prev = trainsif __name__ == '__main__': GMM() 实验要求 实验目标 实现一个混合高斯模型，并且用EM算法估计模型中的参数。 实验过程 用混合高斯模型产生k个高斯分布的数据（其中参数自己设定），然后用你实现的EM算法估计参数，看看每次迭代后似然值变化情况，考察EM算法是否可以获得正确的结果（与你设定的结果比较）。 可以UCI上找一个简单问题数据，用你实现的GMM进行聚类。 算法原理 GMM算法 高斯模型就是用高斯概率密度函数（正态分布曲线）精确地量化事物，将一个事物分解为若干的基于高斯概率密度函数（正态分布曲线）形成的模型。 对图像背景建立高斯模型的原理及过程：图像灰度直方图反映的是图像中某个灰度值出现的频次，也可以认为是图像灰度概率密度的估计。如果图像所包含的目标区域和背景区域相比比较大，且背景区域和目标区域在灰度上有一定的差异，那么该图像的灰度直方图呈现双峰-谷形状，其中一个峰对应于目标，另一个峰对应于背景的中心灰度。对于复杂的图像，尤其是医学图像，一般是多峰的。通过将直方图的多峰特性看作是多个高斯分布的叠加，可以解决图像的分割问题。 在智能监控系统中，对于运动目标的检测是中心内容，而在运动目标检测提取中，背景目标对于目标的识别和跟踪至关重要。而建模正是背景目标提取的一个重要环节。 我们首先要提起背景和前景的概念，前景是指在假设背景为静止的情况下，任何有意义的运动物体即为前景。建模的基本思想是从当前帧中提取前景，其目的是使背景更接近当前视频帧的背景。即利用当前帧和视频序列中的当前背景帧进行加权平均来更新背景,但是由于光照突变以及其他外界环境的影响，一般的建模后的背景并非十分干净清晰，而高斯混合模型是是建模最为成功的方法之一。 混合高斯模型使用K（基本为3到5个）个高斯模型来表征图像中各个像素点的特征,在新一帧图像获得后更新混合高斯模型, 用当前图像中的每个像素点与混合高斯模型匹配,如果成功则判定该点为背景点, 否则为前景点。 通观整个高斯模型，主要是有方差和均值两个参数决定，对均值和方差的学习，采取不同的学习机制,将直接影响到模型的稳定性、精确性和收敛性 。由于我们是对运动目标的背景提取建模，因此需要对高斯模型中方差和均值两个参数实时更新。为提高模型的学习能力,改进方法对均值和方差的更新采用不同的学习率;为提高在繁忙的场景下,大而慢的运动目标的检测效果,引入权值均值的概念,建立背景图像并实时更新,然后结合权值、权值均值和背景图像对像素点进行前景和背景的分类。 具体实现过程： 为图像的每个像素点指定一个初始的均值、标准差以及权重。 收集N（一般取200以上，否则很难得到像样的结果）帧图像利用在线EM算法得到每个像 素点的均值、标准差以及权重。 从N+1帧开始检测，检测的方法： 对每个像素点： 将所有的高斯核按照 ω / σ 降序排序 选择满足下式的前M个高斯核：M = arg min(ω / σ &gt; T) 如果当前像素点的像素值在中有一个满足：就可以认为其为背景点。 更新背景图像，用EM算法。 EM算法 EM 算法是 Dempster，Laind，Rubin 于 1977 年提出的求参数极大似然估计的一种方法，它可以从非完整数据集中对参数进行 MLE 估计，是一种非常简单实用的学习算法。这种方法可以广泛地应用于处理缺损数据，截尾数据，带有噪声等所谓的不完全数据(incomplete data)。 最大期望算法经过两个步骤交替进行计算： 第一步是计算期望（E），利用对隐藏变量的现有估计值，计算其最大似然估计值； 第二步是最大化（M），最大化在 E 步上求得的最大似然值来计算参数的值。 M 步上找到的参数估计值被用于下一个 E 步计算中，这个过程不断交替进行。 通过交替使用这两个步骤，EM算法逐步改进模型的参数，使参数和训练样本的似然概率逐渐增大，最后终止于一个极大点。直观地理解EM算法，它也可被看作为一个逐次逼近算法：事先并不知道模型的参数，可以随机的选择一套参数或者事先粗略地给定某个初始参数λ0 ，确定出对应于这组参数的最可能的状态，计算每个训练样本的可能结果的概率，在当前的状态下再由样本对参数修正，重新估计参数λ，并在新的参数下重新确定模型的状态，这样，通过多次的迭代，循环直至某个收敛条件满足为止，就可以使得模型的参数逐渐逼近真实参数。 具体实现步骤： 给出种类数k,初始化每一类高斯分布的均值μk，方差∑k以及每一类的概率πk； 执行EM； 计算似然，如果没有达到预期效果，则返回第2步； 计算每个数据点对于k个高斯分布的似然，选择似然最大的一类作为数据的最终分类。 其他的混合模型，例如朴素贝叶斯混合模型也是可以使用EM算法推出使用的，这一算法虽然在GMM中作为参数使用，但是其仍然可以单独发挥作用。我觉得EM算法就是相互迭代（毕竟其由E和M两部分组成嘛），求出一个稳定值，而这种相互迭代的方法用的范围挺广的，例如混合模型，K-means等都需要使用。 与K-means的区别 在上文我也已经提到了EM算法可以用在K-means等其他需要迭代的方法上的事实，其实，我觉得GMM 和 K-means 很像，只不过后者要简单，而且相对来说实现并不是很高效。不过 GMM 是学习出一些概率密度函数来（所以 GMM 除了用在 clustering 上之外，还经常被用于 density estimation ），简单地说，K-means 的结果是每个数据点被 assign 到其中某一个 cluster 了，而 GMM 则给出这些数据点被 assign 到每个 cluster 的概率，又称作 soft assignment。 实验环境 Spyder 作为Python开发的集成开发环境； 编程语言：Python 3.5； 操作系统：macOS Sierra。 小结 GMM算法作为EM算法族的一个例子，它指定了各个参与杂合的分布都是高斯分布，即分布参数表现为均值Mu和方差Sigma。通过EM算法作为计算使用的框架，迭代地算出各个高斯分布的参数。 GMM与K-means的思考 提到GMM不得不提K-means，总结了网上的资料以及老师上课的课件，我将两者的区别与联系陈述如下： 两者的联系: 都是迭代执行的算法，且迭代的策略也相同：算法开始执行时先对需要计算的参数赋初值，然后交替执行两个步骤，一个步骤是对数据的估计（k-means是估计每个点所属簇；GMM是计算隐含变量的期望）；第二步是用上一步算出的估计值重新计算参数值，更新目标参数（k-means是计算簇心位置；GMM是计算各个高斯分布的中心位置和协方差矩阵） 两者的区别: 首先，两者需要计算的参数不同：K-means是簇心位置；GMM是各个高斯分布的参数；其次，两者计算目标参数的方法不同：K-means是计算当前簇中所有元素的位置的均值；GMM是基于概率的算法，是通过计算似然函数的最大值实现分布参数的求解的。 关于GMM引发的过拟合的思考 首先我想提到这样的一个“人辨认其他生物（例如鱼）”的例子。当我们被告知水里游的那个生物是鱼之后，我们会使用“在同样的地方生活的是同一种东西”这类似的假设，归纳出“在水里游的都是鱼”这样一个结论。当然这个过程是完全“本能”的，如果不仔细去想，我们也不会了解自己是怎样“认识鱼”的。另一个值得注意的地方是这样的假设并不总是完全正确的，甚至可以说总是会有这样那样的缺陷的，因为我们有可能会把虾、龟、甚至是潜水员当做鱼。也许你觉得可以通过修改前提假设来解决这个问题，例如，基于“生活在同样的地方并且穿着同样衣服的是同一种东西”这个假设，你得出结论：在水里有并且身上长有鳞片的是鱼。可是这样还是有问题，因为有些没有长鳞片的鱼现在又被你排除在外了。 机器在识别方面面临着和人一样的问题，在机器学习中，一个学习算法也会有一个前提假设，这里被称作“归纳偏执”。例如线性回归，目的是要找一个函数尽可能好地拟合给定的数据点，它的归纳偏执就是“满足要求的函数必须是线性函数”。一个没有归纳偏执的学习算法从某种意义上来说毫无用处，就像一个完全没有归纳能力的人一样，在第一次看到鱼的时候有人告诉他那是鱼，下次看到另一条鱼了，他并不知道那也是鱼，因为两条鱼总有一些地方不一样的，或者就算是同一条鱼，在河里不同的地方看到，或者只是看到的时间不一样，也会被他认为是不同的，因为他无法归纳，无法提取主要矛盾、忽略次要因素，只好要求所有的条件都完全一样──然而哲学家已经告诉过我们了：世界上不会有任何样东西是完全一样的，所以这个人即使是有无比强悍的记忆力，也绝学不到任何一点知识。 于是有了上面的铺垫，我们就可以引出论题——“过拟合 ”，就像前面的回归的问题，如果去掉“线性函数”这个归纳偏执，因为对于 N 个点，我们总是可以构造一个 N-1 次多项式函数，让它完美地穿过所有的这 N 个点，或者如果我用任何大于 N-1 次的多项式函数的话，我们甚至可以构造出无穷多个满足条件的函数出来。如果假定特定领域里的问题所给定的数据个数总是有个上限的话，我可以取一个足够大的 N ，从而得到一个（或者无穷多个）“超级函数”，能够拟合这个领域内所有的问题。 没有归纳偏执或者归纳偏执太宽泛会导致过拟合 ，然而另一个极端──限制过大的归纳偏执也是有问题的：如果数据本身并不是线性的，强行用线性函数去做回归通常并不能得到好结果（例如我在“实验一：多项式拟合曲线”中就做过相应的测试）。难点正在于在这之间寻找一个临界点。不过我们在这里相对于机器来说有一个很大的优势：人通常不会孤立地用某一个独立的系统和模型去处理问题，一个人每天都会从各个来源获取大量的信息，并且通过各种手段进行整合处理，归纳所得的所有知识最终得以统一地存储起来，并能有机地组合起来去解决特定的问题。 以上就是我关于“过拟合”的一点不全面的思考！","categories":[{"name":"AI","slug":"AI","permalink":"http://meng.uno/categories/AI/"},{"name":"机器学习","slug":"AI/机器学习","permalink":"http://meng.uno/categories/AI/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://meng.uno/tags/机器学习/"}]},{"title":"Android新闻软件编写","slug":"androidnews","date":"2016-12-16T07:01:14.000Z","updated":"2018-02-09T10:46:20.938Z","comments":true,"path":"posts/8fb3f6d8/","link":"","permalink":"http://meng.uno/posts/8fb3f6d8/","excerpt":"","text":"当我开始学安卓开发时，我发现网上最多的教程就是关于Android上的新闻客户端开发的（而且课时特别长），我本人觉得完全是那些上传网课的人想拉时长牟利，在写完listview之后，因为我们的《软设》项目需要，我也来做做“新闻页”，我只写显示过程（不涉及爬虫），只是为了记录下开发过程供初学者及日后自己回顾。 首先，我在values/string目录加上如下条目，用作显示（内容无关）： 123456789101112131415161718192021222324252627282930313233343536 &lt;string name=\"title\"&gt;是上帝除四害是的次数不多是彻底那就是地产表示比不对是不死都今?&lt;/string&gt; &lt;string name=\"text\"&gt;我是测手术储备货币结算你说的内存金士顿内存就剧场那就看到手残你从从今年刷卡才能加内存显卡才能收到你今年的你朝鲜才能常出现从侠客行朝鲜&lt;/string&gt; &lt;string-array name=\"text_arr\"&gt; &lt;item&gt;bids比貂蝉死不打算比赛的buds不v电话苏帮你吧报错还加班猝死地产表示出版社u白崇禧必须&lt;/item&gt; &lt;item&gt;但是不撒手撒就行字数限制到6个字，多的用省略号，是设置什么属学校决定停止晚自习，我和同学一起回荚冬 我是在那次孝雅之星的事迹报告会上认识她的。当轮到她上场的时候，主持人这样说道：“她是一个外表刚强，内心柔弱的人。”话音刚落，她班上的同学一阵哄堂大笑。 我用疑惑的眼神看了看身旁的同学，她告诉我，在她们班上谁都知道她是一个标准的女汉子。她的话勾起了我的好奇心，使我有了想听听她的故事的欲望。 她步履坚定的走上了演讲台，先是向我们深深地鞠了一躬，便开始娓娓道来她的事迹。 她的父母都在外打拼，忙于事业，所以很少有空去照顾她，所以家中的一切只能由她一人包办。后来，她又有了一个妹妹，致使她身上的担子又加重了许多，但她依然十分 坚强的承担这一切。她说妹妹的到来对于她来说像一个天使一样美好，而并不是觉得她是一个负担。当我们回到家中扑在父母怀里撒娇时，她在床头哄着妹妹入睡；当我作文网 http://wwW.zuoWen8.Com/们安稳的进入梦乡时，她却还在奋笔疾书。夜的黑暗与漫长，只有她才知道；思念的感受有多浓稠，只有她才知道；内心的压抑有多难受，只有她才知 道。 当她说到妹妹因调皮将很烫的饭菜洒到她的手臂上，她还得继续给妹妹喂饭时，当她提及妹妹做坏事后她忍气吞声的到别人家中道歉时，她哽咽了，将头扭到一边独自抹眼泪。 我们沉默了，低头不语。忧伤的气息迅速在全场蔓延，每个人的心都在和她共鸣着，有好几次，她正准备开口时，却都卡在了喉咙，全场为她响起了雷鸣般经久不息的掌声。 &lt;/item&gt; &lt;item&gt;看到他我想到了爸爸，幸好他今天不上班，不用冒那么大的雪，假如哪个人是我爸爸，我多么希看有一个好心人上前伸出一只手，帮他一把。假如那是你，&lt;/item&gt; &lt;item&gt;我停了车子，想往帮助他，可我也象那些来来往往的行人一样，脚步并没有动，的确有很多人同情他，同情也的确对他没用，他还是站不起来，一遍一遍看他起来又摔倒，只好转过头， 不看他，疼痛无奈，一个中年男子的窘态在众人眼前暴露无遗，这时的他没有一点男子汉的心胸。&lt;/item&gt; &lt;item&gt;走到一个小岔路口时，我看到路的另一边一个中年男子坐在地上，他穿着青色衣服，双手扶地，似乎挣扎着坐起来，一次又一次尝试着。旁边躺着他的尽看的大梁自行车，等待着主人扶 起它，在这路上最难过的就是他们了吧！也只有他们可以相互安慰。&lt;/item&gt; &lt;item&gt;春天，春姑娘带来了蒙蒙细雨和柔和的春风，并把它们化作一只大画笔，把绿色涂在草坪上。这时，无数只小燕子从远方飞来，在草坪上飞来飞去。&lt;/item&gt; &lt;item&gt;夏天，草坪旁的花坛里，月季花欣然怒放，引来了勤劳的小蜜蜂和翩翩起舞的蝴蝶，热闹极了。&lt;/item&gt; &lt;item&gt;冬天，雪花落到草坪上，给草坪盖上了一层厚厚的棉被，来年，小草更加茁壮成长。&lt;/item&gt; &lt;item&gt;草坪就像一个氧气袋，它通过光合作用，净化空气，美化环境。我们要爱护学校的草坪。&lt;/item&gt; &lt;/string-array&gt; &lt;string-array name=\"title_arr\"&gt; &lt;item&gt;死地产表示出版社u白崇禧必须&lt;/item&gt; &lt;item&gt;停止晚自习，我和同学一起回荚冬&lt;/item&gt; &lt;item&gt;假如哪个人是我爸爸，我多么希看有一个好心人上前伸出一只手，帮他一把。假如那是你，&lt;/item&gt; &lt;item&gt;我停了的行人一样，脚步并没有动，的确有很多人同情他，同情也的确对他没用，他还是站不起来，一遍一遍看他起来又摔倒，只好转过头，他没有一点男子汉的心胸。&lt;/item&gt; &lt;item&gt;他穿着青色衣服，双手扶地，似乎挣扎着坐起来，一次又一次尝试着。旁边躺着他的尽看的大梁自行车，等待着主人扶&lt;/item&gt; &lt;item&gt;春天。&lt;/item&gt; &lt;item&gt;夏天极了。&lt;/item&gt; &lt;item&gt;冬天，雪花落到&lt;/item&gt; &lt;item&gt;草坪就像的草坪。&lt;/item&gt; &lt;/string-array&gt; 接着编写显示主界面： 123456789101112131415161718192021222324252627 public class MainActivity extends AppCompatActivity&#123; private ListView listview; //private ArrayAdapter&lt;String&gt;arr_adapter; private SimpleAdapter simp_Adapter; private List&lt;Map&lt;String,String&gt;&gt;datalist; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); listview = (ListView)findViewById(R.id.listview); datalist = new ArrayList&lt;Map&lt;String,String&gt;&gt;(); simp_Adapter = new SimpleAdapter(this,getData(),R.layout.item, new String[]&#123;\"title\",\"text\"&#125;,new int[]&#123;R.id.title,R.id.text&#125;); listview.setAdapter(simp_Adapter); &#125; private List&lt;Map&lt;String,String&gt;&gt; getData()&#123; String[] data_text = getResources().getStringArray(R.array.text_arr); String[] data_title = getResources().getStringArray(R.array.title_arr); for(int i=0;i&lt;data_text.length;i++)&#123; Map&lt;String,String&gt;map = new HashMap&lt;String,String&gt;(); map.put(\"title\",data_title[i]); map.put(\"text\",data_text[i]); datalist.add(map); &#125; return datalist; &#125;&#125; 其对应的activity_main.xml文件为： 12345678910111213141516171819 &lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;RelativeLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:tools=\"http://schemas.android.com/tools\" android:id=\"@+id/activity_main\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:paddingBottom=\"@dimen/activity_vertical_margin\" android:paddingTop=\"@dimen/activity_vertical_margin\" tools:context=\"com.example.lpf.test.MainActivity\"&gt; &lt;ListView android:id=\"@+id/listview\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:layout_alignParentBottom=\"true\" android:layout_alignParentStart=\"true\" android:background=\"@color/bg\" android:divider=\"@color/item_item\" android:dividerHeight=\"10dp\"/&gt;&lt;/RelativeLayout&gt; 再然后，编写点击后的后台跳转逻辑： 1234567891011121314 public class ShowActivity extends AppCompatActivity &#123; protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_show); Bundle bundle = getIntent().getExtras(); String title = bundle.getString(\"title\"); String text = bundle.getString(\"text\"); TextView title_view = (TextView) findViewById(R.id.title); title_view.setText(title); TextView text_view = (TextView) findViewById(R.id.text); text_view.setMovementMethod(ScrollingMovementMethod.getInstance()); text_view.setText(text); &#125;&#125; 对应的activity_show.xml文件如下： 123456789101112131415161718192021222324252627 &lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;LinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" android:orientation=\"vertical\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:paddingBottom=\"@dimen/activity_vertical_margin\" android:paddingLeft=\"@dimen/activity_horizontal_margin\" android:paddingRight=\"@dimen/activity_horizontal_margin\" android:paddingTop=\"@dimen/activity_vertical_margin\"&gt; &lt;TextView android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:id=\"@+id/title\" android:text=\"@string/title\" android:textSize=\"22sp\" android:typeface=\"monospace\" android:background=\"@color/itembg\"/&gt; &lt;TextView android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:id=\"@+id/text\" android:textSize=\"18sp\" android:textColor=\"@color/textbg\" android:typeface=\"normal\" android:scrollbars=\"vertical\" android:text=\"@string/text\"/&gt;&lt;/LinearLayout&gt; 最后就是负责点击跳转的任务的后台程序了： 1234567891011121314151617181920212223 public class TestActivity extends ListActivity &#123; String[] data = &#123;\"北京\",\"西安\",\"广州\",\"上海\"&#125;; ListView lstview; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); lstview = (ListView)findViewById(R.id.listview); lstview.setOnItemClickListener(new AdapterView.OnItemClickListener()&#123; @Override public void onItemClick(AdapterView&lt;?&gt; parent, View view, int position, long id) &#123; String s = data[position]; &#125; &#125;); ArrayAdapter&lt;String&gt; adapter = new ArrayAdapter&lt;String&gt;( this, R.layout.item, R.id.listview, data ); lstview.setAdapter(adapter); &#125;&#125; 附加一个item.xml用于接收显示： 1234567891011121314151617181920212223242526272829 &lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;LinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" android:orientation=\"vertical\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:paddingBottom=\"@dimen/activity_vertical_margin\" android:paddingLeft=\"@dimen/activity_horizontal_margin\" android:paddingRight=\"@dimen/activity_horizontal_margin\" android:paddingTop=\"@dimen/activity_vertical_margin\" android:background=\"@drawable/white_bg\"&gt; &lt;TextView android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:id=\"@+id/title\" android:text=\"@string/title\" android:textSize=\"20sp\" android:typeface=\"monospace\" android:background=\"@color/itembg\"/&gt; &lt;TextView android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:id=\"@+id/text\" android:textSize=\"15sp\" android:textColor=\"@color/textbg\" android:typeface=\"normal\" android:maxLines=\"3\" android:ellipsize=\"end\" android:text=\"@string/text\"/&gt;&lt;/LinearLayout&gt; 至此一个新闻客户端基本框架就已经编写完毕！","categories":[{"name":"Android","slug":"Android","permalink":"http://meng.uno/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://meng.uno/tags/Android/"}]},{"title":"Linux 0.11启动引导","slug":"os","date":"2016-12-16T06:52:23.000Z","updated":"2018-02-09T10:46:20.931Z","comments":true,"path":"posts/6c138ff9/","link":"","permalink":"http://meng.uno/posts/6c138ff9/","excerpt":"","text":"Linux引导启动程序程序在boot目录下，有bootset.s, head.s和setup.s（编译后），其中： bootset.s 系统启动时首先是进入实模式，从地址0xffff0（这地址映射的rom-bios在内存的地址）处开始执行bios代码，然后执行系统检测（也就是自检过程）,然后初始化实模式的中断向量表(实模式中断向量在内存物理地址0处)。然后将启动设备的第一个扇区（512字节，也就是bootset.s编译完成的内容）内容读取到内存0x7c00(31kB)处，并且跳转到这里。 跳转到bootset.s后，bootset.s主要做如下工作： bootset.s在最前面的几句代码先将自己移动到内存0x90000（576kB）处； bootset.s将启动设备第2个扇区到第五个扇区内容（4个扇区里面存放的是setup.s的内容）读取到内存0x90200处，也就是bootset.s后面； 将内核其他模块读取到0x10000（64KB）处，读取的大小为192KB，对于当时的内核来说确实是足够大了； 在bootset.s偏移508处定义了根文件系统的设备号，并且根据编译选项进行了赋值操代码默认启动驱动器是软盘a，然后就是bootset.s,setup.s,和内核镜像都成放在软盘a中; setup.s 将系统的一些参数存放在0x90000处,覆盖之前的bootset.s,参数主要包括，内存大小，硬盘参数，显存的参数信息以及根文件系统的设备号; 定义了GDT表，最后加载了gdtr和ldtr，最后跳到保护模式GDT表定义在setup.s,也就是在0x90200的那段内存中，LDT还没有定义。 head.s 其被编译到内核镜像中。重新定义了GDT表(目前就一个第二个段描述符有效)和并定义LDT表（表中中断处理程序目前还是指向一个默认的处理程序），并加载相应的寄存器； 内存开始处设置页目录表，一共有4个叶目录，初始化页目录，然后开启分页，最后跳到主函数main()。 至此，系统启动引导完成。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://meng.uno/categories/操作系统/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://meng.uno/tags/操作系统/"}]},{"title":"Android的ListView的使用","slug":"android_listview","date":"2016-12-15T05:58:11.000Z","updated":"2018-02-09T10:46:20.916Z","comments":true,"path":"posts/5d6c9819/","link":"","permalink":"http://meng.uno/posts/5d6c9819/","excerpt":"","text":"可能我们在手机APP上使用的最多的视图就是列表了，那么Android列表（ListView）该怎么使用呢？ 首先还是显示界面activity_main.xml: 12345678910111213141516171819 &lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;RelativeLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:tools=\"http://schemas.android.com/tools\" android:id=\"@+id/activity_main\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:paddingBottom=\"@dimen/activity_vertical_margin\" android:paddingTop=\"@dimen/activity_vertical_margin\" tools:context=\"com.example.lpf.test.MainActivity\"&gt; &lt;ListView android:id=\"@+id/listview\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:layout_alignParentBottom=\"true\" android:layout_alignParentStart=\"true\" android:background=\"@color/bg\" android:divider=\"@color/item_item\" android:dividerHeight=\"10dp\"/&gt;&lt;/RelativeLayout&gt; 之后是其对应的MainActivity.java文件： 123456789101112131415161718192021222324252627 public class MainActivity extends AppCompatActivity&#123; private ListView listview; //private ArrayAdapter&lt;String&gt;arr_adapter; private SimpleAdapter simp_Adapter; private List&lt;Map&lt;String,String&gt;&gt;datalist; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); listview = (ListView)findViewById(R.id.listview); datalist = new ArrayList&lt;Map&lt;String,String&gt;&gt;(); simp_Adapter = new SimpleAdapter(this,getData(),R.layout.item, new String[]&#123;\"title\",\"text\"&#125;,new int[]&#123;R.id.title,R.id.text&#125;); listview.setAdapter(simp_Adapter); &#125; private List&lt;Map&lt;String,String&gt;&gt; getData()&#123; String[] data_text = getResources().getStringArray(R.array.text_arr); String[] data_title = getResources().getStringArray(R.array.title_arr); for(int i=0;i&lt;data_text.length;i++)&#123; Map&lt;String,String&gt;map = new HashMap&lt;String,String&gt;(); map.put(\"title\",data_title[i]); map.put(\"text\",data_text[i]); datalist.add(map); &#125; return datalist; &#125;&#125; 其他文件保持不变即可。 至此，一个Android列表程序就实现了。","categories":[{"name":"Android","slug":"Android","permalink":"http://meng.uno/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://meng.uno/tags/Android/"}]},{"title":"Android实现输入框回车输入","slug":"android_enter","date":"2016-12-15T05:22:51.000Z","updated":"2018-02-09T10:46:20.915Z","comments":true,"path":"posts/e60b1ba5/","link":"","permalink":"http://meng.uno/posts/e60b1ba5/","excerpt":"","text":"用惯了iOS的各位在开发安卓程序或者使用安卓手机时，都会遇到这样一个问题：原本在iOS上都是回车输入，而到了Android上却需要点击按钮完成输入（对比两个系统上的QQ就发现了）。我一直在使用iOS系统，因为《软设》才着手Android开发，所以我就想能不能像iOS上的那样实现一个输入框+回车符完成输入呢？经过我查找资料，发现确实可以： 12345678910111213141516 &lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;LinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:tools=\"http://schemas.android.com/tools\" android:orientation=\"vertical\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:weightSum=\"1\"&gt; &lt;EditText android:id=\"@+id/edit_message\" android:layout_margin=\"30dp\" android:layout_width=\"match_parent\" android:layout_height=\"80dp\" android:hint=\"请输入文本信息 ...\" android:imeOptions=\"actionSearch\" android:singleLine=\"true\"/&gt;&lt;/LinearLayout&gt; 在EditText中加入了imeOptions就可以将回车符转变成各种各样的功能： actionDone——回车符--&gt;完成 actionSend——回车符--&gt;发送 actionGo——回车符--&gt;前进 actionNext——回车符--&gt;下一项 actionNone——回车符--&gt;无动作 actionPrevious——回车符--&gt;上一项 actionSearch——回车符--&gt;搜索 actionUnspecified——回车符--&gt;未指定 actionSend——回车符--&gt;发送 又查阅资料发现：ime是Input Method Editors的缩写，也就是输入法编辑器，原来如此，不过想使用这个属性，必须加上android:inputType 或者 android:singleline=”true” 至此，就完成了Android回车符向iOS的转化！","categories":[{"name":"Android","slug":"Android","permalink":"http://meng.uno/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://meng.uno/tags/Android/"}]},{"title":"Android页面跳转","slug":"android_pages_jump","date":"2016-12-15T04:46:49.000Z","updated":"2018-02-09T10:46:20.917Z","comments":true,"path":"posts/1da18548/","link":"","permalink":"http://meng.uno/posts/1da18548/","excerpt":"","text":"前情提要 开发安卓单页面程序久了，必然会思考怎么开发像现在一般Android应用程序那样的多页面（指页面有跳转）程序，我也是在搜索了其他牛人的（海量）博客之后，才总结出如下的这点精华步骤（又要感慨一下国内搜索引擎之渣）！ 编写AndroidManifest.xml 首先，我们要确定我们需要怎样的跳转，既然跳转，无非就是自动跳转或者点击按钮，无论哪种，首先我们必须有两个界面（至少），所以在AndroidManifest.xml中，我们需要这样写： 123456789101112131415161718192021222324 &lt;manifest xmlns:android=\"http://schemas.android.com/apk/res/android\" package=\"uno.meng.download\"&gt; &lt;application android:allowBackup=\"true\" android:icon=\"@mipmap/ic_launcher\" android:theme=\"@style/AppTheme\"&gt; &lt;activity android:name=\".MainActivity\" android:label=\"@string/app_name\"&gt; &lt;intent-filter&gt; &lt;action android:name=\"android.intent.action.MAIN\" /&gt; &lt;category android:name=\"android.intent.category.LAUNCHER\" /&gt; &lt;/intent-filter&gt; &lt;/activity&gt; &lt;activity android:name=\".ResultActivity\" android:label=\"@string/comeback\" android:parentActivityName=\".MainActivity\" &gt; &lt;meta-data android:name=\"android.support.PARENT_ACTIVITY\" android:value=\".MainActivity\"/&gt; &lt;/activity&gt; &lt;/application&gt;&lt;/manifest&gt; 其中，每个&lt;activity&gt;对应一个界面，从代码中可见，我将后一个页面加了一个返回前一个页面的“返回符”。 编写跳转前界面search.xml 由于我在此将介绍怎么使用按钮跳转（带输入），所以直接在主界面search.xml（名称随意）中声明这两个组件（按钮，输入框）： 123456789101112131415161718192021 &lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;LinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:tools=\"http://schemas.android.com/tools\" android:orientation=\"vertical\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:weightSum=\"1\"&gt; &lt;EditText android:id=\"@+id/edit_message\" android:layout_margin=\"30dp\" android:layout_width=\"match_parent\" android:layout_height=\"80dp\" android:hint=\"请输入文本信息 ...\"/&gt; &lt;Button android:id=\"@+id/button\" android:text=\"点击提交 \" android:layout_margin=\"100dp\" android:layout_width=\"127dp\" android:layout_height=\"wrap_content\" android:onClick=\"sendMessage\" /&gt;&lt;/LinearLayout&gt; 可见，我对按钮加了一个onClick事件。 编写对应的MainActivity.java 在search.xml对应的MainActivity.java文件中我们写好onCreate方法（每个文件都会有）以及sendMessage方法： 123456789101112131415 public class MainActivity extends AppCompatActivity &#123; public final static String EXTRA_MESSAGE = \"uno.meng.download.MESSAGE\"; public void sendMessage()&#123; EditText editText = (EditText)findViewById(R.id.edit_message); String message = editText.getText().toString(); Intent intent = new Intent(this, ResultActivity.class); intent.putExtra(EXTRA_MESSAGE,message); startActivity(intent); &#125; @Override protected void onCreate(Bundle savedInstanceState)&#123; super.onCreate(savedInstanceState); setContentView(R.layout.search); &#125;&#125; 编写接收界面result.xml 然后到result.xml接收（我用的一个框来接收）： 123456789101112 &lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;LinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:tools=\"http://schemas.android.com/tools\" android:orientation=\"vertical\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:weightSum=\"1\"&gt; &lt;TextView android:layout_margin=\"30dp\" android:layout_width=\"match_parent\" android:layout_height=\"80dp\"/&gt;&lt;/LinearLayout&gt; 编写接收对应的ResultActivity.java 编写对应的ResultActivity.java文件， 将从MainActivity.java接收来的文字打印到result.xml的框中： 123456789101112131415 public class ResultActivity extends AppCompatActivity&#123; private Intent intent; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.result); intent = getIntent(); String message = intent.getStringExtra(MainActivity.EXTRA_MESSAGE); System.out.println(message); TextView textview = new TextView(this); textview.setTextSize(100); textview.setText(message); setContentView(textview); &#125;&#125; 到此为止，已经完成了Android页面跳转！","categories":[{"name":"Android","slug":"Android","permalink":"http://meng.uno/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://meng.uno/tags/Android/"}]},{"title":"表格搜索","slug":"tablesearch","date":"2016-12-13T04:29:32.000Z","updated":"2018-02-09T10:46:20.941Z","comments":true,"path":"posts/49d54823/","link":"","permalink":"http://meng.uno/posts/49d54823/","excerpt":"","text":"虽然表格的排列相当困难，但表格的搜索却非常容易。增加一个搜索输入，如果那里的值匹配到了任意一行的文本，则显示该行，并隐藏其他所有的行。使用jQuery来实现就像下面这么简单： 12345 var allRows = $(\"tr\");$(\"input#search\").on(\"keydown keyup\", function() &#123; allRows.hide(); $(\"tr:contains('\" + $(this).val() + \"')\").show();&#125;); 没有看错，就是这么简单，如果是在实际应用中，可以这样来写： 先声明一个按钮： 1 &lt;input type=\"search\" id=\"search\" placeholder=\"请输入内容……\"&gt; 在input框之后加入以下JavaScript代码： 123456789101112131415 &lt;script&gt;// Quick Table Search$('#search').keyup(function() &#123; var regex = new RegExp($('#search').val(), \"i\"); var rows = $('table tr:gt(0)'); rows.each(function (index) &#123; title = $(this).children(\"#title\").html() if (title.search(regex) != -1) &#123; $(this).show(); &#125; else &#123; $(this).hide(); &#125; &#125;);&#125;);&lt;/script&gt; 完美运行有木有！！！","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/categories/软件工程/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/tags/软件工程/"}]},{"title":"使用JavaScript将页面导出为图片","slug":"canvas","date":"2016-12-13T04:20:18.000Z","updated":"2018-02-09T10:46:20.919Z","comments":true,"path":"posts/f03eda59/","link":"","permalink":"http://meng.uno/posts/f03eda59/","excerpt":"","text":"昨天心血来潮，突然想将我们组开发的网站上的“导出Excel”功能做一点拓展，于是就想能不能直接将网页表格导出为图片！ 在我的不懈搜索后（搜索过程中绝大部分博客上的博文要么相互抄袭要么没什么屁用），终于得到了“canvas2image.js”这个神奇的JavaScript脚本，具体使用办法见如下代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556 &lt;!doctype html&gt;&lt;html&gt;&lt;script src=\"canvas2image.js\"&gt;&lt;/script&gt;&lt;body&gt; &lt;canvas id=\"cvs\"&gt;&lt;/canvas&gt; &lt;button id=\"save\"&gt;save&lt;/button&gt;&lt;script&gt; var canvas, ctx, bMouseIsDown = false, iLastX, iLastY, $save, $imgs, $convert, $imgW, $imgH, $sel; function init ()&#123; canvas = document.getElementById('cvs'); ctx = canvas.getContext('2d'); $save = document.getElementById('save'); $convert = document.getElementById('convert'); $sel = \"png\"; $imgs = document.getElementById('imgs'); $imgW = 1980; $imgH = 2000; bind(); draw(); &#125; function bind () &#123; canvas.onmousedown = function(e) &#123; bMouseIsDown = true; iLastX = e.clientX - canvas.offsetLeft + (window.pageXOffset||document.body.scrollLeft||document.documentElement.scrollLeft); iLastY = e.clientY - canvas.offsetTop + (window.pageYOffset||document.body.scrollTop||document.documentElement.scrollTop); &#125; canvas.onmouseup = function() &#123; bMouseIsDown = false; iLastX = -1; iLastY = -1; &#125; canvas.onmousemove = function(e) &#123; if (bMouseIsDown) &#123; var iX = e.clientX - canvas.offsetLeft + (window.pageXOffset||document.body.scrollLeft||document.documentElement.scrollLeft); var iY = e.clientY - canvas.offsetTop + (window.pageYOffset||document.body.scrollTop||document.documentElement.scrollTop); ctx.moveTo(iLastX, iLastY); ctx.lineTo(iX, iY); ctx.stroke(); iLastX = iX; iLastY = iY; &#125; &#125;; $save.onclick = function (e) &#123; var type = $sel.value, w = $imgW.value, h = $imgH.value; Canvas2Image.saveAsImage(canvas, w, h, type); &#125; &#125; onload = init;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/categories/软件工程/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/tags/软件工程/"}]},{"title":"Java导出Excel","slug":"java2excel","date":"2016-12-06T14:16:48.000Z","updated":"2018-02-09T10:46:20.923Z","comments":true,"path":"posts/7725d215/","link":"","permalink":"http://meng.uno/posts/7725d215/","excerpt":"","text":"完成这个实验，你需要下载jxljar包，具体方法自行百度。 接下来我将直接使用具体代码进行讲解我的实现过程。 文件名： ExcelAction.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879 package net.kuangmeng.excel;/*这里是所有需要导入的库，不用担心当你写好其他代码时，编辑器会提示或者自动帮你补全！*/import java.io.File;import java.io.FileOutputStream;import java.io.IOException;import java.util.ArrayList;import java.util.List;import com.opensymphony.xwork2.ActionSupport;import jxl.Workbook;import jxl.format.Alignment;import jxl.format.Colour;import jxl.format.UnderlineStyle;import jxl.format.VerticalAlignment;import jxl.write.Label;import jxl.write.WritableCellFormat;import jxl.write.WritableFont;import jxl.write.WritableSheet;import jxl.write.WritableWorkbook;import jxl.write.WriteException;import jxl.write.biff.RowsExceededException;@SuppressWarnings(\"serial\")public class ExcelAction extends ActionSupport&#123; public static void main(String[] args) &#123; //主函数调用 //listth为导出excel的表头信息 list&lt;String&gt; listth = new ArrayList&lt;String&gt;; //listtd为导出的excel表项 list&lt;String&gt; listtd = new ArrayList&lt;String&gt;; //num为表的列数 int num ; exportExcel(tablename,listth,listtd,num); &#125;//真正的导出excel方法 public static void exportExcel(String fileName,List&lt;String&gt; listth,List&lt;String&gt; listtd,int num) &#123; //设置保存文件具体位置及文件名 String excelName =\"C:\\\\Users\\\\meng\\\\Desktop\\\\\"+fileName+\".xls\"; try &#123; File excelFile = new File(excelName); // 如果文件存在就删除它 if (excelFile.exists()) excelFile.delete(); // 打开文件 WritableWorkbook book = Workbook.createWorkbook(excelFile); // 生成名为“第一页”的工作表，参数0表示这是第一页 WritableSheet sheet = book.createSheet(\"Up2U导出表格 \", 0); // 文字样式 jxl.write.WritableFont wfc = new jxl.write.WritableFont( WritableFont.ARIAL, 10, WritableFont.NO_BOLD, false, UnderlineStyle.NO_UNDERLINE, jxl.format.Colour.BLACK); jxl.write.WritableCellFormat wcfFC = new jxl.write.WritableCellFormat( wfc); jxl.write.WritableCellFormat wcfF = new jxl.write.WritableCellFormat(wfc); wcfF.setBackground(jxl.format.Colour.BLACK); // 设置单元格样式 wcfFC.setBackground(jxl.format.Colour.GRAY_25);// 单元格颜色 wcfFC.setAlignment(jxl.format.Alignment.CENTRE);// 单元格居中 // 在Label对象的构造子中指名单元格位置是第一列第一行(0,0) // 以及单元格内容为 for(int i=0;i&lt;listth.size()/(num-2);i++)&#123; for(int j=0;j&lt;num-2;j++)&#123; sheet.addCell(new Label(j,i,listth.get(i*(num-2)+j),wcfFC)); &#125; &#125; for(int i=listth.size()/(num-2);i&lt;(listth.size()+listtd.size())/(num-2);i++)&#123; for(int j=0;j&lt;num-2;j++)&#123; sheet.addCell(new Label(j,i,listtd.get((i-1)*(num-2)+j),wcfF)); &#125; &#125; // 写入数据并关闭文件 book.write(); book.close(); System.out.println(\"Excel创建成功\"); &#125; catch (Exception e) &#123; System.out.println(e); &#125; &#125;&#125;","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/categories/软件工程/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/tags/软件工程/"}]},{"title":"Mac MySQL无法启动解决方案","slug":"mysql_error","date":"2016-12-06T13:24:05.000Z","updated":"2018-02-09T10:46:20.929Z","comments":true,"path":"posts/115ed5e0/","link":"","permalink":"http://meng.uno/posts/115ed5e0/","excerpt":"","text":"正像这次博客的日期那样，《软工》大项目接近尾声了，然而直到今天我才真正解决了这个大难题——Mac MySQL无法使用！！！ 检查MySQL是否成功安装 1 mysql --version 关闭MySQL连接（即使没连也无妨） 1 sudo /usr/local/mysql/support-files/mysql.server stop 登录管理员 12 cd /usr/local/mysql/bin/sudo su 禁止MySQL验证来登录（此时不验证密码） 1 ./mysqld_safe --skip-grant-tables &amp; （此时应该成功进入mysql&gt;）设置密码 1 UPDATE mysql.user SET authentication_string=PASSWORD('*****') WHERE User='root'; （若显示密码过期）设置密码永不过期 1 ALTER USER 'root'@'localhost' PASSWORD EXPIRE NEVER; 刷新MySQL的系统权限 1 flush privileges; 至此应该来说MySQL应该好使了。","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/categories/软件工程/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/tags/软件工程/"}]},{"title":"Java发送邮件","slug":"javamail","date":"2016-12-04T14:30:34.000Z","updated":"2018-02-09T10:46:20.925Z","comments":true,"path":"posts/21f3b9c2/","link":"","permalink":"http://meng.uno/posts/21f3b9c2/","excerpt":"","text":"我觉得学会Java mail是一件很自豪的事，怎么说呢，邮箱这么有逼格的东西都能被你玩的很溜的话，一定不一般。 本次试验使用了 javax.mail.jarjar包，请自行百度下载。 我实现的Java mail主要包括4个部分： 发送邮件使用的基本信息 邮件发送器 发件人设置 实际发送 四个部分组成。 发送邮件使用的基本信息 文件名：MailSenderInfo.java 代码如下，我仍然以备注的形式讲解： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495 package net.kuangmeng.mail; /** * 发送邮件需要使用的基本信息 */ import java.util.Properties; public class MailSenderInfo &#123; // 发送邮件的服务器的IP和端口 private String mailServerHost; private String mailServerPort = \"25\"; // 邮件发送者的地址 private String fromAddress; // 邮件接收者的地址 private String toAddress; // 登陆邮件发送服务器的用户名和密码 private String userName; private String password; // 是否需要身份验证 private boolean validate = false; // 邮件主题 private String subject; // 邮件的文本内容 private String content; // 邮件附件的文件名 private String[] attachFileNames; /** * 获得邮件会话属性 */ public Properties getProperties()&#123; Properties p = new Properties(); p.put(\"mail.smtp.host\", this.mailServerHost); p.put(\"mail.smtp.port\", this.mailServerPort); p.put(\"mail.smtp.auth\", validate ? \"true\" : \"false\"); return p; &#125; public String getMailServerHost() &#123; return mailServerHost; &#125; public void setMailServerHost(String mailServerHost) &#123; this.mailServerHost = mailServerHost; &#125; public String getMailServerPort() &#123; return mailServerPort; &#125; public void setMailServerPort(String mailServerPort) &#123; this.mailServerPort = mailServerPort; &#125; public boolean isValidate() &#123; return validate; &#125; public void setValidate(boolean validate) &#123; this.validate = validate; &#125; public String[] getAttachFileNames() &#123; return attachFileNames; &#125; public void setAttachFileNames(String[] fileNames) &#123; this.attachFileNames = fileNames; &#125; public String getFromAddress() &#123; return fromAddress; &#125; public void setFromAddress(String fromAddress) &#123; this.fromAddress = fromAddress; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; public String getToAddress() &#123; return toAddress; &#125; public void setToAddress(String toAddress) &#123; this.toAddress = toAddress; &#125; public String getUserName() &#123; return userName; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125; public String getSubject() &#123; return subject; &#125; public void setSubject(String subject) &#123; this.subject = subject; &#125; public String getContent() &#123; return content; &#125; public void setContent(String textContent) &#123; this.content = textContent; &#125; &#125; 邮件发送器 文件名：SimpleMailSender.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105 package net.kuangmeng.mail;import java.util.Date; import java.util.Properties; import javax.mail.Address; import javax.mail.BodyPart; import javax.mail.Message; import javax.mail.MessagingException; import javax.mail.Multipart; import javax.mail.Session; import javax.mail.Transport; import javax.mail.internet.InternetAddress; import javax.mail.internet.MimeBodyPart; import javax.mail.internet.MimeMessage; import javax.mail.internet.MimeMultipart; /** * 简单邮件（不带附件的邮件）发送器 */ public class SimpleMailSender &#123; /** * 以文本格式发送邮件 * @param mailInfo 待发送的邮件的信息 */ public boolean sendTextMail(MailSenderInfo mailInfo) &#123; // 判断是否需要身份认证 MyAuthenticator authenticator = null; Properties pro = mailInfo.getProperties(); if (mailInfo.isValidate()) &#123; // 如果需要身份认证，则创建一个密码验证器 authenticator = new MyAuthenticator(mailInfo.getUserName(), mailInfo.getPassword()); &#125; // 根据邮件会话属性和密码验证器构造一个发送邮件的session Session sendMailSession = Session.getDefaultInstance(pro,authenticator); try &#123; // 根据session创建一个邮件消息 Message mailMessage = new MimeMessage(sendMailSession); // 创建邮件发送者地址 Address from = new InternetAddress(mailInfo.getFromAddress()); // 设置邮件消息的发送者 mailMessage.setFrom(from); // 创建邮件的接收者地址，并设置到邮件消息中 Address to = new InternetAddress(mailInfo.getToAddress()); mailMessage.setRecipient(Message.RecipientType.TO,to); // 设置邮件消息的主题 mailMessage.setSubject(mailInfo.getSubject()); // 设置邮件消息发送的时间 mailMessage.setSentDate(new Date()); // 设置邮件消息的主要内容 String mailContent = mailInfo.getContent(); mailMessage.setText(mailContent); // 发送邮件 Transport.send(mailMessage); return true; &#125; catch (MessagingException ex) &#123; ex.printStackTrace(); &#125; return false; &#125; /** * 以HTML格式发送邮件 * @param mailInfo 待发送的邮件信息 */ public static boolean sendHtmlMail(MailSenderInfo mailInfo)&#123; // 判断是否需要身份认证 MyAuthenticator authenticator = null; Properties pro = mailInfo.getProperties(); //如果需要身份认证，则创建一个密码验证器 if (mailInfo.isValidate()) &#123; authenticator = new MyAuthenticator(mailInfo.getUserName(), mailInfo.getPassword()); &#125; // 根据邮件会话属性和密码验证器构造一个发送邮件的session Session sendMailSession = Session.getDefaultInstance(pro,authenticator); try &#123; // 根据session创建一个邮件消息 Message mailMessage = new MimeMessage(sendMailSession); // 创建邮件发送者地址 Address from = new InternetAddress(mailInfo.getFromAddress()); // 设置邮件消息的发送者 mailMessage.setFrom(from); // 创建邮件的接收者地址，并设置到邮件消息中 Address to = new InternetAddress(mailInfo.getToAddress()); // Message.RecipientType.TO属性表示接收者的类型为TO mailMessage.setRecipient(Message.RecipientType.TO,to); // 设置邮件消息的主题 mailMessage.setSubject(mailInfo.getSubject()); // 设置邮件消息发送的时间 mailMessage.setSentDate(new Date()); // MiniMultipart类是一个容器类，包含MimeBodyPart类型的对象 Multipart mainPart = new MimeMultipart(); // 创建一个包含HTML内容的MimeBodyPart BodyPart html = new MimeBodyPart(); // 设置HTML内容 html.setContent(mailInfo.getContent(), \"text/html; charset=utf-8\"); mainPart.addBodyPart(html); // 将MiniMultipart对象设置为邮件内容 mailMessage.setContent(mainPart); // 发送邮件 Transport.send(mailMessage); return true; &#125; catch (MessagingException ex) &#123; ex.printStackTrace(); &#125; return false; &#125; &#125; 发件人设置 文件名：MyAuthenticator.java 1234567891011121314151617 package net.kuangmeng.mail;import javax.mail.*; public class MyAuthenticator extends Authenticator&#123; String userName=null; String password=null; public MyAuthenticator()&#123; &#125; public MyAuthenticator(String username, String password) &#123; this.userName = username; this.password = password; &#125; protected PasswordAuthentication getPasswordAuthentication()&#123; return new PasswordAuthentication(userName, password); &#125; &#125; 实际发送 文件名：MailAction.java package net.kuangmeng.mail; import net.kuangmeng.*; public class MailAction { @SuppressWarnings(&quot;static-access&quot;) public static void main(String[] args){ //这个类主要是设置邮件 MailSenderInfo mailInfo = new MailSenderInfo(); mailInfo.setMailServerHost(&quot;smtp.yeah.net&quot;); mailInfo.setMailServerPort(&quot;25&quot;); mailInfo.setValidate(true); mailInfo.setUserName(&quot;*****@yeah.net&quot;); mailInfo.setPassword(&quot;******&quot;);//您的邮箱密码 mailInfo.setFromAddress(&quot;*****@yeah.net&quot;); mailInfo.setToAddress(&quot;****@qq.com&quot;); mailInfo.setSubject(&quot;你好！&quot;);//邮件主题 mailInfo.setContent(&quot;这是一个测试&quot;);//邮件内容 //这个类主要来发送邮件 SimpleMailSender sms = new SimpleMailSender(); sms.sendTextMail(mailInfo);//发送文体格式 sms.sendHtmlMail(mailInfo);//发送html格式 } }","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/categories/软件工程/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/tags/软件工程/"}]},{"title":"Bash的使用","slug":"bash","date":"2016-12-03T09:23:17.000Z","updated":"2018-02-09T10:46:20.918Z","comments":true,"path":"posts/19f2d195/","link":"","permalink":"http://meng.uno/posts/19f2d195/","excerpt":"","text":"显示 “Hello world!” echo Hello world! 每一句指令以换行或分号隔开： echo 'This is the first line'; echo 'This is the second line' 声明一个变量： Variable=&quot;Some string&quot; ***这是错误的做法：***Variable = &quot;Some string&quot; ***原因：***Bash 会把 Variable 当做一个指令，由于找不到该指令，因此这里会报错。 ***也不可以这样：***Variable= 'Some string' ***原因：***Bash 会认为 'Some string' 是一条指令，由于找不到该指令，这里再次报错。这个例子中 'Variable=' 这部分会被当作仅对 'Some string' 起作用的赋值。） 使用变量： 123 echo $Variableecho \"$Variable\"echo '$Variable' 当你赋值 (assign) 、导出 (export)，或者以其他方式使用变量时，变量名前不加 $。如果要使用变量的值， 则要加 $。 注意: ' (单引号) 不会展开变量（即会屏蔽掉变量）。 在变量内部进行字符串代换 echo ${Variable/Some/A} 会把 Variable 中首次出现的 &quot;some&quot; 替换成 “A”。 变量的截取 Length=7 echo ${Variable:0:Length} 这样会仅返回变量值的前7个字符 变量的默认值 echo ${Foo:-&quot;DefaultValueIfFooIsMissingOrEmpty&quot;} 对 null (Foo=) 和空串 (Foo=&quot;&quot;) 起作用； 零（Foo=0）时返回0 注意这仅返回默认值而不是改变变量的值 内置变量： 下面的内置变量很有用 12345 echo \"Last program return value: $?\"echo \"Script's PID: $$\"echo \"Number of arguments: $#\"echo \"Scripts arguments: $@\"echo \"Scripts arguments separated in different variables: $1 $2...\" 读取输入： 123 echo \"What's your name?\"read Name # 这里不需要声明新变量echo Hello, $Name! 通常的 if 结构看起来像这样： 'man test' 可查看更多的信息 123456 if [ $Name -ne $USER ]then echo \"Your name isn't your username\"else echo \"Your name is your username\"fi 根据上一个指令执行结果决定是否执行下一个指令 12 echo \"Always executed\" || echo \"Only executed if first command fails\"echo \"Always executed\" &amp;&amp; echo \"Only executed if first command does NOT fail\" 在 if 语句中使用 &amp;&amp; 和 || 需要多对方括号 123456789 if [ $Name == \"Steve\" ] &amp;&amp; [ $Age -eq 15 ]then echo \"This will run if $Name is Steve AND $Age is 15.\"fiif [ $Name == \"Daniya\" ] || [ $Name == \"Zach\" ]then echo \"This will run if $Name is Daniya OR Zach.\"fi 表达式的格式如下: echo $(( 10 + 5 )) 指令可以带有选项： 与其他编程语言不同的是，bash 运行时依赖上下文。比如，使用 ls 时，列出当前目录。 -l``` 列出文件和目录的详细信息 12345 ## 前一个指令的输出可以当作后一个指令的输入。```grep``` 用来匹配字符串。## 用下面的指令列出当前目录下所有的 txt 文件：```ls -l | grep \"\\.txt\" 以 ^EOF$ 作为结束标记从标准输入读取数据并覆盖 hello.py 123456789 cat &gt; hello.py &lt;&lt; EOF#!/usr/bin/env pythonfrom __future__ import print_functionimport sysprint(\"#stdout\", file=sys.stdout)print(\"#stderr\", file=sys.stderr)for line in sys.stdin: print(line, file=sys.stdout)EOF 重定向可以到输出，输入和错误输出 1234567 python hello.py &lt; \"input.in\"python hello.py &gt; \"output.out\"python hello.py 2&gt; \"error.err\"python hello.py &gt; \"output-and-error.log\" 2&gt;&amp;1python hello.py &gt; /dev/null 2&gt;&amp;1# &gt; 会覆盖已存在的文件， &gt;&gt; 会以累加的方式输出文件中。python hello.py &gt;&gt; \"output.out\" 2&gt;&gt; \"error.err\" 覆盖 output.out , 追加 error.err 并统计行数 12 info bash 'Basic Shell Features' 'Redirections' &gt; output.out 2&gt;&gt; error.errwc -l output.out error.err 运行指令并打印文件描述符 （比如 /dev/fd/123） 12 # 具体可查看： man fdecho &lt;(echo \"#helloworld\") 以 &quot;#helloworld&quot; 覆盖 output.out 1234 cat &gt; output.out &lt;(echo \"#helloworld\")echo \"#helloworld\" &gt; output.outecho \"#helloworld\" | cat &gt; output.outecho \"#helloworld\" | tee output.out &gt;/dev/null 清理临时文件并显示详情（增加 '-i' 选项启用交互模式） 1 rm -v output.out error.err output-and-error.log 一个指令可用 $( ) 嵌套在另一个指令内部 以下的指令会打印当前目录下的目录和文件总数 1 echo &quot;There are $(ls | wc -l) items here.&quot; 反引号 `` 起相同作用，但不允许嵌套 优先使用 $() 1 echo &quot;There are `ls | wc -l` items here.&quot; Bash 的 case 语句与 Java 和 C++ 中的 switch 语句类似 123456 case \"$Variable\" in # 列出需要匹配的字符串 0) echo \"There is a zero.\";; 1) echo \"There is a one.\";; *) echo \"It is not null.\";;esac 循环遍历给定的参数序列 变量$Variable 的值会被打印 3 次 1234 for Variable in &#123;1..3&#125;do echo \"$Variable\"done 或传统的 “for循环” 1234 for ((a=1; a &lt;= 3; a++))do echo $adone 也可以用于文件 用 cat 输出 file1 和 file2 内容 1234 for Variable in file1 file2do cat \"$Variable\"done 或作用于其他命令的输出 对 ls 输出的文件执行 cat 指令 1234 for Output in $(ls)do cat \"$Output\"done while 循环 12345 while [ true ]do echo \"loop body here...\" breakdone 你也可以使用函数 定义函数 1234567 function foo ()&#123; echo \"Arguments work just like script arguments: $@\" echo \"And: $1 $2...\" echo \"This is a function\" return 0&#125; 更简单的方法 12345 bar ()&#123; echo \"Another way to declare functions!\" return 0&#125; 调用函数 1 foo &quot;My name is&quot; $Name 有很多有用的指令需要学习 打印 file.txt 的最后 10 行 1 tail -n 10 file.txt 打印 file.txt 的前 10 行 1 head -n 10 file.txt 将 file.txt 按行排序 1 sort file.txt 报告或忽略重复的行，用选项 -d 打印重复的行 1 uniq -d file.txt 打印每行中 ',' 之前内容 1 cut -d &apos;,&apos; -f 1 file.txt 将 file.txt 文件所有 'okay' 替换为 'great', （兼容正则表达式） 1 sed -i &apos;s/okay/great/g&apos; file.txt 将 file.txt 中匹配正则的行打印到标准输出 这里打印以 &quot;foo&quot; 开头, &quot;bar&quot; 结尾的行 \"^foo.*bar$\" file.txt``` 1234 使用选项 &quot;-c&quot; 统计行数```grep -c &quot;^foo.*bar$&quot; file.txt 如果只是要按字面形式搜索字符串而不是按正则表达式，使用 fgrep (或 grep -F) 1 fgrep &quot;^foo.*bar$&quot; file.txt 以 bash 内建的 'help' 指令阅读 Bash 自带文档 123456 helphelp helphelp forhelp returnhelp sourcehelp . 用 man 指令阅读相关的 Bash 手册 123 apropos bashman 1 bashman bash 用 info 指令查阅命令的 info 文档 （info 中按 ? 显示帮助信息） 1234 apropos info | grep '^info.*('man infoinfo infoinfo 5 info 阅读 Bash 的 info 文档 1234 info bashinfo bash 'Bash Features'info bash 6info --apropos bash","categories":[{"name":"Shells","slug":"Shells","permalink":"http://meng.uno/categories/Shells/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"http://meng.uno/tags/Shell/"},{"name":"Bash","slug":"Bash","permalink":"http://meng.uno/tags/Bash/"}]},{"title":"Java web中的浮出层使用","slug":"iframe","date":"2016-11-23T05:30:45.000Z","updated":"2018-02-09T10:46:20.923Z","comments":true,"path":"posts/fa7b6881/","link":"","permalink":"http://meng.uno/posts/fa7b6881/","excerpt":"","text":"进行《软件工程》大项目时，遇到想在主页上仿Google首页上的那种“一个输入框+两个按钮”，同时一个按钮搜索、一个按钮上传文件，于是到网上查了好久，都没有关于“一个按钮实现文件上传”的功能介绍，最后只能使用“通过一个浮出层弹出上传文件”这种方式，下面贴出JavaScript代码。 在按钮中使用时只需要这样使用就行： 1 &lt;a href=\"javascript:_iframe() %&gt;')\" class=\"button\"&gt;点击进入我的博客&lt;/a&gt; JavaScript代码如下： 123456789101112 &lt;script&gt; function _iframe() &#123; zeroModal.show(&#123; title: '我的博客', iframe: true, url: 'http://www.meng.uno', width: '60%', height: '60%', cancel: true &#125;); &#125; &lt;/script&gt;","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/categories/软件工程/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/tags/软件工程/"}]},{"title":"Mac sudo命令无法使用","slug":"sudo_error","date":"2016-11-19T03:29:25.000Z","updated":"2018-02-11T14:13:13.698Z","comments":true,"path":"posts/e3b9b515/","link":"","permalink":"http://meng.uno/posts/e3b9b515/","excerpt":"","text":"在之前好长一段时间，不知道因为我改动了哪个文件的权限，导致sudo命令无法使用，每次启动sudo总会报什么权限不对的错误，在网上找了好久都没找到解决办法，包括stackoverflow这么牛逼哄哄的网站上面问题人采纳的方案都无济于事，今天闲来无事，又想解决这个问题，这次我是直接进苹果的“Mac 支持”上看的，发现Mac有个单用户模式（在此给出连接），我进入单用户模式，然后就是一个黑框框，在里面输入以下几条命令： 123 mount -uw /chown root:wheel /etc/sudoerschmod 440 /etc/sudoers 大致就是恢复文件权限之类的吧，结果reboot之后，居然就好了😝。 特此记录以下，给出现同种问题的小伙伴提供下。 其实，我的MySQL也有问题，我正准备进MySQL官网看看有什么解决办法😂，所以说，有什么事，能看懂英文的，尽量去软件官网找解决办法！！","categories":[{"name":"sudo","slug":"sudo","permalink":"http://meng.uno/categories/sudo/"},{"name":"error","slug":"sudo/error","permalink":"http://meng.uno/categories/sudo/error/"}],"tags":[{"name":"sudo","slug":"sudo","permalink":"http://meng.uno/tags/sudo/"},{"name":"error","slug":"error","permalink":"http://meng.uno/tags/error/"}]},{"title":"String的“+”操作分析","slug":"string_plus","date":"2016-11-01T08:39:36.000Z","updated":"2018-02-10T13:09:13.130Z","comments":true,"path":"posts/fc57b387/","link":"","permalink":"http://meng.uno/posts/fc57b387/","excerpt":"","text":"起源 昨天，我和队友讨论字符串拼接问题时，他提到了这个问题：直接“+”操作好像是生成了临时的一个新String，然后拼接，再复制给原来的String。带着这个问题，我查了下，得出以下的结论。 结论 我查到的信息之一这样说：因为“+”拼接字符串，每拼接一次都是再内存重新开辟一个新的内存区域（堆里边）,然后把得到的新的字符串存在这块内存，字符串如果很大，循环次多又多，那么浪费了很多时间和空间的开销。 我查到的信息之二这么说：当拼接次数较少时，其实编译器会将其优化为StringBuilder类型，只是当拼接次数特别多时，编译器优化时将会产生过多的StringBuilder类型，从而导致空间浪费。 策略 当拼接次数较少时，我们可以直接使用“+”操作，而当拼接数量较大时，我们最好使用StringBuilder类型。 操作 123 StringBuilder SB = new StringBuilder();SB.append(……);String Result = SB.toString();","categories":[{"name":"Java开发Tips","slug":"Java开发Tips","permalink":"http://meng.uno/categories/Java开发Tips/"},{"name":"String","slug":"Java开发Tips/String","permalink":"http://meng.uno/categories/Java开发Tips/String/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/tags/软件工程/"}]},{"title":"将多个input合并成一个字符串提交给后台","slug":"inputaswhole","date":"2016-10-29T04:50:24.000Z","updated":"2018-02-09T10:46:20.924Z","comments":true,"path":"posts/f12d3e70/","link":"","permalink":"http://meng.uno/posts/f12d3e70/","excerpt":"","text":"需求 我在做我们的《软件工程》作业时，遇到了这样一个问题：我们需要打开一个表，这个表的列数不确定，但要增加增加行的操作。 实现 于是，需求产生了，我需要将前端的多个input标签内容合并成一个字符串来进行提交，我看了几个比较牛的方法（json、ognl……）但是好像与我们的需求偏的有点远（如果可以实现，欢迎留言），最后，没办法只能自己想，由于我还是会一点JavaScript的，所以我就想用JavaScript实现，在尝试了很多次之后，终于成功了，在此先贴上代码。 123456789101112131415161718192021222324 &lt;script type=\"text/javascript\"&gt;function n(n)&#123; var num=\"\"; for(var i=0;i&lt;n;i++)&#123; num += document.getElementById(\"num\"+i).value; &#125;document.getElementById(\"result\").value = num;&#125;&lt;/script&gt;&lt;% int num=3;%&gt;&lt;form action=\"addAction\"&gt;&lt;input id=\"num\" name=\"num\" value=&lt;%=num %&gt; type=\"text\"&gt;&lt;% for(int i=0;i&lt;num;i++)&#123;%&gt;&lt;input id=\"num&lt;%=i %&gt;\" type=\"text\" onblur=\"n(&lt;%=num%&gt;)\"&gt;&lt;% &#125;%&gt;&lt;input name=\"str\" id=\"result\" type=\"hidden\" &gt;&lt;button &gt;提交&lt;/button&gt;&lt;/form&gt; 分析 最后来分析，到底是怎么实现的，其实道理特别简单，就是JavaScript获取input的个数，然后一个循环，将所有input合并，并且给到一个“hidden”的input里，在后台接收这个input就可以了。","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/categories/软件工程/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/tags/软件工程/"}]},{"title":"Git学习小结","slug":"use_git","date":"2016-10-21T07:50:24.000Z","updated":"2018-02-09T10:46:20.940Z","comments":true,"path":"posts/5850713f/","link":"","permalink":"http://meng.uno/posts/5850713f/","excerpt":"","text":"从Git官方教程出发 进入git教程官网我们可以发现，主要从这几个方面来讲解的（几乎所有你能搜到的博客都是这么一成不变！）： 建立项目 init clone 基本操作 add status diff commit reset rm mv 分支管理 branch checkout merge mergetool log stash tag 分享与更新 fetch pull push remote submodule 看到这里，我们基本的git学习就可以结束了，要问为什么我只写标题而不写内容，我只想说，我写这篇博客只是为了通过自己写一遍命令来复习一遍而已。😝","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/categories/软件工程/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/tags/软件工程/"}]},{"title":"E-mail小爬虫","slug":"ruby_email_crawler","date":"2016-10-10T06:18:08.000Z","updated":"2018-02-11T14:12:34.629Z","comments":true,"path":"posts/5d4e2c71/","link":"","permalink":"http://meng.uno/posts/5d4e2c71/","excerpt":"","text":"Ruby据说是一个比Python还要简洁还要快速的编程语言 ：） 好吧，这里并不是要挑起编程语言之间的战争，每个语言都有自己适应的场景，作为程序员应该知道在什么样的应用场景之下，用哪种的语言来实现业务逻辑，才是最重要的。 这次，我们使用Ruby来获取网页上的e-mail地址。 不知道各位有没有在成堆的垃圾邮件中，寻找某宝密码重置的邮件，简直是杯具…… 我们总是小心翼翼的保护着我们的邮箱，但还是被别有用心的人知道；e-mail爬虫就是这些人的工具之一，它可以在某个网页上过滤出一个个的e-mail，然后发送垃圾邮件。 “加密”你的email地址，防止爬虫收集 当然，我们抱着学习的心态，来了解它的基本结构，揭开它神秘的面纱。 代码下载： git clone http://git.shiyanlou.com/shiyanlou/email_spider 准备工作 实验楼已经提供了Ruby运行环境，但是，还是需要我们安装一些插件： 将gem下载源换为国内源 请确保只有ruby.taobao.org 12345 $ gem sources --remove http://rubygems.org/$ gem sources -a http://mirrors.aliyuncs.com/rubygems/$ gem sources -l**CURRENT SOURCES **http://mirrors.aliyuncs.com/rubygems/ 安装Ruby爬虫库 anemone 1234 $ sudo apt-get update$ sudo apt-get install ruby1.9.1-dev$ sudo apt-get install libsqlite3-dev$ sudo gem install anemone 查看对应的数据库支持 Ruby数据库支持 12 sudo gem install data_mappersudo gem install dm-sqlite-adapter 数据库设计 我们使用sqlite3来放置我们扒下来的数据： Site：存储爬行过的网站 Page：存储爬行过的存在email地址的页面的URL Address：email地址 我们只讲解其中一个表的model，其他更深入的请看： data_mapper property详解 Page模型需要include模块DataMapper::Resource，引入相应的方法，其中就包括了property，belongs_to，has n，validates_presence_of，这些我们马上需要用到的方法。 property：定义了对象的属性（表的字段类型），Serial是自增ID，并且是主键。 belongs_to： 定义了一对多的关系，一个网站可能包含了多个网页URL has n：定义多对多的关系，一个网页上可能包含多个email地址，一个email可能同时存在多个网页上。 validates_presence_of：检查 url是否存在。 data_mapper validates详解 爬虫代码 首先，我们需要引入uri 和 anemone包，其次还需要刚才定义的数据库的model 1234567 require 'uri'require 'anemone'require_relative 'data'data是对data.rb文件的引用。ARGV：获取命令行参数ruby crawl.rb http://www.test.test ARGV是Ruby的数组，所以我们用循环来处理它，因为我可以输入不只一个URL，如果，我们使用多线程的话，这样就可以同一时间处理多个URL，事半功倍。 然后马上使用URI()来处理传入的URL，结果返回给uri，下一步就把这个结果存入数据库中，uri.host网站的域名，和当前时间(这里使用的是内置模块Time) URI模块。 接下来的事情就很写意了，我们不需要自己去做很多的比如什么广度和深度算法的设计，我们只需要给它一个入口的URL，它会自动的去爬行，根本停不下来啊！ 使用模块Anemone的方法crawl创建一个新的爬虫，参数就传一个我们想爬行的URL就OK了！ Storage.PStore用来缓存新扒下来的网页代码，on_every_page处理每个页面，正则去匹配email，该页面的所有email会被包装在一个数组里面，然后循环这个数组并将结果存放数据库。 Anemone爬虫模块 if判断将会去查询address表，如果这个数据存在就更新，不存在则创建。 Datamapper更删查改详解 最后，将得到的E-mail地址输出到屏幕，又接着下一次循环，你要是不想等了，直接Ctrl+c吧 ：）","categories":[{"name":"Ruby","slug":"Ruby","permalink":"http://meng.uno/categories/Ruby/"},{"name":"爬虫","slug":"Ruby/爬虫","permalink":"http://meng.uno/categories/Ruby/爬虫/"},{"name":"E-mail","slug":"Ruby/爬虫/E-mail","permalink":"http://meng.uno/categories/Ruby/爬虫/E-mail/"}],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://meng.uno/tags/爬虫/"},{"name":"E-mail","slug":"E-mail","permalink":"http://meng.uno/tags/E-mail/"},{"name":"Ruby","slug":"Ruby","permalink":"http://meng.uno/tags/Ruby/"}]},{"title":"我的Java+Struts2+MySQL配置","slug":"profile_javaweb","date":"2016-10-07T11:18:54.000Z","updated":"2018-02-09T10:46:20.933Z","comments":true,"path":"posts/61cdd944/","link":"","permalink":"http://meng.uno/posts/61cdd944/","excerpt":"","text":"在Eclipse中配置Struts2 为了配置Struts2，首先我明确了，配置其所需要的各个部分的文件，我的理解是，一个web.xml(配置监听器)、一个struts.xml(配置“action”)、导入必要的jar包，现将配置好的文件结构截图展示如下： 其中，web.xml与struts.xml具体内容将在以后篇幅具体展开！ 在Eclipse中配置MySQL 通过对该实验的理解，我发现eclipse配置数据库，并不是针对某一个项目，而是针对整个集成开发环境，所以，相应地配置MySQL也是整个IDE的事，在软件的总配置中，如下图所示位置： 此为我成功地加入了MySQL之后的界面，如果没有加入，需要点击右侧的“Add…”进行添加，如下图： 由于我添加的是最新的MySQL 5.1，所以在具体的项目中，我也需要导入相应版本的jar包，用来加载MySQL驱动： 添加的具体方法是将本地的此jar文件拖动到“WebContent-&gt;WEB-INF-&gt;lib”文件夹下，然后右键，将其添加到“Build Path”。 在Eclipse中配置Tomcat Tomcat是一个开源的web应用服务器，与MySQL一样，它也是对整个集成开发环境而言的，所以关于其的配置，也在eclipse的设置中，已经配置好的环境如下： 如果是第一次配置，仍然需要点击右侧的“Add…”来选择你要安装的版本： 再下一步就是要选择安装的tomcat的地址与安装名称了： 点击结束，就会自动安装好，每次对着web项目点击右键，在“Run As”选项下，第一个，就是：Run On Server，即在tomcat上运行该程序。 至此，开发环境已经完全搭建好了，接下来就是实际的开发过程了!","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/categories/软件工程/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/tags/软件工程/"}]},{"title":"软工实验二回顾","slug":"lab2_se","date":"2016-10-06T12:42:57.000Z","updated":"2018-02-09T10:46:20.927Z","comments":true,"path":"posts/5353b854/","link":"","permalink":"http://meng.uno/posts/5353b854/","excerpt":"","text":"到现在为止，实验二基本上接近尾声了，今天发现了好几个特别坑的地方，现在乘着兴致，我将其总结如下： SAE的坑 首先，我想发表一下关于我们《软件工程》课所要用的SaaS平台——SAE的唾弃： 特别贵 特别不人性 错误特别多 …… 怎么应对SAE的坑 关于数据库的选择 我之前用的是“共享型”的，后来一直不成功，怎么都连不上（还不报错）！于是，我换成“独享型”还是没什么改变！！！在再三排查之后，发现原来是一个比较简单的又比较不注意的地方，而且网上还没有相关教程！！！ 原来， 我们本地的MySQL是不区分大小写的，而SAE上的MySQL大小写敏感！！ 连上数据库之后 在刚才的惊喜之后，又有了另一个问题，就是：原来SAE上传之后需要相对路径，不能使用我原来使用的绝对路径！ 关于中文 基本上在编写每一个页面时都会遇到关于中文的问题。 数据库插入中文 如果没有声明，默认情况下好像MySQL不是utf-8的编码，所以我将MySQL数据库地址后加入?useUnicode=true&amp;characterEncoding=utf8，就解决了这个问题。 网页传输遇到中文 我将一个页面的中文传递到另一个页面，发现在另一个页面接收时，其为空或者乱码，很乱的那种！后来，经过查询，我将“s”添加上，例如&lt;s:from&gt;…… 暂时只想到这么多啦！！","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/categories/软件工程/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/tags/软件工程/"}]},{"title":"软工实验一要点回顾","slug":"lab1_se","date":"2016-09-28T10:57:29.000Z","updated":"2018-02-09T10:46:20.926Z","comments":true,"path":"posts/9ba24af6/","link":"","permalink":"http://meng.uno/posts/9ba24af6/","excerpt":"","text":"距离实验一结束已经有一段时间了，之所以选择在现在这个时候写这篇回顾，是想考验一下，是否真的像老师说的那样： “变量名没有特殊意义的话，过段时间就看不懂了！” 虽然没有到那种程度，但是确实：养成一个好的起变量名的习惯，是非常非常重要的！ 这一次再看以前的代码，觉得有几点比较好的地方： 方法较清晰 我们组在一开始规划的时候，就将这次实验“藐视”了，以至于我们只能使用一开始想好的强大的数据结构：数组！！！ 我们几乎把每种数组都用了一遍，也算是锻炼我们Java结构化编程基础了吧！我们 用String数组存放以“+/-”分割下来的多项式的每一项； 用Int数组存放每一项的符号； 用Char数组存放原始的输入串的每一个字符——以删掉多余的空格…… 总之，Java基本的元素，我们淋漓尽致地用上了！！ 安排较合理 我们没有将这次实验当做什么大的项目来做，反而是想“投机取巧”。 怎么个巧呢？待我一点点招来： 首先，我们在基本功能保障的情况下，写好了化简以及简化、求导等主要功能； 然后，当我想要添加功能时，我觉得我可以不用改动已经写好的功能，而仅仅将输入做处理，做成我们需要的样子！！ 是不是很机智！ 于是，在我们后来的拓展中，我们仅仅以一个for循环就实现一个功能的神速，比较简单地完成了这次实验。 后记 这是我使用Java写的第一个项目，有很多东西没法用的那么熟练，例如：每次分割字符串，我们都是用“substring+for循环”来实现。 后来，我终于发现我为什么没法用 split了，原来在使用它的时候，参数如果是符号，就要加“\\”，对，是两个“\\”，这样才行。 也算是通过实验掌握的一个Java小知识吧！！","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/categories/软件工程/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://meng.uno/tags/软件工程/"}]},{"title":"一次数学建模经历","slug":"cumum2016","date":"2016-09-12T04:25:49.000Z","updated":"2018-02-09T10:46:20.920Z","comments":true,"path":"posts/832e4a48/","link":"","permalink":"http://meng.uno/posts/832e4a48/","excerpt":"","text":"经过三个白天，一个黑夜的战斗，我们终于如期赶出我们的数学建模论文。我将链接附加于此，希望大家帮忙指正。版权所有，请勿抄袭。 https://mega.nz/#!PMliSAbb!6hoWFHJEI3W3M0Exn6edmbhhl2CGdZa7XRom-KjktVI 结果：省一 三天日记 第一天 看看现在的时间，竞赛第一天就这么过去了。然而到现在为止，我们什么都没做！！ 为什么会这样？ 我觉得，最主要的原因，应该是我们组自己的问题——从来没有实际模拟过！就在开赛的前几天，我们还在为平时的课而发愁。 还有就是，我们的选题，虽然我学过一年的交通，但是在这道题上，我还是显得手足无措，丝毫没有思路，当初我们之所以选这道题是因为我们觉得第一题可能不太适合我们非数学系的人做，这么看来，第二题不适合 我们非工程学生做啊233。 我的想法 虽然有这么多的困难，但是我觉得我还是很有信心的，毕竟这次竞赛意义非比寻常！ 虽然有那么多的不适合，但是还是有很努力的小伙伴们一起！ 立个Flag 我们一定做好这次建模！ 第二天 我们或许还是太年轻，太没有经验，昨天大好时光居然就那么浪费了，谁知道今天依旧没有什么头绪。还 有10分钟就明天了，可是到现在我们连一个模型都没建好，连第一题都没有写出来。虽说第一次，失败了也没有关系，但是如果还有时间可以努力，但是已经宣布你失败了，谁会甘心！ 我们从早上8点到正心去合作讨论，一直到刚才不久，才回到寝楼的自习室，继续我们的”创举“，只能用充实来形容这一天天的生活。 不过，大学生嘛，总得在大学期间有所追求，有所疯狂，眼看着已经大三，这应该是我们这组人唯一一次参加的数学建模了。时间不多也不少，还有一半！ 看着对面的两个队友都在认真地查阅着文献，而我却在这写博客，着实有点不好意思，不过还好，马上就结束了，希望我能在接下来的一半时间里，认真投入，也预祝我们对在这次比赛中取得好成绩！ 第三天 本来昨天才应该是第三天，可是我觉得加上这11个小时，第三天才算完整！ 说实话，前两天我们真的没做出什么像样的东西来，连第二题都没有写完，连模型都没有建起来，但是最后一天往往就是转机！ 第三天如往常一样来临，这一次我们起的一个比一个晚，总是听到周围同学不想做了的豪情壮语，我们也有点想要放弃了呢。 但我们没一个人敢先提“放弃”，就这样我们仅仅抱着想把这次竞赛打完的想法，一点点凑着我们丝毫没有连贯性的论文。 夜，很快就来了，我们都感到疲倦。 最终只有我和赵正宇坚持熬夜来做，我们避开楼管大叔，来到正心楼8楼，准确地说是822教室，教室里随处可见考研教材和英语资料。 我们选了最后一排，继续我们的创作，本来丝毫没有连贯性的一篇一万多字的“杂文”，居然在我们不到三个小时的时间里将它完全驯服妥帖。 我们本来都在暗自高兴，也就聊到了其他的一些事情，可能没有这次竞赛，不会和这位老乡这么亲切，也不会体验到真正的努力是什么滋味！ 乘着兴致，我很快又做完了平时需要几个小时才能完成的评优评奖答辩PPT。 这是天已经亮了，哈尔滨远没有家乡那么热闹，一切都还在睡梦中。 我们迫不及待地一遍遍保存、转换格式、阅读……确保没有什么错误了，我们又急切地准备提交了。这一切简直不敢相信，只能说太佩服自己了！ 今天早晨，吃了这学期第一次早餐，最饱的一次早餐……","categories":[{"name":"数学建模","slug":"数学建模","permalink":"http://meng.uno/categories/数学建模/"}],"tags":[{"name":"数学建模","slug":"数学建模","permalink":"http://meng.uno/tags/数学建模/"}]},{"title":"基本算法","slug":"algorithm","date":"2016-07-17T13:01:44.000Z","updated":"2018-02-18T13:25:50.287Z","comments":true,"path":"posts/cff3a942/","link":"","permalink":"http://meng.uno/posts/cff3a942/","excerpt":"","text":"数论算法 求两数的最大公约数 function gcd(a,b:integer):integer; begin if b=0 then gcd:=a else gcd:=gcd (b,a mod b); end ; 123 ## 求两数的最小公倍数```stylus function lcm(a,b:integer):integer; begin if a&lt;b then swap(a,b); lcm:=a; while lcm mod b&gt;0 do inc(lcm,a); end; ## 素数的求法 ### 小范围内判断一个数是否为质数 1 function prime (n: integer): Boolean; var I: integer; begin for I:=2 to trunc(sqrt(n)) do if n mod I=0 then begin prime:=false; exit; end; prime:=true; end; ### 判断longint范围内的数是否为素数（包含求50000以内的素数表） ```stylus procedure getprime; var i,j:longint; p:array[1..50000] of boolean; begin fillchar(p,sizeof(p),true); p[1]:=false; i:=2; while i&lt;50000 do begin if p[i] then begin j:=i*2; while j&lt;50000 do begin p[j]:=false; inc(j,i); end; end; inc(i); end; l:=0; for i:=1 to 50000 do if p[i] then begin inc(l);pr[l]:=i; end; end;{getprime} function prime(x:longint):integer; var i:integer; begin prime:=false; for i:=1 to l do if pr[i]&gt;=x then break else if x mod pr[i]=0 then exit; prime:=true; end;{prime} 12345 # 图论算法## 最小生成树### Prim算法```stylus procedure prim(v0:integer); var lowcost,closest:array[1..maxn] of integer; i,j,k,min:integer; begin for i:=1 to n do begin lowcost[i]:=cost[v0,i]; closest[i]:=v0; end; for i:=1 to n-1 do begin &#123;寻找离生成树最近的未加入顶点k&#125; min:=maxlongint; for j:=1 to n do if (lowcost[j]&lt;min) and (lowcost[j]&lt;&gt;0) then begin min:=lowcost[j]; k:=j; end; lowcost[k]:=0; &#123;将顶点k加入生成树&#125; &#123;生成树中增加一条新的边k到closest[k]&#125; &#123;修正各点的lowcost和closest值&#125; for j:=1 to n do if cost[k,j]&lt;lwocost[j] then begin lowcost[j]:=cost[k,j]; closest[j]:=k; end; end; end;&#123;prim&#125; ### Kruskal算法(贪心) 按权值递增顺序删去图中的边，若不形成回路则将此边加入最小生成树。 1 function find(v:integer):integer; &#123;返回顶点v所在的集合&#125; var i:integer; begin i:=1; while (i&lt;=n) and (not v in vset[i]) do inc(i); if i&lt;=n then find:=i else find:=0; end; procedure kruskal; var tot,i,j:integer; begin for i:=1 to n do vset[i]:=[i];&#123;初始化定义n个集合，第I个集合包含一个元素I&#125; p:=n-1; q:=1; tot:=0; &#123;p为尚待加入的边数，q为边集指针&#125; sort; &#123;对所有边按权值递增排序，存于e[I]中，e[I].v1与e[I].v2为边I所连接的两个顶点的序号，e[I].len为第I条边的长度&#125; while p&gt;0 do begin i:=find(e[q].v1);j:=find(e[q].v2); if i&lt;&gt;j then begin inc(tot,e[q].len); vset[i]:=vset[i]+vset[j];vset[j]:=[]; dec(p); end; inc(q); end; writeln(tot); end; ## 最短路径 ### 标号法求解单源点最短路径 ```stylus var a:array[1..maxn,1..maxn] of integer; b:array[1..maxn] of integer; {b[i]指顶点i到源点的最短路径} mark:array[1..maxn] of boolean; procedure bhf; var best,best_j:integer; begin fillchar(mark,sizeof(mark),false); mark[1]:=true; b[1]:=0;{1为源点} repeat best:=0; for i:=1 to n do If mark[i] then {对每一个已计算出最短路径的点} for j:=1 to n do if (not mark[j]) and (a[i,j]&gt;0) then if (best=0) or (b[i]+a[i,j]&lt;best) then begin best:=b[i]+a[i,j]; best_j:=j; end; if best&gt;0 then begin b[best_j]:=best；mark[best_j]:=true; end; until best=0; end;{bhf} 123 ### Floyed算法求解所有顶点对之间的最短路径```stylus procedure floyed; begin for I:=1 to n do for j:=1 to n do if a[I,j]&gt;0 then p[I,j]:=I else p[I,j]:=0; &#123;p[I,j]表示I到j的最短路径上j的前驱结点&#125; for k:=1 to n do &#123;枚举中间结点&#125; for i:=1 to n do for j:=1 to n do if a[i,k]+a[j,k]&lt;a[i,j] then begin a[i,j]:=a[i,k]+a[k,j]; p[I,j]:=p[k,j]; end; end; ### Dijkstra 算法 ```stylus var a:array[1..maxn,1..maxn] of integer; b,pre:array[1..maxn] of integer; {pre[i]指最短路径上I的前驱结点} mark:array[1..maxn] of boolean; procedure dijkstra(v0:integer); begin fillchar(mark,sizeof(mark),false); for i:=1 to n do begin d[i]:=a[v0,i]; if d[i]&lt;&gt;0 then pre[i]:=v0 else pre[i]:=0; end; mark[v0]:=true; repeat {每循环一次加入一个离1集合最近的结点并调整其他结点的参数} min:=maxint; u:=0; {u记录离1集合最近的结点} for i:=1 to n do if (not mark[i]) and (d[i]&lt;min) then begin u:=i; min:=d[i]; end; if u&lt;&gt;0 then begin mark[u]:=true; for i:=1 to n do if (not mark[i]) and (a[u,i]+d[u]&lt;d[i]) then begin d[i]:=a[u,i]+d[u]; pre[i]:=u; end; end; until u=0; end; 123 ## 计算图的传递闭包```stylus Procedure Longlink; Var T:array[1..maxn,1..maxn] of boolean; Begin Fillchar(t,sizeof(t),false); For k:=1 to n do For I:=1 to n do For j:=1 to n do T[I,j]:=t[I,j] or (t[I,k] and t[k,j]); End; ## 无向图的连通分量 ### 深度优先 ```stylus procedure dfs ( now,color: integer); begin for i:=1 to n do if a[now,i] and c[i]=0 then begin {对结点I染色} c[i]:=color; dfs(I,color); end; end; 12345678910111213141516171819202122 ### 宽度优先（种子染色法） ## 关键路径 几个定义： 顶点1为源点，n为汇点。 a. 顶点事件最早发生时间Ve[j], Ve [j] = max&#123; Ve [j] + w[I,j] &#125;,其中Ve (1) = 0; b. 顶点事件最晚发生时间 Vl[j], Vl [j] = min&#123; Vl[j] – w[I,j] &#125;,其中 Vl(n) = Ve(n); c. 边活动最早开始时间 Ee[I], 若边I由&lt;j,k&gt;表示，则Ee[I] = Ve[j]; d. 边活动最晚开始时间 El[I], 若边I由&lt;j,k&gt;表示，则El[I] = Vl[k] – w[j,k]; 若 Ee[j] = El[j] ，则活动j为关键活动，由关键活动组成的路径为关键路径。 求解方法： a. 从源点起topsort,判断是否有回路并计算Ve; b. 从汇点起topsort,求Vl; c. 算Ee 和 El; ## 拓扑排序 找入度为0的点，删去与其相连的所有边，不断重复这一过程。 例：寻找一数列，其中任意连续p项之和为正，任意q 项之和为负，若不存在则输出NO. ## 回路问题 ### Euler回路(DFS) 定义：经过图的每条边仅一次的回路。（充要条件：图连同且无奇点） ### Hamilton回路 定义：经过图的每个顶点仅一次的回路。 一笔画 充要条件：图连通且奇点个数为0个或2个。 ## 判断图中是否有负权回路 Bellman-ford 算法 x[I],y[I],t[I]分别表示第I条边的起点，终点和权。共n个结点和m条边。```stylus procedure bellman-ford begin for I:=0 to n-1 do d[I]:=+infinitive; d[0]:=0; for I:=1 to n-1 do for j:=1 to m do &#123;枚举每一条边&#125; if d[x[j]]+t[j]&lt;d[y[j]] then d[y[j]]:=d[x[j]]+t[j]; for I:=1 to m do if d[x[j]]+t[j]&lt;d[y[j]] then return false else return true; end; ## 第n最短路径问题 **第二最短路径：每举最短路径上的每条边，每次删除一条，然后求新图的最短路径，取这些路径中最短的一条即为第二最短路径。同理，第n最短路径可在求解第n-1最短路径的基础上求解。** # 背包问题 ## 部分背包问题可有贪心法求解：计算Pi/Wi - 数据结构： - w[i]:第i个背包的重量； - p[i]:第i个背包的价值； ## 0-1背包： 每个背包只能使用一次或有限次(可转化为一次) ### 求最多可放入的重量。 有一个箱子容量为v(正整数，o≤v≤20000)，同时有n个物品(o≤n≤30)，每个物品有一个体积 (正整数)。要求从 n 个物品中，任取若千个装入箱内，使箱子的剩余空间为最小。 #### 搜索方法 ```stylus procedure search(k,v:integer); {搜索第k个物品，剩余空间为v} var i,j:integer; begin if v&lt;best then best:=v; if v-(s[n]-s[k-1])&gt;=best then exit; {s[n]为前n个物品的重量和} if k&lt;=n then begin if v&gt;w[k] then search(k+1,v-w[k]); search(k+1,v); end; end; 12345678 #### DP F[I,j]为前i个物品中选择若干个放入使其体积正好为j的标志，为布尔型。 实现:将最优化问题转化为判定性问题 ```stylusf [I, j] = f [ i-1, j-w[i] ] (w[I]&lt;=j&lt;=v) 边界：f[0,0]:=true. For I:=1 to n do For j:=w[I] to v do F[I,j]:=f[I-1,j-w[I]]; 优化：当前状态只与前一阶段状态有关，可降至一维。 F[0]:=true; For I:=1 to n do begin F1:=f; For j:=w[I] to v do If f[j-w[I]] then f1[j]:=true; F:=f1; End;``` ### 求可以放入的最大价值。```stylus F[I,j] 为容量为I时取前j个背包所能获得的最大价值。 F [i,j] = max &#123; f [ i – w [ j ], j-1] + p [ j ], f[ i,j-1] &#125; ### 求恰好装满的情况数。 ```stylus DP: Procedure update; var j,k:integer; begin c:=a; for j:=0 to n do if a[j]&gt;0 then if j+now&lt;=n then inc(c[j+now],a[j]); a:=c; end; 123456789101112 ## 可重复背包 ### 求最多可放入的重量。 F[I,j]为前i个物品中选择若干个放入使其体积正好为j的标志，为布尔型。 状态转移方程为: f[I,j] = f [ I-1, j – w[I]*k ] (k=1.. j div w[I]) ### 求可以放入的最大价值。 进行一次竞赛，总时间T固定，有若干种可选择的题目，每种题目可选入的数量不限，每种题目有一个ti（解答此题所需的时间）和一个si（解答此题所得的分数），现要选择若干题目，使解这些题的总时间在T以内的前提下，所得的总分最大，求最大的得分。 易想到： f[i,j] = max &#123; f [i- k*w[j], j-1] + k*p[j] &#125; (0&lt;=k&lt;= i div w[j]) 其中f[i,j]表示容量为i时取前j种背包所能达到的最大值。 实现：```stylus Begin FillChar(f,SizeOf(f),0); For i:=1 To M Do For j:=1 To N Do If i-problem[j].time&gt;=0 Then Begin t:=problem[j].point+f[i-problem[j].time]; If t&gt;f[i] Then f[i]:=t; End; Writeln(f[M]); End. ### 求恰好装满的情况数。 求自然数n本质不同的质数和的表达式的数目。 思路一，生成每个质数的系数的排列，在一一测试，这是通法。 1 procedure try(dep:integer); var i,j:integer; begin cal; &#123;此过程计算当前系数的计算结果，now为结果&#125; if now&gt;n then exit; &#123;剪枝&#125; if dep=l+1 then begin &#123;生成所有系数&#125; cal; if now=n then inc(tot); exit; end; for i:=0 to n div pr[dep] do begin xs[dep]:=i; try(dep+1); xs[dep]:=0; end; end; 思路二，递归搜索效率较高 1 procedure try(dep,rest:integer); var i,j,x:integer; begin if (rest&lt;=0) or (dep=l+1) then begin if rest=0 then inc(tot); exit; end; for i:=0 to rest div pr[dep] do try(dep+1,rest-pr[dep]*i); end; &#123;main: try(1,n); &#125; 思路三：可使用动态规划求解 V个物品，背包容量为n，求放法总数。 实现： ```stylus Procedure update; var j,k:integer; begin c:=a; for j:=0 to n do if a[j]&gt;0 then for k:=1 to n div now do if j+now*k&lt;=n then inc(c[j+now*k],a[j]); a:=c; end; {main} begin read(now); {读入第一个物品的重量} i:=0; {a[i]为背包容量为i时的放法总数} while i&lt;=n do begin a[i]:=1; inc(i,now); end; {定义第一个物品重的整数倍的重量a值为1，作为初值} for i:=2 to v do begin read(now); update; {动态更新} end; writeln(a[n]); 123 # 排序算法 ## 快速排序```stylus procedure qsort(l,r:integer); var i,j,mid:integer; begin i:=l;j:=r; mid:=a[(l+r) div 2]; &#123;将当前序列在中间位置的数定义为中间数&#125; repeat while a[i]&lt;mid do inc(i); &#123;在左半部分寻找比中间数大的数&#125; while a[j]&gt;mid do dec(j);&#123;在右半部分寻找比中间数小的数&#125; if i&lt;=j then begin &#123;若找到一组与排序目标不一致的数对则交换它们&#125; swap(a[i],a[j]); inc(i);dec(j); &#123;继续找&#125; end; until i&gt;j; if l&lt;j then qsort(l,j); &#123;若未到两个数的边界，则递归搜索左右区间&#125; if i&lt;r then qsort(i,r); end;&#123;sort&#125; ## 插入排序 思路：当前a[1]..a[i-1]已排好序了，现要插入a[i]使a[1]..a[i]有序。 1 procedure insert_sort; var i,j:integer; begin for i:=2 to n do begin a[0]:=a[i]; j:=i-1; while a[0]&lt;a[j] do begin a[j+1]:=a[j]; j:=j-1; end; a[j+1]:=a[0]; end; end;&#123;inset_sort&#125; ## 选择排序 ```stylus procedure sort; var i,j,k:integer; begin for i:=1 to n-1 do for j:=i+1 to n do if a[i]&gt;a[j] then swap(a[i],a[j]); end; 123 ## 冒泡排序```stylus procedure bubble_sort; var i,j,k:integer; begin for i:=1 to n-1 do for j:=n downto i+1 do if a[j]&lt;a[j-1] then swap( a[j],a[j-1]); &#123;每次比较相邻元素的关系&#125; end; ## 堆排序 ```stylus procedure sift(i,m:integer);{调整以i为根的子树成为堆,m为结点总数} var k:integer; begin a[0]:=a[i]; k:=2*i;{在完全二叉树中结点i的左孩子为2*i,右孩子为2*i+1} while k&lt;=m do begin if (k&lt;m) and (a[k]&lt;a[k+1]) then inc(k);{找出a[k]与a[k+1]中较大值} if a[0]&lt;a[k] then begin a[i]:=a[k];i:=k;k:=2*i; end else k:=m+1; end; a[i]:=a[0]; {将根放在合适的位置} end; procedure heapsort; var j:integer; begin for j:=n div 2 downto 1 do sift(j,n); for j:=n downto 2 do begin swap(a[1],a[j]); sift(1,j-1); end; end; 123 ## 归并排序```stylus &#123;a为序列表，tmp为辅助数组&#125; procedure merge(var a:listtype; p,q,r:integer); &#123;将已排序好的子序列a[p..q]与a[q+1..r]合并为有序的tmp[p..r]&#125; var I,j,t:integer; tmp:listtype; begin t:=p;i:=p;j:=q+1;&#123;t为tmp指针，I,j分别为左右子序列的指针&#125; while (t&lt;=r) do begin if (i&lt;=q)&#123;左序列有剩余&#125; and ((j&gt;r) or (a[i]&lt;=a[j])) &#123;满足取左边序列当前元素的要求&#125; then begin tmp[t]:=a[i]; inc(i); end else begin tmp[t]:=a[j];inc(j); end; inc(t); end; for i:=p to r do a[i]:=tmp[i]; end;&#123;merge&#125; procedure merge_sort(var a:listtype; p,r: integer); &#123;合并排序a[p..r]&#125; var q:integer; begin if p&lt;&gt;r then begin q:=(p+r-1) div 2; merge_sort (a,p,q); merge_sort (a,q+1,r); merge (a,p,q,r); end; end; &#123;main&#125; begin merge_sort(a,1,n); end. ## 基数排序 思想：对每个元素按从低位到高位对每一位进行一次排序 # 高精度计算 高精度数的定义： 1 type hp=array[1..maxlen] of integer; ## 高精度加法 ```stylus procedure plus ( a,b:hp; var c:hp); var i,len:integer; begin fillchar(c,sizeof(c),0); if a[0]&gt;b[0] then len:=a[0] else len:=b[0]; for i:=1 to len do begin inc(c[i],a[i]+b[i]); if c[i]&gt;10 then begin dec(c[i],10); inc(c[i+1]); end; {进位} end; if c[len+1]&gt;0 then inc(len); c[0]:=len; end;{plus} 123 ## 高精度减法```stylus procedure substract(a,b:hp;var c:hp); var i,len:integer; begin fillchar(c,sizeof(c),0); if a[0]&gt;b[0] then len:=a[0] else len:=b[0]; for i:=1 to len do begin inc(c[i],a[i]-b[i]); if c[i]&lt;0 then begin inc(c[i],10);dec(c[i+1]); end; while (len&gt;1) and (c[len]=0) do dec(len); c[0]:=len; end; ## 高精度乘以低精度 ```stylus procedure multiply(a:hp;b:longint;var c:hp); var i,len:integer; begin fillchar(c,sizeof(c),0); len:=a[0]; for i:=1 to len do begin inc(c[i],a[i]*b); inc(c[i+1],(a[i]*b) div 10); c[i]:=c[i] mod 10; end; inc(len); while (c[len]&gt;=10) do begin {处理最高位的进位} c[len+1]:=c[len] div 10; c[len]:=c[len] mod 10; inc(len); end; while (len&gt;1) and (c[len]=0) do dec(len); {若不需进位则调整len} c[0]:=len; end;{multiply} 123 ## 高精度乘以高精度```stylus procedure high_multiply(a,b:hp; var c:hp&#125; var i,j,len:integer; begin fillchar(c,sizeof(c),0); for i:=1 to a[0] do for j:=1 to b[0] do begin inc(c[i+j-1],a[i]*b[j]); inc(c[i+j],c[i+j-1] div 10); c[i+j-1]:=c[i+j-1] mod 10; end; len:=a[0]+b[0]+1; while (len&gt;1) and (c[len]=0) do dec(len); c[0]:=len; end; ## 高精度除以低精度 ```stylus procedure devide(a:hp;b:longint; var c:hp; var d:longint); {c:=a div b; d:= a mod b} var i,len:integer; begin fillchar(c,sizeof(c),0); len:=a[0]; d:=0; for i:=len downto 1 do begin d:=d*10+a[i]; c[i]:=d div b; d:=d mod b; end; while (len&gt;1) and (c[len]=0) then dec(len); c[0]:=len; end; 123 ## 高精度除以高精度```stylus procedure high_devide(a,b:hp; var c,d:hp); var i,len:integer; begin fillchar(c,sizeof(c),0); fillchar(d,sizeof(d),0); len:=a[0];d[0]:=1; for i:=len downto 1 do begin multiply(d,10,d); d[1]:=a[i]; while(compare(d,b)&gt;=0) do &#123;即d&gt;=b&#125; begin Subtract(d,b,d); inc(c[i]); end; end; while(len&gt;1)and(c.s[len]=0) do dec(len); c.len:=len; end; # 树的遍历 ## 已知前序中序求后序 ```stylus procedure Solve(pre,mid:string); var i:integer; begin if (pre='') or (mid='') then exit; i:=pos(pre[1],mid); solve(copy(pre,2,i),copy(mid,1,i-1)); solve(copy(pre,i+1,length(pre)-i),copy(mid,i+1,length(mid)-i)); post:=post+pre[1]; {加上根，递归结束后post即为后序遍历} end; 123 ## 已知中序后序求前序```stylus procedure Solve(mid,post:string); var i:integer; begin if (mid=&apos;&apos;) or (post=&apos;&apos;) then exit; i:=pos(post[length(post)],mid); pre:=pre+post[length(post)]; &#123;加上根，递归结束后pre即为前序遍历&#125; solve(copy(mid,1,I-1),copy(post,1,I-1)); solve(copy(mid,I+1,length(mid)-I),copy(post,I,length(post)-i)); end; ## 已知前序后序求中序的一种 ```stylus function ok(s1,s2:string):boolean; var i,l:integer; p:boolean; begin ok:=true; l:=length(s1); for i:=1 to l do begin p:=false; for j:=1 to l do if s1[i]=s2[j] then p:=true; if not p then begin ok:=false;exit;end; end; end; procedure solve(pre,post:string); var i:integer; begin if (pre='') or (post='') then exit; i:=0; repeat inc(i); until ok(copy(pre,2,i),copy(post,1,i)); solve(copy(pre,2,i),copy(post,1,i)); midstr:=midstr+pre[1]; solve(copy(pre,i+2,length(pre)-i-1),copy(post,i+1,length(post)-i-1)); end; 123456789 # 进制转换 ## 任意正整数进制间的互化 除n取余 ## 实数任意正整数进制间的互化 乘n取整 ## 负数进制 设计一个程序，读入一个十进制数的基数和一个负进制数的基数，并将此十进制数转换为此负 进制下的数：-R∈&#123;-2，-3，-4,....-20&#125; # 全排列与组合的生成 ## 排列的生成：（1..n） ```stylusprocedure solve(dep:integer); var i:integer; begin if dep=n+1 then begin writeln(s);exit; end; for i:=1 to n do if not used[i] then begin s:=s+chr(i+ord(&apos;0&apos;));used[i]:=true; solve(dep+1); s:=copy(s,1,length(s)-1); used[i]:=false; end; end; ## 组合的生成(1..n中选取k个数的所有方案) 1 procedure solve(dep,pre:integer); var i:integer; begin if dep=k+1 then begin writeln(s);exit; end; for i:=1 to n do if (not used[i]) and (i&gt;pre) then begin s:=s+chr(i+ord('0'));used[i]:=true; solve(dep+1,i); s:=copy(s,1,length(s)-1); used[i]:=false; end; end; # 查找算法 ## 折半查找 ```stylus function binsearch(k:keytype):integer; var low,hig,mid:integer; begin low:=1;hig:=n; mid:=(low+hig) div 2; while (a[mid].key&lt;&gt;k) and (low&lt;=hig) do begin if a[mid].key&gt;k then hig:=mid-1 else low:=mid+1; mid:=(low+hig) div 2; end; if low&gt;hig then mid:=0; binsearch:=mid; end; 12345 ## 树形查找 二叉排序树：每个结点的值都大于其左子树任一结点的值而小于其右子树任一结点的值。 查找 ```stylusfunction treesrh(k:keytype):pointer; var q:pointer; begin q:=root; while (q&lt;&gt;nil) and (q^.key&lt;&gt;k) do if k&lt;q^.key then q:=q^.left else q:=q^.right; treesrh:=q; end; # 贪心 会议问题 - n个活动每个活动有一个开始时间和一个结束时间，任一时刻仅一项活动进行，求满足活动数最多的情况。 解：按每项活动的结束时间进行排序，排在前面的优先满足。 - 会议室空闲时间最少。 - 每个客户有一个愿付的租金，求最大利润。 - 共R间会议室，第i个客户需使用i间会议室，费用相同，求最大利润。 # 回溯法框架 ## n皇后问题 ```stylus procedure try(i:byte); var j:byte; begin if i=n+1 then begin print;exit;end; for j:=1 to n do if a[i] and b[j+i] and c[j-i] then begin x[i]:=j; a[j]:=false; b[j+i]:=false; c[j-i]:=false; try(i+1); a[j]:=true; b[i+j]:=true; c[j-i]:=true; end; end; 1234 ## Hanoi Tower ```stylus h(n)=2*h(n-1)+1 h(1)=1 初始所有铜片都在a柱上 procedure hanoi(n,a,b,c:byte); &#123;将第n块铜片从a柱通过b柱移到c柱上&#125; begin if n=0 then exit; hanoi(n-1,a,c,b); &#123;将上面的n-1块从a柱通过c柱移到b柱上&#125; write(n,’moved from’,a,’to’,c); hanoi(n-1,b,a,c);&#123; 将b上的n-1块从b柱通过a柱移到c柱上 end; 初始铜片分布在3个柱上，给定目标柱goal h[1..3,0..n]存放三个柱的状态，now与nowp存最大的不到位的铜片的柱号和编号,h[I,0]存第I个柱上的个数。 Procedure move(k,goal:integer); &#123;将最大不到位的k移到目标柱goal上&#125; Begin If k=0 then exit; For I:=1 to 3 do For j:=1 to han[I,0] do If h[I,j]=k then begin now:=I;nowp:=j; end; &#123;找到k的位置&#125; If now&lt;&gt;goal then begin &#123;若未移到目标&#125; Move(k-1,6-now-goal); &#123;剩下的先移到没用的柱上&#125; Writeln(k moved from now to goal); H[goal,h[goal,0]+1]:=h[now,nowp]; h[now,nowp]:=0; Inc(h[goal,0]); dec(h[now,0]); Move(k-1,goal); &#123;剩下的移到目标上&#125; End; # DFS框架 ```stylus procedure work(dep,pre,s:longint); {入口为work(1,1,n)} {dep为当前试放的第dep个数,pre为前一次试放的数,s为当前剩余可分的总数} var j:longint; begin if dep=n then begin if s&gt;=pre then inc(r); exit; end; for j:=pre to s div 2 do work(dep+1,j,s-j); end; 类似： procedure try(dep:integer); var i:integer; begin if dep=k then begin if tot&gt;=a[dep-1] then inc(sum); exit; end; for i:=a[dep-1] to tot div 2 do begin a[dep]:=i; dec(tot,i); try(dep+1); inc(tot,i); end; end;{try} 12 # BFS框架 ```stylus head:=1; tail:=0; while tail&lt;head do begin inc(tail); for k:=1 to n do if k方向可扩展 then begin inc(head); list[head].x:=list[tail].x+dx[k]; &#123;扩展出新结点list[head]&#125; list[head].y:=list[tail].y+dy[k]; 处理新结点list[head]; end; end; # 数据结构相关算法 ## 链表的定位函数loc(I:integer):pointer; {寻找链表中的第I个结点的指针} ```stylus procedure loc(L:linklist; I:integer):pointer; var p:pointer; j:integer; begin p:=L.head; j:=0; if (I&gt;=1) and (I&lt;=L.len) then while j&lt;I do begin p:=p^.next; inc(j); end; loc:=p; end; 123 ## 单链表的插入操作```stylus procedure insert(L:linklist; I:integer; x:datatype); var p,q:pointer; begin p:=loc(L,I); new(q); q^.data:=x; q^.next:=p^.next; p^.next:=q; inc(L.len); end; ## 单链表的删除操作 ```stylus procedure delete(L:linklist; I:integer); var p,q:pointer; begin p:=loc(L,I-1); q:=p^.next; p^.next:=q^.next; dispose(q); dec(L.len); end; 123 ## 双链表的插入操作（插入新结点q） ```stylusp:=loc(L,I); new(q); q^.data:=x; q^.pre:=p; q^.next:=p^.next; p^.next:=q; q^.next^.pre:=q; ## 双链表的删除操作 1 p:=loc(L,I); &#123;p为要删除的结点&#125; p^.pre^.next:=p^.next; p^.next^.pre:=p^.pre; dispose(p); ## 关键路径（最长路经） ```stylus var a,b:array [1..10,1..10] of integer; n,last,out:integer; q,c:array [1..10] of integer; o:set of 1..10; procedure init; var i,j:integer; begin readln(n); for i:=1 to n do for j:=1 to n do read(a[i,j]); last:=0; o:=[]; out:=0; b:=a; end; procedure sort; var i,j:integer; p:boolean; begin while out&lt;&gt;n do begin for i:=1 to n do if not (i in o) then begin p:=true; for j:=1 to n do if a[j,i]=1 then begin p:=false; break; end; if p then begin inc(last); q[last]:=i; inc(out); o:=o+[i]; fillchar(a[i],sizeof(a[i]),0); end; end; end; end; procedure work_1; var i,j,t,k:integer; begin a:=b; c[1]:=0; for i:=1 to n do begin k:=0; for j:=1 to i-1 do if (a[q[j],q[i]]&gt;0) and (a[q[j],q[i]]+c[q[j]]&gt;k) then k:=a[q[j],q[i]]+c[q[j]]; c[q[i]]:=k; end; end; procedure work_2; var i,j,k:integer; begin writeln(q[n]); for i:=n-1 downto 1 do begin k:=maxint; for j:=i+1 to n do if (a[q[i],q[j]]&gt;0) and (c[q[j]]-a[q[i],q[j]]&lt;k) then k:=c[q[j]]-a[q[i],q[j]]; if c[q[i]]=k then writeln(q[i],' '); c[q[i]]:=k; end; end; begin init; sort; work_1; work_2; end. 123 ## 拓扑排序```stylus var a:array [1..100,1..100] of 0..1; n:integer; p:set of 1..100; procedure init; var i,j,k:integer; begin fillchar(a,sizeof(a),0); readln(n); for i:=1 to n do begin read(k); while k&lt;&gt;0 do begin a[i,k]:=1; read(k); end; end; p:=[]; end; procedure search; var i,j,t,sum,printed:integer; begin printed:=0; while printed&lt;n do for i:=1 to n do begin sum:=0; for j:=1 to n do sum:=sum+a[j,i]; if (sum=0) and not(i in p) then begin write(i,&apos; &apos;); p:=p+[i]; inc(printed); for t:=1 to n do a[i,t]:=0; end; end; end; begin init; search; end.","categories":[{"name":"算法设计","slug":"算法设计","permalink":"http://meng.uno/categories/算法设计/"}],"tags":[{"name":"算法设计","slug":"算法设计","permalink":"http://meng.uno/tags/算法设计/"}]},{"title":"完全动态最大匹配的简单确定性算法","slug":"biggest-match","date":"2016-07-16T12:40:27.000Z","updated":"2018-02-18T13:25:50.291Z","comments":true,"path":"posts/8e9f2014/","link":"","permalink":"http://meng.uno/posts/8e9f2014/","excerpt":"","text":"Simple Deterministic Algorithms for Fully Dynamic Maximal Matching 解决的问题 这篇文章介绍了什么是“完全动态最大匹配”，然后介绍了他们提供的在最坏情况下更新时间为平摊O(√m)（m表示图中的边数）时间复杂度、O(n+m)空间复杂度内完成的“3/2-近似最大基数匹配（MCM）”算法。这篇文章是为了处理图论中的“匹配”问题，作者将“图”分成[1]一般图，[2]低荫度[4]图 两种来处理。而对于每种图，处理步骤与方法基本一致，每种图都有——“插入”、“删除”两种操作，所不同的就是每种图所对应的情况（Case）不同而已。 采用的思想 这篇算法总体采用了分治的思想在每个小的情况下又有贪心算法的影子，本来“3/2-近似最大基数匹配（MCM）”这个问题相当难解决，而且已知算法中，要么时间复杂度为O(n)，要么为O((n+m)√2/2)而且相当复杂，情况相当多。这篇算法一个很大的优点就是，思路清晰，作者将自己设计算法的思路，无遗地展现在读者面前。说起思路清晰，也就是分的情况条例清晰，也就是我们所说的分治思想。本来一个大问题不好求解，但我们可以通过将其分解为等价的几个小问题分别求解。 就像这篇算法，将“完全动态最大匹配”分为一般图与低荫度图两个部分来分别阐述，让算法在一般情况以及特殊情况都能游刃有余。 在应对每一大类图的各种操作（插入或删除）时，由于仍旧很复杂，所以作者又一次运用分治思想，将他们每个具体的操作继续分解为更小的几种情况，同时做到面面俱到，条理清晰。 在每一个小的情况下，遍历所有情况，找出能使匹配最大的情况，属于贪心的范畴，对于贪心算法，由于每种情况实在所要找的节点较少，所以我也认为贪心是比较不错的选择，而且，我们没必要在这样的小点上过于纠结。 基本算法描述 一般图 定义V={1,2……n}表示图的顶点的集合 为了简单处理，假定√n为整数； 定义G = (G0,G1……)表示图的集合，而且定义G0为空图，Gi由Gi-1得到； 对于每一个时间跨度i,Gi=(V,Ei),mi=|Ei| （m表示图中的边数）。 数据结构 M 存储在AVL树中（支持O(logn)时间复杂度的插入、删除）每个节点v处保存mate(v)返回当前匹配中的邻接顶点； N(v) 存储在AVL树中（v∈V）用于存储节点v的邻接顶点，变量deg(v)存储v的度（无向图）（支持O(logn)时间复杂度的插入、删除以及取出r邻接顶点在O(r)时间复杂度内）； F(v)（v∈V）用于保存v的自由邻接节点（支持O(1)时间复杂度下的插入、删除以及如果有自由邻接顶点就返回TRUE的has-free(v)操作，O(√n)时间复杂度下的返回任意自由邻接顶点的get-free(v)操作），为了很好的得出F(v)，还另外加了一个长度为n的Boolean型数组来表明当前自由邻接顶点、一个长度为√n的范围在[√nj+1,√n(j+1)]的计数数组来保存位置j处的自由邻接顶点的数目、一个变量来存储总的自由邻接节点数。 一个最大堆Fmax存储所有的以自身的度为权的自由节点（支持O(logn)时间内的插入、删除、update-key、find-max操作）。 具体算法 初始化图后，定义三个不变量，每次程序循环运行结束都不会突破这些不变量： 不变量1：所有节点度不超过√(2m+2n)； 不变量2：在第i次循环变为自由节点的节点度不超过√(2m)； 不变量3：M是最大匹配，而且没有长度为3的增光路径。 然后进行循环，每次循环对边ei进行操作。 插入边ei={u,v}的操作 首先更新相关的数据结构：N(u),N(v),deg(u),deg(v),Fmax以及u、v的值。 然后分如下四种情况讨论： u、v都已匹配，此时无需操作； u、v都是自由节点，这种情况下涉及更新M与Fmax，将u、v从F(x)中移除，花费O(√n+m)时间； u是自由的而v已被匹配，这种境况下，找到最大匹配集M中与v匹配的节点x=mate(v),再找到与x邻接的自由顶点w，如果能找到，则将匹配(x,v)移除，而将（u,v)、(x,w)加入。操作时间也在O(√n+m)内； v是自由的而v已被匹配，这种情况与上一种相对称。 删除边ei={u,v}的操作 删除操作主要分为两种情况： ei ∉ M 唯一要做的事就是，将u从F(v)，v从F(u)中删去； ei∈M 由分为两种情况讨论： deg(u)≤√(2m) 时，我们必须通过aug-path(u)来所搜一条以u为起点的长度为3的增广路径，如果没有找到，那么直接标定v为自由节点即可，如果找到，定义u的自由邻接节点为w，w的邻接顶点为y，y的自由临界顶点为x，将{u,w}和{y,x}添加到匹配中而将{w,y}删除，同样的方法处理v。 deg(u)&gt;√(2m) 时，此时u不能自由，因为它的度太高。保持u匹配，我们通过surrogate(u)来获取u的代替节点，我们称呼为su，改变它的状态为自由，然后像在a)中处理u一样处理su。 对于低荫度图 在这部分中，考虑的是荫度不大于c的图，而c由下式确定： 其中E(U)表示U中的边数。 由于图较稀疏，所以将每条边都带上方向，构成△-方向无向图 数据结构 与一般图基本相同。 具体算法 主要从：定向、插入、删除，几个部分来阐述： 定向 在每一步中，都通过运行算法A，来保证当前图是△-方向的。像如下算法中那样更新F和D，如果有t条边在定向，我们需要O(t)时间。 插入边ei={u,v}的操作 由于出度最多为△，所以插入时间O(△)。 删除边ei={u,v}的操作 未匹配的边被删除没什么可以操作的，但是当匹配的边被删除就有趣了，这里必须找到u(v)的匹配节点，时间复杂度仍为O(△)。 算法分析的结论 分析这个算法，其时间复杂度确实是平摊条件[4]下O(√m)(m表示图的边数)； 其空间复杂度为O(m+n)。 这个算法确实能在最短的时间内的出“3/2-近似最大基数匹配（MCM）”。 用一个例子说明相关算法 为了较好的说明这个算法，我仅就自己画的一个图做些简要的分析，有遗漏之处实属算法没理解透： （图如下，分别由6个顶点、7条边组成，由于算法本身要求图中点、边数目较多，而简短的语言无法描述清楚，所以选择这样一个简单的图来叙述） 以下模拟算法过程：（只举例说明） 由文章知，该算法要处理动态图的最大匹配问题，首先初始化G0为空，我们按e0—e6的顺序向图中添加边，然后删除边。 将e0（AB）加入，直接将此边加入最大匹配M； 将e1（AC）加入，不操作； 将e2（BC）加入，不操作； 将e3（CE）加入，直接将此边加入M； 将e4（BF）加入，不操作； 将e5（EF）加入，不操作； 将e6加入，将此边加入M，同时将e3从M中删除，将e4加入，将e0删除，将e1加入M。 得到如下的最大匹配： 删除边时： （由于删边不容易看出来，所以仅将出现可见变化时的情况列出。） 删除e0，不操作； 删除e1,将e1从最大匹配M中删除； 删除e4，将e2加入M，将e4删除。 得到的匹配如下： 通过以上两个实例（一个删除、一个插入），基本能模拟本文关于动态最大匹配的一般算法。 认识与看法 已有算法的问题所在 算法提到对于低荫度图，给每条边改成有向边处理，然后用贪心算法求解，但是算法并未给出如何判断一个图是否是低荫度图，而且即使有了一个标准，那么当一个图先是低荫度图，后来因为添加一条边之后，成了算法判断的非低荫度图，之后再添加边……如此一来，后面添加边的匹配操作，仍然会按低荫度图处理，这样一来时间复杂度就明显升高了。与此相反，当一个图先是普通图，当减去一条边后，成了低荫度图，再继续减去边……后来虽然形成了低荫度图，但是仍然按普通图来处理的。——我的意思是，当加边/减边（一个更新操作）在普通图与低荫度图之间轮换时，算法会因每次都错开最好情况而用的时间急剧升高。在实际应用中，这种情况应该会很常见，所以我认为这个问题还是相当严峻的。 算法一直在说向图G，但这是一个“抽象”的概念，文中并没有提及这个图是怎么存储的，也没有提及添加/删除边是怎么进行的。我觉得这虽然是不起眼的一部分，但是它实现的好坏，却是后来算法的高效进行与否的保证。（在第四次作业中我将详细分析不同存储结构存储的图的不同之处，以及哪种存储对此算法的实现最有益。） 已有算法可改进之处 算法中提到对点的度按降序排列，但如果两个点的度完全一样，或者所有点的度完全一样时，这样的处理难免有些草率，和普通匹配算法没有这一处理操作的算法过程相似，甚至多了偶尔的不必要交换（当度相同时的交换），于是我想到，能不能通过增加一个标志位来改进交换同时由于考虑到一般情况下，顶点的度有大部分是相同的，所以可以考虑改进一下排序操作，找一个比较稳定的排序是比较好的。 算法用AVL树来存储匹配，这一点感觉是比较好的操作，但是当存储每个点的邻接点时，不仅又用AVL树来存储，而且需要用另外一个变量存储该顶点的度，而且每次插入/删除边（一个更新操作）都可能需要调整AVL树，于是，我想能不能用更好的适用于随机搜索（插入、删除）的数据结构，例如：散列表来存储邻接顶点呢？这样一来，搜索的时间由O(logN)减小到O(1)，空间基本不会增加，反而减少一个整型空间（每个顶点减少一个，共N个），插入/删除边的时间大约也是O(1)，这样一来就比以前的算法要改进了一些（具体实现，见作业四）。 算法中提到用一个数据结构F(v)来存储顶点v的邻接顶点中未匹配的顶点，及其信息。然后算法提到一个长度为n（n表示所有顶点数量）的数组以及一个长度√n的计数数组。这种处理，在原则上是没有什么错误的，但是长度为n或者√n的数组没法实现每次插入顶点时就没法用了，为了实现完全动态匹配，我们需要用一个更好的数据结构来完成这一操作（当然对于本算法，这一改进并没有什么作用，但是想到可以为算法进行拓展，所以这个改进是必要的），我想到的数据结构是动态表——一种最省空间，且扩充/缩减时间O(1)（由摊还分析可证）的数据结构。 当数据量较大，短时间有较多条边需要插入/删除时，（通过插入操作来说明）每次操作，都是先将边加入存储边的数据结构，然后再依次更新其他相邻节点的邻接信息，以及边的信息。最后再分情况（动态规划）依次判断以及做出调整，简单来讲，整个判断过程分为三个部分，而且这三个部分是相互独立的，所以假如有N次插入，那么就有3N步，正常情况（该算法原来描述那样）。在一次插入边的操作结束后，存储边的数据结构便空闲下来，而第二次边的插入还没有开始。中间这部分时间浪费严重（当大数据来临时）。 已有算法不适用之处 算法一开始是通过一个空的数据结构开始插入边，来建立匹配，假如已有一个大数据的图（数据在外存，一般来说数据量过大，没法一次性装入内存）或者，由于数据量过大，没法普通存储（或者为了省空间、减小出错率）而用压缩图来存储，如果仍然用现有的算法来做，是极其困难的。也许可以实现，但是也困难重重，我仅将其归为不适用的一类。 改进意见 针对第一处问题。为了在每一步都使算法做到最优，那么在低荫度图与普通图的转换接口处，就应该更加重视，为了解决这个问题，我觉得，可以在每增加/删除一条边（一个更新操作）时增加一次判断，即：max[|E(U)|/(|U|-1)]&gt;C时，就进行普通图的操作，否则进行低荫度图的操作，其中C为预设的荫度的分界线。同时，首先对普通图的操作，或者对低荫度图的操作，当第一次出现两种图混合时，再初始化另一种图的存储结构，这样一来如果一直是基于两者中一种图的更新操作，就不需要那么大的空间开销。 在原算法，没有这一判断时，相对现在的改进，在每一次更新操作的时间上先是少一步，但当更新操作在多次往往复复地在两种图之间转换时，虽然改进多了一次判断，但是避免了两种图用同一种算法实现的时间消耗，算法改进的正确性及合理性得证。 针对第二处问题。我觉得这里的问题是作者的一个疏忽，当然在这个算法中，选用哪种数据结构来存储图，确实不是那么好选择的。选用邻接矩阵时，虽然边的信息清晰明了，但是，当数据量增大时，空间开销也是挺大的。若选用邻接表，减少了空间开销，但是，当每次统计某个节点的邻接顶点时，显得有些麻烦，邻接多重表，十字链表等弊端就更多与优点了。于是，在此改进中，我仅仅提出“邻接矩阵”与“邻接表”这两种存储图的数据结构来存储这个算法有关的图，这样，相对来说，比其他数据结构要简单，以及开销较小（时间/空间上）。 这两种图的存储结构，都可以实现边的插入/删除在O(1)时间内，并且相对其他存储结构还比较好实现，于是正确性得证。 针对第一处不足。我觉得可以增加一个标志位（整型）来实现对同一个度的不同节点做一下区分，第一次度为某个值的顶点标记为1，以后如果再有和这个点度相同的标记为2，……以此类推，每次为了保证度越高的节点越先匹配，不仅要判断度的大小，同时当度相等时，还要判断标志位，标志位越小（越大也行）就越优先保持匹配。 这一改进，使该算法对多顶点度相等的图，效果明显，当然当顶点度基本都不相同时，这一改进显得一无是处，反而增加空间开销。但就对程序改进角度讲，这样做着实可以在某些情况下，增加算法正确性，减少算法时间复杂性，我觉得这可以作为改进合理性的证明。 针对第二处不足。我觉得可以用散列表来存储每个顶点的邻接点信息，这样一来，可以减少一个整型变量空间，同时使搜索某个点是否与另一个点邻接能够在O(1)时间内完成（这也是散列表的最大的用处）。当然，散列表的构造也有很多方式，这里可以假设之前每个顶点都有一个ID或者有一个单独的可区分的标识。当以顺序ID来标记每个顶点时，可以用直接寻址法；当以单独的可区分标识来标记每个顶点时，可以用数据分析法来确定散列函数。 该改进的正确性，可以通过散列表在搜索上的正确性来证明，同时在空间复杂性上可能比以前算法要多（当然也可能相同），但在搜索时间上，对原有算法改进是十分显著的。由此，改进的合理性由此得证。 针对第三处不足。这一点属于“个人爱好”，为什么这么说呢？因为这一改进对原有算法不会产生一丁点的影响，但是却为程序可拓展性做了一点贡献。用动态表代替原有长度固定的数组，当顶点个数增多时，可以避免每次不够用又重新手动申请空间的弊端。可以说，动态表这一数据结构完美适应了顶点可变的情况，当边减少时，那些独立的顶点，可以通过某种方式，将其删去，以减少空间复杂性，同时，顶点减少，搜索更快；当边增多时，如果某些顶点原来没有记录，再在动态表中将其加入，丝毫不用担心空间分配麻烦问题。 动态表实现简单，效率高，事实上它和普通数组相比基本没有效率损失。我觉得即使是原算法思想（即使没边，也有顶点）也可以用动态表代替数组。 针对第四处不足。当大数据来临时，我将每次的匹配过程看成三部分，这让我想起了《计算机组成原理》中关于指令流水线的介绍，我发现该算法中三部分之间互相无关联，于是，我就想能不能仿照指令流水线的方式，来改进已有算法的三段匹配过程呢？也就是说，当第一条边插入时，我顺序开始执行那三段操作，当执行完第二段时，第二次插入已经可以开始执行了……依次类推，当大量数据进行同一个操作（插入/删除边）时，就可以成倍地减少时间复杂性（将三段融合成一段）。 这一改进符合并行性要求，而且可以证明，原来程序的三段互不影响，那么这个改进就显得在大数据上大有用武之处。 针对第一处不适。由于该算法是每次（动态）加入边，而现实是需要先初始化一个图，而且还可能是大量的数据的图，所以该算法不适用之处就显现出来了。虽然如果将已经存在的大数据图里的边一个个挑出来再加入，可以完成此操作，但是考虑时间将会是特别大的。于是想到，能不能给该算法在加一点能够对静态图匹配的内容，以便其能够在大数据上发挥作用。 如今，数据已进入海量时代，应对大数据冲击，已经成为考验所有算法好坏的一个标准，于是对此算法往大数据上适应，是十分有必要的。","categories":[{"name":"算法设计","slug":"算法设计","permalink":"http://meng.uno/categories/算法设计/"},{"name":"最大匹配","slug":"算法设计/最大匹配","permalink":"http://meng.uno/categories/算法设计/最大匹配/"}],"tags":[{"name":"算法设计","slug":"算法设计","permalink":"http://meng.uno/tags/算法设计/"},{"name":"最大匹配","slug":"最大匹配","permalink":"http://meng.uno/tags/最大匹配/"},{"name":"确定性算法","slug":"确定性算法","permalink":"http://meng.uno/tags/确定性算法/"},{"name":"动态","slug":"动态","permalink":"http://meng.uno/tags/动态/"}]},{"title":"汇编指令大全","slug":"asm-func","date":"2016-07-16T12:18:01.000Z","updated":"2018-02-18T13:25:50.290Z","comments":true,"path":"posts/711069a/","link":"","permalink":"http://meng.uno/posts/711069a/","excerpt":"","text":"数据传输指令 通用数据传送指令 MOV 传送字或字节. MOVSX 先符号扩展,再传送. MOVZX 先零扩展,再传送. PUSH 把字压入堆栈. POP 把字弹出堆栈. PUSHA 把AX,CX,DX,BX,SP,BP,SI,DI依次压入堆栈. POPA 把DI,SI,BP,SP,BX,DX,CX,AX依次弹出堆栈. PUSHAD 把EAX,ECX,EDX,EBX,ESP,EBP,ESI,EDI依次压入堆栈. POPAD 把EDI,ESI,EBP,ESP,EBX,EDX,ECX,EAX依次弹出堆栈. BSWAP 交换32位寄存器里字节的顺序 XCHG 交换字或字节.( 至少有一个操作数为寄存器,段寄存器不可作为操作数) CMPXCHG 比较并交换操作数.( 第二个操作数必须为累加器AL/AX/EAX ) XADD 先交换再累加.( 结果在第一个操作数里 ) XLAT 字节查表转换. BX 指向一张 256 字节的表的起点, AL 为表的索引值 (0-255,即0-FFH); 返回 AL 为查表结果. ( [BX+AL]-&gt;AL ) 输入输出端口传送指令 IN I/O端口输入. ( 语法: IN 累加器, {端口号│DX} ) OUT I/O端口输出. ( 语法: OUT {端口号│DX},累加器 ) 输入输出端口由立即方式指定时, 其范围是 0-255; 由寄存器 DX 指定时,其范围是 0-65535. 目的地址传送指令. LEA 装入有效地址. 例: LEA DX,string ;把偏移地址存到DX. LDS 传送目标指针,把指针内容装入DS. 例: LDS SI,string ;把段地址:偏移地址存到DS:SI. LES 传送目标指针,把指针内容装入ES. 例: LES DI,string ;把段地址:偏移地址存到ES:DI. LFS 传送目标指针,把指针内容装入FS. 例: LFS DI,string ;把段地址:偏移地址存到FS:DI. LGS 传送目标指针,把指针内容装入GS. 例: LGS DI,string ;把段地址:偏移地址存到GS:DI. LSS 传送目标指针,把指针内容装入SS. 例: LSS DI,string ;把段地址:偏移地址存到SS:DI. 标志传送指令. LAHF 标志寄存器传送,把标志装入AH. SAHF 标志寄存器传送,把AH内容装入标志寄存器. PUSHF 标志入栈. POPF 标志出栈. PUSHD 32位标志入栈. POPD 32位标志出栈. 算术运算指令 ADD 加法. ADC 带进位加法. INC 加 1. AAA 加法的ASCII码调整. DAA 加法的十进制调整. SUB 减法. SBB 带借位减法. DEC 减 1. NEC 求反(以 0 减之). CMP 比较.(两操作数作减法,仅修改标志位,不回送结果). AAS 减法的ASCII码调整. DAS 减法的十进制调整. MUL 无符号乘法. IMUL 整数乘法. 以上两条,结果回送AH和AL(字节运算),或DX和AX(字运算) AAM 乘法的ASCII码调整. DIV 无符号除法. IDIV 整数除法. 以上两条,结果回送: 商回送AL,余数回送AH, (字节运算); 或商回送AX,余数回送DX, (字运算). AAD 除法的ASCII码调整. CBW 字节转换为字. (把AL中字节的符号扩展到AH中去) CWD 字转换为双字. (把AX中的字的符号扩展到DX中去) CWDE 字转换为双字. (把AX中的字符号扩展到EAX中去) CDQ 双字扩展. (把EAX中的字的符号扩展到EDX中去) 逻辑运算指令 AND 与运算. or 或运算. XOR 异或运算. NOT 取反. TEST 测试.(两操作数作与运算,仅修改标志位,不回送结果). SHL 逻辑左移. SAL 算术左移.(=SHL) SHR 逻辑右移. SAR 算术右移.(=SHR) ROL 循环左移. ROR 循环右移. RCL 通过进位的循环左移. RCR 通过进位的循环右移. 以上八种移位指令,其移位次数可达255次. 移位一次时, 可直接用操作码. 如 SHL AX,1.移位&gt;1次时, 则由寄存器CL给出移位次数.如 MOV CL,04 SHL AX,CL 串指令 DS:SI 源串段寄存器 :源串变址. ES:DI 目标串段寄存器:目标串变址. CX 重复次数计数器. AL/AX 扫描值. D标志 0表示重复操作中SI和DI应自动增量; 1表示应自动减量. Z标志 用来控制扫描或比较操作的结束. MOVS 串传送. ( MOVSB 传送字符. MOVSW 传送字. MOVSD 传送双字. ) CMPS 串比较. ( CMPSB 比较字符. CMPSW 比较字. ) SCAS 串扫描. 把AL或AX的内容与目标串作比较,比较结果反映在标志位. LODS 装入串.把源串中的元素(字或字节)逐一装入AL或AX中. ( LODSB 传送字符. LODSW 传送字. LODSD 传送双字. ) STOS 保存串.是LODS的逆过程. REP 当CX/ECX&lt;&gt;0时重复. REPE/REPZ 当ZF=1或比较结果相等,且CX/ECX&lt;&gt;0时重复. REPNE/REPNZ 当ZF=0或比较结果不相等,且CX/ECX&lt;&gt;0时重复. REPC 当CF=1且CX/ECX&lt;&gt;0时重复. REPNC 当CF=0且CX/ECX&lt;&gt;0时重复. 程序转移指令 无条件转移指令 (长转移) JMP 无条件转移指令 CALL 过程调用 RET/RETF过程返回. 条件转移指令 (短转移,-128到+127的距离内) 当且仅当(SF XOR OF)=1时,OP1&lt;OP2 JA/JNBE 不小于或不等于时转移. JAE/JNB 大于或等于转移. JB/JNAE 小于转移. JBE/JNA 小于或等于转移. 以上四条,测试无符号整数运算的结果(标志C和Z). JG/JNLE 大于转移. JGE/JNL 大于或等于转移. JL/JNGE 小于转移. JLE/JNG 小于或等于转移. 以上四条,测试带符号整数运算的结果(标志S,O和Z). JE/JZ 等于转移. JNE/JNZ 不等于时转移. JC 有进位时转移. JNC 无进位时转移. JNO 不溢出时转移. JNP/JPO 奇偶性为奇数时转移. JNS 符号位为 &quot;0&quot; 时转移. JO 溢出转移. JP/JPE 奇偶性为偶数时转移. JS 符号位为 &quot;1&quot; 时转移. 循环控制指令(短转移) LOOP CX不为零时循环. LOOPE/LOOPZ CX不为零且标志Z=1时循环. LOOPNE/LOOPNZ CX不为零且标志Z=0时循环. JCXZ CX为零时转移. JECXZ ECX为零时转移. 中断指令 INT 中断指令 INTO 溢出中断 IRET 中断返回 处理器控制指令 HLT 处理器暂停, 直到出现中断或复位信号才继续. WAIT 当芯片引线TEST为高电平时使CPU进入等待状态. ESC 转换到外处理器. LOCK 封锁总线. NOP 空操作. STC 置进位标志位. CLC 清进位标志位. CMC 进位标志取反. STD 置方向标志位. CLD 清方向标志位. STI 置中断允许位. CLI 清中断允许位. 伪指令 DW 定义字(2字节). PROC 定义过程. ENDP 过程结束. SEGMENT 定义段. ASSUME 建立段寄存器寻址. ENDS 段结束. END 程序结束. 处理机控制指令 标志处理指令 CLC（进位位置0指令） CMC（进位位求反指令） STC（进位位置为1指令） CLD（方向标志置1指令） STD（方向标志位置1指令） CLI（中断标志置0指令） STI（中断标志置1指令） NOP（无操作） HLT（停机） WAIT（等待） ESC（换码） LOCK（封锁）","categories":[{"name":"Language","slug":"Language","permalink":"http://meng.uno/categories/Language/"},{"name":"ASM","slug":"Language/ASM","permalink":"http://meng.uno/categories/Language/ASM/"}],"tags":[{"name":"ASM","slug":"ASM","permalink":"http://meng.uno/tags/ASM/"},{"name":"汇编","slug":"汇编","permalink":"http://meng.uno/tags/汇编/"}]},{"title":"汇编语言代码规范","slug":"asm-principle","date":"2016-07-16T09:31:04.000Z","updated":"2018-02-18T10:38:20.009Z","comments":true,"path":"posts/b0b4f7ec/","link":"","permalink":"http://meng.uno/posts/b0b4f7ec/","excerpt":"","text":"随着程序功能的增加和版本的提高，程序越来越复杂，源文件也越来越多，风格规范的源程序会对软件的升级、修改和维护带来极大的方便，要想开发一个成熟的软件产品，必须在编写源程序的时候就有条不紊，细致严谨。 在编程中，在程序排版、注释、命名和可读性等问题上都有一定的规范，虽然编写可读性良好的代码并不是必然的要求（世界上还有难懂代码比赛，看谁的代码最不好读懂！），但好的代码风格实际上是为自己将来维护和使用这些代码节省时间。 变量和函数的命名 匈牙利表示法 匈牙利表示法主要用在变量和子程序的命名，这是现在大部分程序员都在使用的命名约定。“匈牙利表示法”这个奇怪的名字是为了纪念匈牙利籍的Microsoft程序员Charles Simonyi，他首先使用了这种命名方法。 匈牙利表示法用连在一起的几个部分来命名一个变量，格式是类型前缀加上变量说明，类型用小写字母表示，如用h表示句柄，用dw表示double word，用sz表示以0结尾的字符串等，说明则用首字母大写的几个英文单词组成，如TimeCounter，NextPoint等，可以令人一眼看出变量的含义来，在汇编语言中常用的类型前缀有： 123456789 b 表示bytew 表示worddw 表示dwordh 表示句柄lp 表示指针sz 表示以0结尾的字符串lpsz 表示指向0结尾的字符串的指针f 表示浮点数st 表示一个数据结构 这样一来，变量的意思就很好理解： 12345 hWinMain 主窗口的句柄dwTimeCount 时间计数器，以双字定义szWelcome 欢迎信息字符串，以0结尾lpBuffer 指向缓冲区的指针stWndClass WNDCLASS结构 由于匈牙利表示法既描述了变量的类型，又描述了变量的作用，所以能帮助程序员及早发现变量的使用错误，如把一个数值当指针来使用引发的内存页错误等。 对于函数名，由于不会返回多种类型的数值，所以命名时一般不再用类型开头，但名称还是用表示用途的单词组成，每个单词的首字母大写。Windows API是这种命名方式的绝好例子，当人们看到ShowWindow，GetWindowText，DeleteFile和GetCommandLine之类的API函数名称时，恐怕不用查手册，就能知道它们是做什么用的。比起int 21h/09h和int 13h/02h之类的中断调用，好处是不必多讲的。 对匈牙利表示法的补充 使用匈牙利表示法已经基本上解决了命名的可读性问题，但相对于其他高级语言，汇编语言有语法上的特殊性，考虑下面这些汇编语言特有的问题： 对局部变量的地址引用要用lea指令或用addr伪操作，全局变量要用offset；对局部变量的使用要特别注意初始化问题。如何在定义中区分全局变量、局部变量和参数？ 汇编的源代码占用的行数比较多，代码行数很容易膨胀，程序规模大了如何分清一个函数是系统的API还是本程序内部的子程序？ 实际上上面的这些问题都可以归纳为区分作用域的问题。为了分清变量的作用域，命名中对全局变量、局部变量和参数应该有所区别，所以我们需要对匈牙利表示法做一些补充，以适应Win32汇编的特殊情况，下面的补充方法是笔者提出的，读者可以参考使用： 全局变量的定义使用标准的匈牙利表示法，在参数的前面加下划线，在局部变量的前面加@符号，这样引用的时候就能随时注意到变量的作用域。 在内部子程序的名称前面加下划线，以便和系统API区别。 如下面是一个求复数模的子程序，子程序名前面加下划线表示这是本程序内部模块，两个参数——复数的实部和虚部用_dwX和_dwY表示，中间用到的局部变量@dwResult则用@号开头： 123456789101112131415 _Calc proc _dwX,_dwY local @dwResult finit fild _dwX fld st(0) fmul ;i * i fild _dwY fld st(0) fmul ;j * j fadd ;i * i + j * j fsqrt ;sqrt(i * i + j * j) fistp @dwResult ;put result mov eax,@dwResult ret_Calc endp 代码的书写格式 排版方式 程序的排版风格应该遵循以下规则。 首先是大小写的问题，汇编程序中对于指令和寄存器的书写是不分大小写的，但小写代码比大写代码便于阅读，所以程序中的指令和寄存器等要采用小写字母，而用equ伪操作符定义的常量则使用大写，变量和标号使用匈牙利表示法，大小写混合。 其次是使用Tab的问题。汇编源程序中Tab的宽度一般设置为8个字符。在语法上，指令和操作数之间至少有一个空格就可以了，但指令的助记符长度是不等长的，用Tab隔开指令和操作数可以使格式对齐，便于阅读。如： 123 xor eax,eaxfistp dwNumberxchg eax,ebx 上述代码的写法就不如下面的写法整齐： 123 xor eax, eax fistp dwNumberxchg eax, ebx 还有就是缩进格式的问题。程序中的各部分采用不同的缩进，一般变量和标号的定义不缩进，指令用两个Tab缩进，遇到分支或循环伪指令再缩进一格，如： 12345678910111213 .datadwFlag dd ?.codestart: mov eax,dwFlag .if dwFlag == 1 call _Function1 .else call _Function2 .endif 合适的缩进格式可以明显地表现出程序的流程结构，也很容易发现嵌套错误，当缩进过多的时候，可以意识到嵌套过深，该改进程序结构了。","categories":[{"name":"Language","slug":"Language","permalink":"http://meng.uno/categories/Language/"},{"name":"ASM","slug":"Language/ASM","permalink":"http://meng.uno/categories/Language/ASM/"}],"tags":[{"name":"ASM","slug":"ASM","permalink":"http://meng.uno/tags/ASM/"},{"name":"汇编语言","slug":"汇编语言","permalink":"http://meng.uno/tags/汇编语言/"},{"name":"代码规范","slug":"代码规范","permalink":"http://meng.uno/tags/代码规范/"}]},{"title":"rIOMMU：Efficient IOMMU for I/O Devices that Employ Ring Buffers","slug":"rIOMMU","date":"2016-06-22T12:28:00.000Z","updated":"2018-02-18T13:26:12.307Z","comments":true,"path":"posts/51c782dd/","link":"","permalink":"http://meng.uno/posts/51c782dd/","excerpt":"","text":"文章内容理解 作者写作背景 在I/O设备开始与CPU异步直接与主存交换信息（DMA时代）开始时，DMA使用物理地址直接存取，这就给系统带来了很多诸如劣质甚至恶意设备影响，造成系统崩溃……等麻烦，在这种情况下，对I/O设备的存取统一管理的单元——输入输出存储管理单元（IOMMU）应运而生。随着设备带宽的提高，那些像网卡和PCIe SSD控制器等高带宽设备可以与系统通过一个环型缓冲器相互影响，于是一种带有环形的缓冲器能够分层、平滑地替换虚拟地址的rIOMMU成了研究的重点。这种rIOMMU能高达7.56倍地提高普通IOMMU的效率，是没有IOMMU的0.77—1.00倍。 文章结构 该文章从以下七个部分论述： 摘要：简述本次论文的主要内容； 介绍：向读者介绍什么是IOMMU以及什么是Riommu其他缩写的概念； 背景：在什么情况下，作者提出用rIOMMU改进原有IOMMU的： 首先讲OS的DMA保护； 接着讲IOMMU的设计与提升作用； 最后提出rIOMMU的概念。 安全代价：讲解OS与IO设备的关系与保护方式 设计：这是作者主要论述的部分，也是本文的核心，从以下三个方面论述： 数据结构 硬件实现 软件实现 评估：从7个模式分别测试该设计的可行性，又分为方法与结果两个部分论述 总结 下面直接进入文章的设计部分： 数据结构 作者从软件、硬件两种方式来组合实现rIOMMU,所以数据结构不得不是最先介绍的东西了。我将以代码与文字结合的方式介绍： 以上四个结构体所展示的数据结构，都是硬件软件公用的，他们都被rIOMMU用来转换虚拟地址，被操作系统调用。接下来定义一个只有硬件会使用的结构体： ## 硬件处理 首先，在与rRING相连的rIOTLB_entry的IOVA中寻找e，如果e不存在rIOMMU就搜索表，用上面定义的数据结构，找到rPTE，并插入rIOTLB一个匹配的entry，同时使表移动确保e.rpte是rPTE中给定的rIOVA。 其次，如果e已经初始化在rIOTLB被找到，rIOMMU匹配每一个IOVA和e，并且实时更新e。 然后，检查IOVA.offset如果出错，会造成rIOMMU启动I/O默认页（IOPF）,当然这并不是所希望的，未出错时，最终该offset会加到rPTE.phys_addr上形成虚拟地址的转换。 最后还有关于错误的一些处理，在此不再赘述。 软件处理 说完了硬件上的处理，接下来该软件上的操作了，说是软件其实就是设备的驱动程序、映射函数等底层的软件，这部分的处理和Linux中IOMMU的基准处理相似。 这一部分主要是处理映射的问题，具体就是将数据结构中定义的每个结构体的各个域之间建立联系。映射给每个设备一个ring ID，一个映射的物理地址，它包含两个部分： 在ring的尾部分配一个环入口rPTE，然后更新上面数据结构提到的tail/nmapped域； 当rPTE初始化后，首先确保其内容更新对rIOMMU是可见的，它的返回状态是入口的索引，而且这个ring ID是由IOVA所得到的。 这一部分也同样有错误处理，在此不再赘述。 可行性分析 可行性评估 在读了这一篇关于优化IOMMU的文章后，我在网上寻找了一下，相关的研究进展情况，发现早在很多年前像Intel、AMD等处理器生产商早就有关于IOMMU的应用，但是在像本文所讲的rIOMMU还没有得到应用过，也就是说文章现在所言皆是理想的情况。 在文章的后半部分，作者也从“方法”、“实验执行”、“基准”等方面做了很多测试，其中在“方法”模块采用：①strict，②strict+，③defer，④defer+，⑤riommu-，⑥riommu，⑦none其中模式，可以说是比较准确的了下图及下表展示所有测试结果： 通过结果可见，当运行“需求-响应”（RR）模式是，相对于普通IOMMU，提升不是多么的明显，但是在其他方面，结果还是挺理想的。 创新之处 作者在测试部分将模拟方法分成7个等级，基本上模拟了所有的正常可能情况，有力证明了本次实验的成功。 作者在进行设计之初，分析了现有的DMA与IOMMU，然后提出自己的设计，使我们对总体设计有一个整体认识，也使的作者的设计比较容易接受。 在设计上，作者不仅考虑到硬件，同时对软件也进行了设计，而且设计过程相当明细，用实际的代码来解释，使设计极具可行性。 设计存在的不足分析 我认为作者在设计时并未考虑这样设计所带来的结构复杂性，也未对实际的能耗做评估，也许可能会由于总线分配问题而没法嵌入系统。 作者虽然提到rIOMMU在对有错误的DMA设备的保护的作用，但是没有给出具体的保护方案。 我想到既然通过环形缓冲器能解决速度的问题，那么会不会带来其他的弊端，例如：某次传输没有传输完就被后一次的覆盖掉或者当环形缓冲器中有错误，没法处理时会不会发生DMA总是在那里占用总线而又没有实际的数据传输。 既然是环形缓冲器，那么当传输数据是暂时性的，而且又没能在有效的时间范围内进入环形缓冲器，那么是不是就有冲掉的风险。 针对不足的改进意见 在上一部分我浅显地提出了自己认为是不足的地方，在此仅仅做些自己认为合理的改进意见。不能保证我的观点是完全正确，但是这确实是我自己对相关问题的认识所得。 作者可以增加关于能耗的测试，作者提到这样的rIOMMU确实在某些方面比IOMM要有效得多，但是能耗是不是也如此呢？作者应该往这方面做些必要的测试（由于水平有限，所以只能借助作者之手完成这项测试）。 既然rIOMMU对设备有保护作用，那么其作用具体体现在哪呢？仅仅是在对错误数据的处理上，远远不足以满足现在设备的要求，例如，当某设备出错，重复发送某信息时，作为向主存传输信息的接口，应该如何处理呢？我认为可以从软件上进行相关判断，我觉得这将是这类IOMMU值得改进的地方。 我觉得环缓冲器还应该增加错误信息清除能力，当出现出错信息时，能有效地将其清除并且不影响其他设备的正常传输。 每个环形缓冲器都会有数量“size”的限制，像用尽这种现象应该是尽量避免的。也许可以通过取一个大大的“buffer”值来基本解决这一问题，但是将造成空间消耗严重，我觉得更好的解决办法是，修改设计，使设计能够容纳多个环缓冲器，当然不是每个环每次都会使用，当第一个环占满并且还有数据需要缓冲时，才会调用第二个环……在这种设计上，我觉得将会增加很多判断，设计空间的动态分配等问题。 附录 在此将本文所有用到的英文缩写做一下梳理： IOMMU: Input/Output Memory Management Unit 输入输出存储管理单元 rIOMMU: IOMMU Employed Ring Buffers 带环缓冲器的IOMMU IOTLB: I/O Translation Lookaside Buffer 用于IOMMU的块表 IOVA: I/O Visual Address IO虚拟地址","categories":[{"name":"计算机组成","slug":"计算机组成","permalink":"http://meng.uno/categories/计算机组成/"},{"name":"IOMMU","slug":"计算机组成/IOMMU","permalink":"http://meng.uno/categories/计算机组成/IOMMU/"}],"tags":[{"name":"IOMMU","slug":"IOMMU","permalink":"http://meng.uno/tags/IOMMU/"},{"name":"Buffer","slug":"Buffer","permalink":"http://meng.uno/tags/Buffer/"}]},{"title":"Matlab基本函数","slug":"matlab-func","date":"2016-06-07T11:02:10.000Z","updated":"2018-02-18T13:25:50.294Z","comments":true,"path":"posts/dbf56532/","link":"","permalink":"http://meng.uno/posts/dbf56532/","excerpt":"","text":"求矩阵行数/列数/维数的函数 ndims(A) 返回A的维数 size(A) 返回A各个维的最大元素个数 length(A) 返回max(size(A)) [m,n]=size(A) 如果A是二维数组，返回行数和列数 nnz(A) 返回A中非0元素的个数 取整函数 fix(x) 截尾取整 floor(x) 不超过x 的最大整数(高斯取整) ceil(x) 大于x 的最小整数 生成随机数函数 rand(n):生成0到1之间的n阶随机数方阵 rand(m,n):生成0到1之间的m×n的随机数矩阵 其他随机数生成函数 betarnd 贝塔分布的随机数生成器 binornd 二项分布的随机数生成器 chi2rnd 卡方分布的随机数生成器 exprnd 指数分布的随机数生成器 frndf分布的随机数生成器 gamrnd 伽玛分布的随机数生成器 geornd 几何分布的随机数生成器 hygernd 超几何分布的随机数生成器 lognrnd 对数正态分布的随机数生成器 nbinrnd 负二项分布的随机数生成器 ncfrnd 非中心f分布的随机数生成器 nctrnd 非中心t分布的随机数生成器 ncx2rnd 非中心卡方分布的随机数生成器 normrnd 正态（高斯）分布的随机数生成器 poissrnd 泊松分布的随机数生成器 raylrnd 瑞利分布的随机数生成器 trnd 学生氏t分布的随机数生成器 unidrnd 离散均匀分布的随机数生成器 unifrnd 连续均匀分布的随机数生成器 weibrnd 威布尔分布的随机数生成器 基本数学函数 abs(x)：纯量的绝对值或向量的长度 angle(z)：复数z的相角(Phase angle) sqrt(x)：开平方 real(z)：复数z的实部 imag(z)：复数z的虚部 conj(z)：复数z的共轭复数 round(x)：四舍五入至最近整数 fix(x)：无论正负，舍去小数至最近整数 floor(x)：地板函数，即舍去正小数至最近整数 ceil(x)：天花板函数，即加入正小数至最近整数 rat(x)：将实数x化为分数表示 rats(x)：将实数x化为多项分数展开 sign(x)：符号函数 当x&lt;0时，sign(x)=-1 当x=0时，sign(x)=0 当x&gt;0时，sign(x)=1 rem(x,y)：求x除以y的馀数 gcd(x,y)：整数x和y的最大公因数 lcm(x,y)：整数x和y的最小公倍数 exp(x)：自然指数 pow2(x)：2的指数 log(x)：以e为底的对数，即自然对数或 log2(x)：以2为底的对数 log10(x)：以10为底的对数 常用的三角函数 sin(x)：正弦函数 cos(x)：馀弦函数 tan(x)：正切函数 asin(x)：反正弦函数 acos(x)：反馀弦函数 atan(x)：反正切函数 atan2(x,y)：四象限的反正切函数 sinh(x)：超越正弦函数 cosh(x)：超越馀弦函数 tanh(x)：超越正切函数 asinh(x)：反超越正弦函数 acosh(x)：反超越馀弦函数 atanh(x)：反超越正切函数 向量的常用函数 min(x): 向量x的元素的最小值 max(x): 向量x的元素的最大值 mean(x): 向量x的元素的平均值 median(x): 向量x的元素的中位数 std(x): 向量x的元素的标准差 diff(x): 向量x的相邻元素的差 sort(x): 对向量x的元素进行排序（Sorting） length(x): 向量x的元素个数 norm(x): 向量x的欧氏（Euclidean）长度 sum(x): 向量x的元素总和 prod(x): 向量x的元素总乘积 cumsum(x): 向量x的累计元素总和 cumprod(x): 向量x的累计元素总乘积 dot(x, y): 向量x和y的内积 cross(x, y): 向量x和y的外积 永久常数 i或j：基本虚数单位（即） eps：系统的浮点（Floating-point）精确度 inf：无限大， 例如1/0 nan或NaN：非数值（Not a number），例如0/0 pi：圆周率 realmax：系统所能表示的最大数值 realmin：系统所能表示的最小数值 nargin: 函数的输入引数个数 nargout: 函数的输出引数个数 基本绘图函数 plot: x轴和y轴均为线性刻度（Linear scale） loglog: x轴和y轴均为对数刻度（Logarithmic scale） semilogx: x轴为对数刻度，y轴为线性刻度 semilogy: x轴为线性刻度，y轴为对数刻度 plot绘图函数的参数 字元 颜色 字元 图线型态 y 黄色 . 点 k 黑色 o 圆 w 白色 x x b 蓝色 + + g 绿色 * * r 红色 - 实线 c 亮青色 : 点线 m 锰紫色 -. 点虚线 -- 虚线 注解 xlabel('Input Value'); % x轴注解 ylabel('Function Value'); % y轴注解 title('Two Trigonometric Functions'); % 图形标题 legend('y = sin(x)','y = cos(x)'); % 图形注解 grid on; % 显示格线 二维绘图函数 bar 长条图 errorbar 图形加上误差范围 fplot 较精确的函数图形 polar 极座标图 hist 累计图 rose 极座标累计图 stairs 阶梯图 stem 针状图 fill 实心图 feather 羽毛图 compass 罗盘图 quiver 向量场图","categories":[{"name":"Language","slug":"Language","permalink":"http://meng.uno/categories/Language/"},{"name":"MATLAB","slug":"Language/MATLAB","permalink":"http://meng.uno/categories/Language/MATLAB/"}],"tags":[{"name":"MATLAB","slug":"MATLAB","permalink":"http://meng.uno/tags/MATLAB/"}]},{"title":"数学建模常用的十大算法","slug":"cumum-func","date":"2015-02-03T12:03:33.000Z","updated":"2018-02-18T13:25:50.292Z","comments":true,"path":"posts/dd0e4c80/","link":"","permalink":"http://meng.uno/posts/dd0e4c80/","excerpt":"","text":"概述 蒙特卡罗算法 该算法又称随机性模拟算法，是通过计算机仿真来解决问题的算法，同时可以通过模拟来检验自己模型的正确性，几乎是比赛时必用的方法。 数据拟合、参数估计、插值等数据处理算法 比赛中通常会遇到大量的数据需要处理，而处理数据的关键就在于这些算法，通常使用MATLAB 作为工具。 线性规划、整数规划、多元规划、二次规划等规划类算法 建模竞赛大多数问题属于最优化问题，很多时候这些问题可以用数学规划算法来描述，通常使用Lindo、Lingo 软件求解。 图论算法 这类算法可以分为很多种，包括最短路、网络流、二分图等算法，涉及到图论的问题可以用这些方法解决，需要认真准备。 动态规划、回溯搜索、分治算法、分支定界等计算机算法 这些算法是算法设计中比较常用的方法，竞赛中很多场合会用到。 最优化理论的三大非经典算法：模拟退火算法、神经网络算法、遗传算法 这些问题是用来解决一些较困难的最优化问题的，对于有些问题非常有帮助，但是算法的实现比较困难，需慎重使用。 网格算法和穷举法 两者都是暴力搜索最优点的算法，在很多竞赛题中有应用，当重点讨论模型本身而轻视算法的时候，可以使用这种暴力方案，最好使用一些高级语言作为编程工具。 一些连续数据离散化方法 很多问题都是实际来的，数据可以是连续的，而计算机只能处理离散的数据，因此将其离散化后进行差分代替微分、求和代替积分等思想是非常重要的。 数值分析算法 如果在比赛中采用高级语言进行编程的话，那些数值分析中常用的算法比如方程组求解、矩阵运算、函数积分等算法就需要额外编写库函数进行调用。 图象处理算法 赛题中有一类问题与图形有关，即使问题与图形无关，论文中也会需要图片来说明问题，这些图形如何展示以及如何处理就是需要解决的问题，通常使用MATLAB 进行处理。 以下将结合历年的竞赛题，对这十类算法进行详细地说明。 十类算法的详细说明 蒙特卡罗算法 大多数建模赛题中都离不开计算机仿真，随机性模拟是非常常见的算法之一。举个例子就是97 年的A 题，每个零件都有自己的标定值，也都有自己的容差等级，而求解最优的组合方案将要面对着的是一个极其复杂的公式和108 种容差选取方案，根本不可能去求解析解，那如何去找到最优的方案呢？随机性模拟搜索最优方案就是其中的一种方法，在每个零件可行的区间中按照正态分布随机的选取一个标定值和选取一个容差值作为一种方案，然后通过蒙特卡罗算法仿真出大量的方案，从中选取一个最佳的。另一个例子就是去年的彩票第二问，要求设计一种更好的方案，首先方案的优劣取决于很多复杂的因素，同样不可能刻画出一个模型进行求解，只能靠随机仿真模拟。 数据拟合、参数估计、插值等算法 数据拟合在很多赛题中有应用，与图形处理有关的问题很多与拟合有关系，一个例子就是98 年美国赛A 题，生物组织切片的三维插值处理，94 年A 题逢山开路，山体海拔高度的插值计算，还有吵的沸沸扬扬可能会考的“非典”问题也要用到数据拟合算法，观察数据的走向进行处理。此类问题在MATLAB中有很多现成的函数可以调用，熟悉MATLAB，这些方法都能游刃有余的用好。 规划类问题算法 竞赛中很多问题都和数学规划有关，可以说不少的模型都可以归结为一组不等式作为约束条件、几个函数表达式作为目标函数的问题，遇到这类问题，求解就是关键了，比如98年B 题，用很多不等式完全可以把问题刻画清楚，因此列举出规划后用Lindo、Lingo 等软件来进行解决比较方便，所以还需要熟悉这两个软件。 图论问题 98年B题、00年B题、95年锁具装箱等问题体现了图论问题的重要性，这类问题算法有很多，包括：Dijkstra、Floyd、Prim、Bellman-Ford，最大流，二分匹配等问题。每一个算法都应该实现一遍，否则到比赛时再写就晚了。 计算机算法设计中的问题 计算机算法设计包括很多内容：动态规划、回溯搜索、分治算法、分支定界。比如92 年B 题用分枝定界法，97 年B 题是典型的动态规划问题，此外98 年B 题体现了分治算法。这方面问题和ACM 程序设计竞赛中的问题类似，推荐看一下《计算机算法设计与分析》（电子工业出版社）等与计算机算法有关的书。 最优化理论的三大非经典算法 这十几年来最优化理论有了飞速发展，模拟退火法、神经网络、遗传算法这三类算法发展很快。近几年的赛题越来越复杂，很多问题没有什么很好的模型可以借鉴，于是这三类算法很多时候可以派上用场，比如：97 年A 题的模拟退火算法，00 年B 题的神经网络分类算法，象01 年B 题这种难题也可以使用神经网络，还有美国竞赛89 年A 题也和BP 算法有关系，当时是86 年刚提出BP 算法，89 年就考了，说明赛题可能是当今前沿科技的抽象体现。03 年B 题伽马刀问题也是目前研究的课题，目前算法最佳的是遗传算法。 网格算法和穷举算法 网格算法和穷举法一样，只是网格法是连续问题的穷举。比如要求在N 个变量情况下的最优化问题，那么对这些变量可取的空间进行采点，比如在[a; b] 区间内取M +1 个点，就是a; a+(b-a)/M; a+2 (b-a)/M; …… ; b 那么这样循环就需要进行(M + 1)N 次运算，所以计算量很大。比如97 年A 题、99 年B 题都可以用网格法搜索，这种方法最好在运算速度较快的计算机中进行，还有要用高级语言来做，最好不要用MATLAB 做网格，否则会算很久的。穷举法大家都熟悉，就不说了。 一些连续数据离散化的方法 大部分物理问题的编程解决，都和这种方法有一定的联系。物理问题是反映我们生活在一个连续的世界中，计算机只能处理离散的量，所以需要对连续量进行离散处理。这种方法应用很广，而且和上面的很多算法有关。事实上，网格算法、蒙特卡罗算法、模拟退火都用了这个思想。 数值分析算法 这类算法是针对高级语言而专门设的，如果你用的是MATLAB、Mathematica，大可不必准备，因为象数值分析中有很多函数一般的数学软件是具备的。 图象处理算法 01 年A 题中需要你会读BMP 图象、美国赛98 年A 题需要你知道三维插值计算，03 年B 题要求更高，不但需要编程计算还要进行处理，而数模论文中也有很多图片需要展示，因此图象处理就是关键。做好这类问题，重要的是把MATLAB 学好，特别是图象处理的部分。","categories":[{"name":"数学建模","slug":"数学建模","permalink":"http://meng.uno/categories/数学建模/"}],"tags":[{"name":"数学建模","slug":"数学建模","permalink":"http://meng.uno/tags/数学建模/"},{"name":"算法","slug":"算法","permalink":"http://meng.uno/tags/算法/"}]},{"title":"破解时常用的汇编命令","slug":"asm-func-black","date":"2014-11-03T12:10:37.000Z","updated":"2018-02-18T13:25:50.289Z","comments":true,"path":"posts/36aa5187/","link":"","permalink":"http://meng.uno/posts/36aa5187/","excerpt":"","text":"概述 基本上多数破解的思路是一样的，就是将本来判断为true的时候干的事情改为逻辑值为false就做，因此常常需要替换一些汇编命令： 12345678910111213141516 cmp a,b 比较a与bmov a,b 把b的值送给aret 返回主程序nop 无作用,英文“no operation”的简写，意思是“do nothing”(机器码90)call 调用子程序je 或jz 若相等则跳(机器码74 或0F84)jne或jnz 若不相等则跳(机器码75或0F85)jmp 无条件跳(机器码EB)jb 若小于则跳ja 若大于则跳jg 若大于则跳jge 若大于等于则跳jl 若小于则跳jle 若小于等于则跳pop 出栈push 压栈 常见修改(机器码) 12 74=&gt;75 74=&gt;90 74=&gt;EB75=&gt;74 75=&gt;90 75=&gt;EB jnz -&gt; nop 1 75-&gt;90(相应的机器码修改) jnz -&gt; jmp 1 75 -&gt; EB(相应的机器码修改) jnz -&gt; jz 12 75-&gt;74 (正常) 0F 85 -&gt; 0F 84(特殊情况下,有时,相应的机器码修改) 两种不同情况的不同修改方法 修改为jmp je(jne,jz,jnz) =&gt;jmp相应的机器码EB （出错信息向上找到的第一个跳转）jmp的作用是绝对跳，无条件跳，从而跳过下面的出错信息。 出错信息，例如：注册码不对，sorry,未注册版不能...，&quot;Function Not Avaible in Demo&quot; 或 &quot;Command Not Avaible&quot; 或 &quot;Can't save in Shareware/Demo&quot;等 （我们希望把它跳过，不让它出现）。 修改为nop je(jne,jz,jnz) =&gt;nop相应的机器码90 （正确信息向上找到的第一个跳转） nop的作用是抹掉这个跳转，使这个跳转无效，失去作用，从而使程序顺利来到紧跟其后的正确信息处。 正确信息，例如：注册成功，谢谢您的支持等（我们希望它不被跳过，让它出现，程序一定要顺利来到这里）。 出错信息（我们希望不要跳到这里，不让它出现）它们在存贮器和寄存器、寄存器和输入输出端口之间传送数据。 例如使用windbg时候： 12 0:000&gt; dd 0c366b28 l40c366b28 7e830c74 940f0108 c0b60fc0 01b805eb 执行ed 0c366b28 7e830c75 修改为: 12 0:000&gt; dd 0c366b28 l40c366b28 7e830c75 940f0108 c0b60fc0 01b805eb","categories":[{"name":"Language","slug":"Language","permalink":"http://meng.uno/categories/Language/"},{"name":"ASM","slug":"Language/ASM","permalink":"http://meng.uno/categories/Language/ASM/"}],"tags":[{"name":"破解","slug":"破解","permalink":"http://meng.uno/tags/破解/"},{"name":"ASM","slug":"ASM","permalink":"http://meng.uno/tags/ASM/"},{"name":"汇编","slug":"汇编","permalink":"http://meng.uno/tags/汇编/"}]}]}