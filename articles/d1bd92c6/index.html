<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">

  <meta http-equiv="X-Frame-Options" content="DENY">
  <title>自然语言处理（NLP）基础 | 欢迎来到匡盟盟的博客！</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta name="keywords" content="匡盟盟, Colyn Kuang, Blog, 博客" />


  <meta name="google-site-verification" content="3YclHsmiu1_poywYScAg4jt4RGqoHUoIXQJFV5vEZ1I" />


  <meta name="baidu-site-verification" content="d6tIQA0tgL" />


  <meta name="description" content="NLP 概述 解决 NLP 问题的一般思路 1 2 3   这个问题人类可以做好么？   - 可以 -&amp;gt; 记录自己的思路 -&amp;gt; 设计流程让机器完成你的思路   - 很难 -&amp;gt; 尝试从计算机的角度来思考问题   NLP 的历史进程  *  规则系统         * 正则表达式/自动机     * 规则是固定的     * 搜索引擎 1       2       3       4">
  <meta name="keywords" content="AI,NLP,自然语言处理">
  <meta property="og:type" content="article">
  <meta property="og:title" content="自然语言处理（NLP）基础">
  <meta property="og:url" content="http://www.meng.uno/articles/d1bd92c6/index.html">
  <meta property="og:site_name" content="欢迎来到匡盟盟的博客！">
  <meta property="og:description" content="NLP 概述 解决 NLP 问题的一般思路 1 2 3   这个问题人类可以做好么？   - 可以 -&amp;gt; 记录自己的思路 -&amp;gt; 设计流程让机器完成你的思路   - 很难 -&amp;gt; 尝试从计算机的角度来思考问题   NLP 的历史进程  *  规则系统         * 正则表达式/自动机     * 规则是固定的     * 搜索引擎 1       2       3       4">
  <meta property="og:locale" content="zh-CN">
  <meta property="og:image" content="http://www.meng.uno/images/assets/TIM截图20180807203305.png">
  <meta property="og:image" content="http://www.meng.uno/images/assets/TIM截图20180807210029.png">
  <meta property="og:image" content="http://www.meng.uno/images/assets/TIM截图20180807210133.png">
  <meta property="og:image" content="http://www.meng.uno/images/assets/公式_20180728195601.png">
  <meta property="og:image" content="http://www.meng.uno/images/assets/公式_20180728201614.png">
  <meta property="og:image" content="http://www.meng.uno/images/assets/公式_20180728202629.png">
  <meta property="og:image" content="http://www.meng.uno/images/assets/公式_20180728205525.png">
  <meta property="og:image" content="http://www.meng.uno/images/assets/TIM截图20180728212554.png">
  <meta property="og:image" content="http://www.meng.uno/images/assets/TIM截图20180728215749.png">
  <meta property="og:image" content="http://www.meng.uno/images/assets/TIM截图20180728212444.png">
  <meta property="og:image" content="http://www.meng.uno/images/assets/TIM截图20180728213300.png">
  <meta property="og:image" content="http://www.meng.uno/images/assets/公式_20180805204149.png">
  <meta property="og:image" content="http://www.meng.uno/images/assets/公式_20180805211530.png">
  <meta property="og:image" content="http://www.meng.uno/images/assets/公式_20180805211644.png">
  <meta property="og:image" content="http://www.meng.uno/images/assets/公式_20180805211936.png">
  <meta property="og:image" content="http://www.meng.uno/images/assets/公式_20180805212222.png">
  <meta property="og:image" content="http://www.meng.uno/images/assets/TIM截图20180805212441.png">
  <meta property="og:image" content="http://www.meng.uno/images/assets/公式_20180806100950.png">
  <meta property="og:image" content="http://www.meng.uno/images/assets/公式_20180806102047.png">
  <meta property="og:image" content="http://www.meng.uno/images/assets/公式_2018080695721.png">
  <meta property="og:image" content="http://www.meng.uno/images/assets/TIM截图20180805234123.png">
  <meta property="og:image" content="http://www.meng.uno/images/assets/公式_2018080695819.png">
  <meta property="og:image" content="http://www.meng.uno/images/assets/TIM截图20180805231056.png">
  <meta property="og:updated_time" content="2018-08-16T03:55:08.000Z">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="自然语言处理（NLP）基础">
  <meta name="twitter:description" content="NLP 概述 解决 NLP 问题的一般思路 1 2 3   这个问题人类可以做好么？   - 可以 -&amp;gt; 记录自己的思路 -&amp;gt; 设计流程让机器完成你的思路   - 很难 -&amp;gt; 尝试从计算机的角度来思考问题   NLP 的历史进程  *  规则系统         * 正则表达式/自动机     * 规则是固定的     * 搜索引擎 1       2       3       4">
  <meta name="twitter:image" content="http://www.meng.uno/images/assets/TIM截图20180807203305.png">
  <meta name="twitter:creator" content="@kuangmengmeng">
  <link rel="publisher" href="mengmengkuang">
  <meta property="fb:admins" content="kuangmengmeng">
  <meta property="fb:app_id" content="1559086807462632">

  <link rel="alternate" href="/atom.xml" title="欢迎来到匡盟盟的博客！" type="application/atom+xml">




  <link rel="icon" id="myid" href="/css/images/logo.png">
  <link rel="apple-touch-icon" id="myid" href="/css/images/logo.png">

  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">

  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Montserrat:700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic" rel="stylesheet" type="text/css">
  <link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <style type="text/css">
    @font-face {
      font-family: futura-pt;
      src: url(https://use.typekit.net/af/9749f0/00000000000000000001008f/27/l?subset_id=2&fvd=n5) format("woff2");
      font-weight: 500;
      font-style: normal;
    }

    @font-face {
      font-family: futura-pt;
      src: url(https://use.typekit.net/af/90cf9f/000000000000000000010091/27/l?subset_id=2&fvd=n7) format("woff2");
      font-weight: 500;
      font-style: normal;
    }

    @font-face {
      font-family: futura-pt;
      src: url(https://use.typekit.net/af/8a5494/000000000000000000013365/27/l?subset_id=2&fvd=n4) format("woff2");
      font-weight: lighter;
      font-style: normal;
    }

    @font-face {
      font-family: futura-pt;
      src: url(https://use.typekit.net/af/d337d8/000000000000000000010095/27/l?subset_id=2&fvd=i4) format("woff2");
      font-weight: 400;
      font-style: italic;
    }
  </style>
  <link rel="stylesheet" href="/css/style.css">

  <script src="/js/jquery-3.1.1.min.js"></script>
  <script src="/js/bootstrap.js"></script>
  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/css/bootstrap.css">
  <link rel="stylesheet" href="/css/prism-duotone-sea.css">


  <link rel="stylesheet" href="/css/dialog.css">





  <link rel="stylesheet" href="/css/header-post.css">





  <link rel="stylesheet" href="/css/vdonate.css">




  <!-- 
<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"1","bdMiniList":["copy","weixin","linkedin","sqq","tsina","twi","fbook","mail"],"bdPic":"","bdStyle":"0","bdSize":"16"},"slide":{"type":"slide","bdImg":"0","bdPos":"left","bdTop":"100"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["qzone","tsina","tqq","renren","weixin"]}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>

 -->





  <link rel="canonical" href="http://www.meng.uno/articles/d1bd92c6/" />

  <link rel="stylesheet" href="/css/animate.css">
  <link rel="stylesheet" href="/css/loading.css">

  <script>
    var linkEle = document.getElementById("myid");
    var tmplink = linkEle.href;

    var tmptitle = document.title;
    document.addEventListener('visibilitychange', function() {
      var isHidden = document.hidden;
      if (isHidden) {
        document.title = '喔唷，崩溃啦！';
        linkEle.href = '/css/images/avatar.png';
      } else {
        document.title = tmptitle;
        linkEle.href = tmplink;

      }
    });


    function Hide() {
      var mychar = document.getElementById("homelogoback").style.display = "none";
    }
  </script>

  <script defer src="https://use.fontawesome.com/releases/v5.0.8/js/all.js"></script>




</head>


<body data-spy="scroll" data-target="#toc" data-offset="50">



  <div id="container">
    <div id="wrap">

      <header>
        <div id="allheader" class="navbar navbar-default navbar-static-top" role="navigation">
          <div class="navbar-inner">
            <div class="container">
              <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
              <span class="sr-only"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>


              <a class="brand" style="
                 border-width: 0px;  margin-top: 0px;" href="#" data-toggle="modal" data-target="#myModal">
                  <img class="img-rotate" style="box-shadow:1px 1px 10px 3px #e5e5e5; border-radius: 50%;" width="124px" height="124px" alt="匡盟盟的博客" src="/css/images/logo.png">
              </a>


              <div class="navbar-collapse collapse">
                <ul class="hnav navbar-nav">

                  <li> <a class="main-nav-link" href="/">首页</a> </li>

                  <li> <a class="main-nav-link" href="/archives">所有文章</a> </li>

                  <li> <a class="main-nav-link" href="/categories">分类</a> </li>

                  <li> <a class="main-nav-link" href="/tags">标签</a> </li>

                  <li> <a class="main-nav-link" href="/about">关于我</a> </li>

                  <li> <a class="main-nav-link" href="/comments">留言板</a> </li>

                  <li>
                    <div id="search-form-wrap">

                      <form class="search-form">
                        <input type="text" style="width=0;" class="ins-search-input search-form-input" placeholder="" />
                        <button type="submit" class="search-form-submit"></button>
                      </form>
                      <div class="ins-search">
                        <div class="ins-search-mask"></div>
                        <div class="ins-search-container">
                          <div class="ins-input-wrapper">
                            <input type="text" class="ins-search-input" placeholder="请输入关键词..." />
                            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
                          </div>
                          <div class="ins-section-wrapper">
                            <div class="ins-section-container"></div>
                          </div>
                        </div>
                      </div>
                      <script>
                        (function(window) {
                          var INSIGHT_CONFIG = {
                            TRANSLATION: {
                              POSTS: '文章',
                              PAGES: '页面',
                              CATEGORIES: '分类',
                              TAGS: '标签',
                              UNTITLED: '空标题',
                            },
                            ROOT_URL: '/',
                            CONTENT_URL: '/content.json',
                          };
                          window.INSIGHT_CONFIG = INSIGHT_CONFIG;
                        })(window);
                      </script>
                      <script src="/js/insight.js"></script>

                    </div>
                  </li>

                </ul>
              </div>
            </div>

          </div>
        </div>

      </header>

      <script>
        (function(w, i, d, g, e, t, s) {
          w[d] = w[d] || [];
          t = i.createElement(g);
          t.async = 1;
          t.src = e;
          s = i.getElementsByTagName(g)[0];
          s.parentNode.insertBefore(t, s);
        })(window, document, '_gscq', 'script', '//widgets.getsitecontrol.com/125646/script.js');
      </script>


      <div id="content" class="outer">

        <section id="main" style="float:none;">
          <article id="post-NLP-自然语言处理基础" style="width: 75%; float:left;" class="article article-type-post" itemscope itemprop="blogPost">
            <div id="articleInner" class="article-inner">


              <header class="article-header">
                <h1 class="thumb" class="article-title" itemprop="name">
                  自然语言处理（NLP）基础
                </h1>
              </header>

              <div class="article-meta">
                <a href="/articles/d1bd92c6/" class="article-date">
	  <time datetime="2018-07-05T14:09:21.000Z" itemprop="datePublished">2018-07-05</time>
	</a>
                <a class="article-category-link" href="/categories/NLP/">NLP</a>
                <a class="article-views">
	<span id="busuanzi_container_page_pv">
		阅读量<span id="busuanzi_value_page_pv"></span>
	</span>
	<span class="post-count"> | 字数2,956</span>
	<span class="post-count"> | 预计时间11分钟</span>
	</a>
              </div>
              <div class="article-entry" itemprop="articleBody">

                <h1>NLP 概述</h1>
                <h2 id="解决-nlp-问题的一般思路">解决 NLP 问题的一般思路</h2>
                <figure class="highlight tex">
                  <table>
                    <tr>
                      <td class="gutter">
                        <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                      </td>
                      <td class="code">
                        <pre><span class="line">这个问题人类可以做好么？</span><br><span class="line">  - 可以 -&gt; 记录自己的思路 -&gt; 设计流程让机器完成你的思路</span><br><span class="line">  - 很难 -&gt; 尝试从计算机的角度来思考问题</span><br></pre>
                      </td>
                    </tr>
                  </table>
                </figure>
                <h2 id="nlp-的历史进程">NLP 的历史进程</h2>
                <ul>
                  <li>
                    <p><strong>规则系统</strong></p>
                    <ul>
                      <li>正则表达式/自动机</li>
                      <li>规则是固定的</li>
                      <li><strong>搜索引擎</strong>
                        <figure class="highlight tex">
                          <table>
                            <tr>
                              <td class="gutter">
                                <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                              </td>
                              <td class="code">
                                <pre><span class="line">“豆瓣酱用英语怎么说？”</span><br><span class="line">规则：“xx用英语怎么说？” =&gt; translate(XX, English)</span><br><span class="line"></span><br><span class="line">“我饿了”</span><br><span class="line">规则：“我饿（死）了” =&gt; recommend(饭店，地点)</span><br></pre>
                              </td>
                            </tr>
                          </table>
                        </figure>
                      </li>
                    </ul>
                  </li>
                  <li>
                    <p><strong>概率系统</strong></p>
                    <ul>
                      <li>
                        <p>规则从数据中<strong>抽取</strong></p>
                      </li>
                      <li>
                        <p>规则是有<strong>概率</strong>的</p>
                      </li>
                      <li>
                        <p>概率系统的一般<strong>工作方式</strong></p>
                        <figure class="highlight tex">
                          <table>
                            <tr>
                              <td class="gutter">
                                <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre>
                              </td>
                              <td class="code">
                                <pre><span class="line">流程设计</span><br><span class="line">  收集训练数据</span><br><span class="line">    预处理</span><br><span class="line">      特征工程</span><br><span class="line">        分类器（机器学习算法）</span><br><span class="line">          预测</span><br><span class="line">            评价</span><br></pre>
                              </td>
                            </tr>
                          </table>
                        </figure>
                        <div align="center"><img src="http://www.meng.uno/images/assets/TIM截图20180807203305.png" height="200"></div>
                        <ul>
                          <li>最重要的部分：数据收集、预处理、特征工程</li>
                        </ul>
                      </li>
                      <li>
                        <p>示例</p>
                        <figure class="highlight tex">
                          <table>
                            <tr>
                              <td class="gutter">
                                <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre>
                              </td>
                              <td class="code">
                                <pre><span class="line">任务：</span><br><span class="line">  “豆瓣酱用英语怎么说” =&gt; translate(豆瓣酱，Eng)</span><br><span class="line">流程设计（序列标注）：</span><br><span class="line">  子任务1： 找出目标语言 “豆瓣酱用 **英语** 怎么说”</span><br><span class="line">  子任务2： 找出翻译目标 “ **豆瓣酱** 用英语怎么说”</span><br><span class="line">收集训练数据：</span><br><span class="line">  （子任务1）</span><br><span class="line">  “豆瓣酱用英语怎么说”</span><br><span class="line">  “茄子用英语怎么说”</span><br><span class="line">  “黄瓜怎么翻译成英语”</span><br><span class="line">预处理：</span><br><span class="line">  分词：“豆瓣酱 用 英语 怎么说”</span><br><span class="line">抽取特征：</span><br><span class="line">  （前后各一个词）</span><br><span class="line">  0 茄子：    &lt; _ 用</span><br><span class="line">  0 用：      豆瓣酱 _ 英语</span><br><span class="line">  1 英语：    用 _ 怎么说</span><br><span class="line">  0 怎么说：  英语 _ &gt;</span><br><span class="line">分类器：</span><br><span class="line">  SVM/CRF/HMM/RNN</span><br><span class="line">预测：</span><br><span class="line">  0.1 茄子：    &lt; _ 用</span><br><span class="line">  0.1 用：      豆瓣酱 _ 英语</span><br><span class="line">  0.7 英语：    用 _ 怎么说</span><br><span class="line">  0.1 怎么说：  英语 _ &gt;</span><br><span class="line">评价：</span><br><span class="line">  准确率</span><br></pre>
                              </td>
                            </tr>
                          </table>
                        </figure>
                      </li>
                    </ul>
                  </li>
                </ul>
                <ul>
                  <li>
                    <p>概率系统的优/缺点</p>
                    <ul>
                      <li><code>+</code> 规则更加贴近于真实事件中的规则，因而效果往往比较好</li>
                      <li><code>-</code> 特征是由专家/人指定的；</li>
                      <li><code>-</code> 流程是由专家/人设计的；</li>
                      <li><code>-</code> 存在独立的<strong>子任务</strong></li>
                    </ul>
                  </li>
                  <li>
                    <p><strong>深度学习</strong></p>
                    <ul>
                      <li>深度学习相对概率模型的优势
                        <ul>
                          <li>特征是由专家指定的 <code>-&gt;</code> 特征是由深度学习自己提取的</li>
                          <li>流程是由专家设计的 <code>-&gt;</code> 模型结构是由专家设计的</li>
                          <li>存在独立的子任务 <code>-&gt;</code> End-to-End Training</li>
                        </ul>
                      </li>
                    </ul>
                  </li>
                </ul>
                <h2 id="seq2seq-模型">Seq2Seq 模型</h2>
                <ul>
                  <li>
                    <p>大部分自然语言问题都可以使用 Seq2Seq 模型解决</p>
                    <div align="center"><img src="http://www.meng.uno/images/assets/TIM截图20180807210029.png" height="200"></div>
                  </li>
                  <li>
                    <p><strong>“万物”皆 Seq2Seq</strong></p>
                    <div align="center"><img src="http://www.meng.uno/images/assets/TIM截图20180807210133.png" height="300"></div>
                  </li>
                </ul>
                <h2 id="评价机制">评价机制</h2>
                <h3 id="困惑度-perplexity-ppx">困惑度 (Perplexity, PPX)</h3>
                <blockquote>
                  <p><a href="https://en.wikipedia.org/wiki/Perplexity" target="_blank" rel="noopener">Perplexity</a> - Wikipedia</p>
                </blockquote>
                <ul>
                  <li>在信息论中，perplexity 用于度量一个<strong>概率分布</strong>或<strong>概率模型</strong>预测样本的好坏程度</li>
                </ul>
                <p>
                </p>
                <h3>基本公式</h3>
                <p></p>
                <ul>
                  <li>
                    <p><strong>概率分布</strong>（离散）的困惑度</p>
                    <div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=\dpi{150}&space;{\displaystyle&space;2^{H(p)}=2^{-\sum&space;_{x}p(x)\log&space;_{2}p(x)}}" target="_blank" rel="noopener"><img src="http://www.meng.uno/images/assets/公式_20180728195601.png"></a></div>
                    <blockquote>
                      <p>其中 <code>H(p)</code> 即<strong>信息熵</strong></p>
                    </blockquote>
                  </li>
                  <li>
                    <p><strong>概率模型</strong>的困惑度</p>
                    <div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=\dpi{150}&space;{\displaystyle&space;b^{-{\frac&space;{1}{N}}\sum&space;_{i=1}^{N}\log&space;_{b}q(x_{i})}}" target="_blank" rel="noopener"><img src="http://www.meng.uno/images/assets/公式_20180728201614.png"></a></div>
                    <blockquote>
                      <p>通常 <code>b=2</code></p>
                    </blockquote>
                  </li>
                  <li>
                    <p><strong>指数部分</strong>也可以是<strong>交叉熵</strong>的形式，此时困惑度相当于交叉熵的指数形式</p>
                    <div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=\dpi{150}&space;2^{H(\tilde{p},q)}&space;=&space;2^{-\sum_x\tilde{p}(x)\log_{2}q(x)}" target="_blank" rel="noopener"><img src="http://www.meng.uno/images/assets/公式_20180728202629.png"></a></div>
                    <blockquote>
                      <p>其中 <code>p~</code> 为<strong>测试集</strong>中的经验分布——<code>p~(x) = n/N</code>，其中 <code>n</code> 为 x 的出现次数，N 为测试集的大小</p>
                    </blockquote>
                  </li>
                </ul>
                <p><strong>语言模型中的 PPX</strong></p>
                <ul>
                  <li>
                    <p>在 <strong>NLP</strong> 中，困惑度常作为<strong>语言模型</strong>的评价指标</p>
                    <div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=\dpi{150}&space;\begin{aligned}&space;\mathrm{PPX}(W_{test})&space;&=2^{-\sum_{i=1}^{|V|}\tilde{p}(w_i)\log_{2}q(w_i)}\\&space;&=2^{-\sum_{i=1}^{|V|}\frac{\mathrm{cnt}(w_i)}{N}\log_{2}q(w_i)}&space;\end{aligned}"
                        target="_blank" rel="noopener"><img src="http://www.meng.uno/images/assets/公式_20180728205525.png"></a></div>
                  </li>
                  <li>
                    <p>直观来说，就是下一个<strong>候选词数目</strong>的期望值——</p>
                    <p>如果不使用任何模型，那么下一个候选词的数量就是整个词表的数量；通过使用 <code>bi-gram</code>语言模型，可以将整个数量限制到 <code>200</code> 左右</p>
                  </li>
                </ul>
                <h3 id="bleu">BLEU</h3>
                <blockquote>
                  <p><a href="https://blog.csdn.net/qq_21190081/article/details/53115580" target="_blank" rel="noopener">一种机器翻译的评价准则——BLEU</a> - CSDN博客</p>
                </blockquote>
                <ul>
                  <li>
                    <p>机器翻译评价准则</p>
                  </li>
                  <li>
                    <p>计算公式</p>
                    <div align="center"><img src="http://www.meng.uno/images/assets/TIM截图20180728212554.png" height=""></div>
                    <p>其中</p>
                    <div style="position:relative;left:25%"><img src="http://www.meng.uno/images/assets/TIM截图20180728215749.png" height=""></div>
                    <div style="position:relative;left:25%"><img src="http://www.meng.uno/images/assets/TIM截图20180728212444.png" height=""></div>
                    <!-- <div style="position:relative;left:25%"><img src="http://www.meng.uno/images/assets/TIM截图20180728212444.png" height="" /></div> -->
                    <blockquote>
                      <p><code>c</code> 为生成句子的长度；<code>r</code> 为参考句子的长度——目的是<strong>惩罚</strong>长度过短的候选句子</p>
                    </blockquote>
                  </li>
                  <li>
                    <p>为了计算方便，会加一层 <code>log</code></p>
                    <div align="center"><img src="http://www.meng.uno/images/assets/TIM截图20180728213300.png" height=""></div>
                    <blockquote>
                      <p>通常 <code>N=4, w_n=1/4</code></p>
                    </blockquote>
                  </li>
                </ul>
                <h3 id="rouge">ROUGE</h3>
                <blockquote>
                  <p><a href="https://blog.csdn.net/qq_25222361/article/details/78694617" target="_blank" rel="noopener">自动文摘评测方法：Rouge-1、Rouge-2、Rouge-L、Rouge-S</a> - CSDN博客</p>
                </blockquote>
                <ul>
                  <li>一种机器翻译/自动摘要的评价准则</li>
                </ul>
                <blockquote>
                  <p><a href="https://blog.csdn.net/joshuaxx316/article/details/58696552" target="_blank" rel="noopener">BLEU，ROUGE，METEOR，ROUGE-浅述自然语言处理机器翻译常用评价度量</a> - CSDN博客</p>
                </blockquote>
                <h1>语言模型</h1>
                <h2 id="xx-模型的含义">XX 模型的含义</h2>
                <ul>
                  <li>如果能使用某个方法对 XX <strong>打分</strong>（Score），那么就可以把这个方法称为 “<strong>XX 模型</strong>”
                    <ul>
                      <li><strong>篮球明星模型</strong>: <code>Score(库里)</code>、<code>Score(詹姆斯)</code></li>
                      <li><strong>话题模型</strong>——对一段话是否在谈论某一话题的打分
                        <figure class="highlight plain">
                          <table>
                            <tr>
                              <td class="gutter">
                                <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                              </td>
                              <td class="code">
                                <pre><span class="line">Score( NLP | &quot;什么 是 语言 模型？&quot; ) --&gt; 0.8</span><br><span class="line">Score( ACM | &quot;什么 是 语言 模型？&quot; ) --&gt; 0.05</span><br></pre>
                              </td>
                            </tr>
                          </table>
                        </figure>
                      </li>
                    </ul>
                  </li>
                </ul>
                <h2 id="概率-统计语言模型-plm-slm">概率/统计语言模型 (PLM, SLM)</h2>
                <ul>
                  <li>
                    <p><strong>语言模型</strong>是一种对语言打分的方法；而<strong>概率语言模型</strong>把语言的“得分”通过<strong>概率</strong>来体现</p>
                  </li>
                  <li>
                    <p>具体来说，概率语言模型计算的是<strong>一个序列</strong>作为一句话可能的概率</p>
                    <figure class="highlight plain">
                      <table>
                        <tr>
                          <td class="gutter">
                            <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                          </td>
                          <td class="code">
                            <pre><span class="line">Score(&quot;什么 是 语言 模型&quot;) --&gt; 0.05   # 比较常见的说法，得分比较高</span><br><span class="line">Score(&quot;什么 有 语言 模型&quot;) --&gt; 0.01   # 不太常见的说法，得分比较低</span><br></pre>
                          </td>
                        </tr>
                      </table>
                    </figure>
                  </li>
                </ul>
                <ul>
                  <li>
                    <p>以上过程可以形式化为：</p>
                    <div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=p(W)=p(w_1^T)=p(w_1,w_2,...,w_T" target="_blank" rel="noopener"><img src="http://www.meng.uno/images/assets/公式_20180805204149.png" height=""></a></div>
                    <p>根据贝叶斯公式，有</p>
                    <div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=p(w_1^T)=p(w_1)\cdot&space;p(w_2|w_1)\cdot&space;p(w_3|w_1^2)\cdots&space;p(w_T|w_1^{T-1})" target="_blank" rel="noopener"><img src="http://www.meng.uno/images/assets/公式_20180805211530.png" height=""></a></div>
                  </li>
                  <li>
                    <p>其中每个条件概率就是<strong>模型的参数</strong>；如果这个参数都是已知的，那么就能得到整个序列的概率了</p>
                  </li>
                </ul>
                <h3 id="参数的规模">参数的规模</h3>
                <ul>
                  <li>设词表的大小为 <code>N</code>，考虑长度为 <code>T</code> 的句子，理论上有 <code>N^T</code> 种可能的句子，每个句子中有 <code>T</code> 个参数，那么参数的数量将达到 <code>O(T*N^T)</code></li>
                </ul>
                <h3 id="可用的概率模型">可用的概率模型</h3>
                <ul>
                  <li>统计语言模型实际上是一个概率模型，所以常见的概率模型都可以用于求解这些参数</li>
                  <li>常见的概率模型有：N-gram 模型、决策树、最大熵模型、隐马尔可夫模型、条件随机场、神经网络等</li>
                  <li>目前常用于语言模型的是 N-gram 模型和神经语言模型（下面介绍）</li>
                </ul>
                <h2 id="n-gram-语言模型">N-gram 语言模型</h2>
                <ul>
                  <li>
                    <p>马尔可夫(Markov)假设——未来的事件，只取决于有限的历史</p>
                  </li>
                  <li>
                    <p>基于马尔可夫假设，N-gram 语言模型认为一个词出现的概率只与它前面的 n-1 个词相关</p>
                    <div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=p(w_k|w_1,..,w_{k-1})\approx&space;p(w_k|w_{k-n&plus;1},..,w_{k-1})" target="_blank" rel="noopener"><img src="http://www.meng.uno/images/assets/公式_20180805211644.png" height=""></a></div>
                  </li>
                  <li>
                    <p>根据<strong>条件概率公式</strong>与<strong>大数定律</strong>，当语料的规模足够大时，有</p>
                    <div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=p(w_k|w_{k-n&plus;1}^{k-1})=\frac{p(w_{k-n&plus;1}^k)}{p(w_{k-n&plus;1}^{k-1})}\approx&space;\frac{\mathrm{count}(w_{k-n&plus;1}^k)}{\mathrm{count}(w_{k-n&plus;1}^{k-1})}" target="_blank"
                        rel="noopener"><img src="http://www.meng.uno/images/assets/公式_20180805211936.png" height=""></a></div>
                  </li>
                  <li>
                    <p>以 <code>n=2</code> 即 bi-gram 为例，有</p>
                    <div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=p(w_k|w_{k-1})=\frac{p(w_{k-1},w_k)}{p(w_{k-1})}\approx&space;\frac{\mathrm{count}(w_{k-1},w_k)}{\mathrm{count}(w_{k-1})}" target="_blank" rel="noopener"><img src="http://www.meng.uno/images/assets/公式_20180805212222.png" height=""></a></div>
                  </li>
                  <li>
                    <p>假设词表的规模 <code>N=200000</code>（汉语的词汇量），模型参数与 `n· 的关系表</p>
                    <div align="center"><img src="http://www.meng.uno/images/assets/TIM截图20180805212441.png" height=""></div>
                  </li>
                </ul>
                <h3 id="可靠性与可区别性">可靠性与可区别性</h3>
                <ul>
                  <li>假设没有计算和存储限制，<code>n</code> 是不是越大越好？</li>
                  <li>早期因为计算性能的限制，一般最大取到 <code>n=4</code>；如今，即使 <code>n&gt;10</code> 也没有问题，</li>
                  <li>但是，随着 <code>n</code> 的增大，模型的性能增大却不显著，这里涉及了<strong>可靠性与可区别性</strong>的问题</li>
                  <li>参数越多，模型的可区别性越好，但是可靠性却在下降——因为语料的规模是有限的，导致 <code>count(W)</code> 的实例数量不够，从而降低了可靠性</li>
                </ul>
                <h3 id="oov-问题">OOV 问题</h3>
                <ul>
                  <li>OOV 即 Out Of Vocabulary，也就是序列中出现了词表外词，或称为<strong>未登录词</strong></li>
                  <li>或者说在测试集和验证集上出现了训练集中没有过的词</li>
                  <li>一般<strong>解决方案</strong>：
                    <ul>
                      <li>设置一个词频阈值，只有高于该阈值的词才会加入词表</li>
                      <li>所有低于阈值的词替换为 UNK（一个特殊符号）</li>
                    </ul>
                  </li>
                  <li>无论是统计语言模型还是神经语言模型都是类似的处理方式
                    <blockquote>
                      <p><a href="#nplm-%E4%B8%AD%E7%9A%84-oov-%E9%97%AE%E9%A2%98">NPLM 中的 OOV 问题</a></p>
                    </blockquote>
                  </li>
                </ul>
                <h3 id="平滑处理-todo">平滑处理 TODO</h3>
                <ul>
                  <li><code>count(W) = 0</code> 是怎么办？</li>
                  <li>平滑方法（层层递进）：
                    <ul>
                      <li>Add-one Smoothing (Laplace)</li>
                      <li>Add-k Smoothing (k&lt;1)</li>
                      <li>Back-off （回退）</li>
                      <li>Interpolation （插值法）</li>
                      <li>Absolute Discounting （绝对折扣法）</li>
                      <li>Kneser-Ney Smoothing （KN）</li>
                      <li>Modified Kneser-Ney</li>
                    </ul>
                    <blockquote>
                      <p><a href="https://blog.csdn.net/baimafujinji/article/details/51297802" target="_blank" rel="noopener">自然语言处理中N-Gram模型的Smoothing算法</a> - CSDN博客</p>
                    </blockquote>
                  </li>
                </ul>
                <h2 id="神经概率语言模型-nplm">神经概率语言模型 (NPLM)</h2>
                <ul>
                  <li>
                    <p>神经概率语言模型依然是一个概率语言模型，它通过<strong>神经网络</strong>来计算概率语言模型中每个参数</p>
                    <div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=p(w|{\color{Red}\text{context}(w)})=g(i_w,{\color{Red}V_{context}})" target="_blank" rel="noopener"><img src="http://www.meng.uno/images/assets/公式_20180806100950.png" height=""></a></div>
                    <ul>
                      <li>其中 <code>g</code> 表示神经网络，<code>i_w</code> 为 <code>w</code> 在词表中的序号，<code>context(w)</code> 为 <code>w</code> 的上下文，<code>V_context</code> 为上下文构成的特征向量。</li>
                      <li><code>V_context</code> 由上下文的<strong>词向量</strong>进一步组合而成</li>
                    </ul>
                  </li>
                </ul>
                <h3 id="n-gram-神经语言模型">N-gram 神经语言模型</h3>
                <ul>
                  <li>
                    <p>这是一个经典的神经概率语言模型，它沿用了 N-gram 模型中的思路，将 <code>w</code> 的前 <code>n-1</code> 个词作为 <code>w</code> 的上下文 <code>context(w)</code>，而 <code>V_context</code> 由这 <code>n-1</code> 个词的词向量拼接而成，即</p>
                    <div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=p(w_k|{\color{Red}w_{k-n&plus;1}^{k-1}})=g(i_{w_k},{\color{Red}[c(w_{k-n&plus;1});...;c(w_{k-1})]})" target="_blank" rel="noopener"><img src="http://www.meng.uno/images/assets/公式_20180806102047.png" height=""></a></div>
                    <ul>
                      <li>其中 <code>c(w)</code> 表示 <code>w</code> 的词向量</li>
                      <li>不同的神经语言模型中 <code>context(w)</code> 可能不同，比如 Word2Vec 中的 CBOW 模型</li>
                    </ul>
                  </li>
                  <li>
                    <p>每个训练样本是形如 <code>(context(w), w)</code> 的二元对，其中 <code>context(w)</code> 取 w 的前 <code>n-1</code> 个词；当不足 <code>n-1</code>，用特殊符号填充</p>
                    <ul>
                      <li>同一个网络只能训练特定的 <code>n</code>，不同的 <code>n</code> 需要训练不同的神经网络</li>
                    </ul>
                  </li>
                </ul>
                <h4 id="n-gram-神经语言模型的网络结构">N-gram 神经语言模型的网络结构</h4>
                <ul>
                  <li>
                    <p>【<strong>输入层</strong>】首先，将 <code>context(w)</code> 中的每个词映射为一个长为 <code>m</code> 的词向量，<strong>词向量在训练开始时是随机的</strong>，并<strong>参与训练</strong>；</p>
                  </li>
                  <li>
                    <p>【<strong>投影层</strong>】将所有上下文词向量<strong>拼接</strong>为一个长向量，作为 <code>w</code> 的特征向量，该向量的维度为 <code>m(n-1)</code></p>
                  </li>
                  <li>
                    <p>【<strong>隐藏层</strong>】拼接后的向量会经过一个规模为 <code>h</code> 隐藏层，该隐层使用的激活函数为 <code>tanh</code></p>
                  </li>
                  <li>
                    <p>【<strong>输出层</strong>】最后会经过一个规模为 <code>N</code> 的 Softmax 输出层，从而得到词表中每个词作为下一个词的概率分布</p>
                    <blockquote>
                      <p>其中 <code>m, n, h</code> 为超参数，<code>N</code> 为词表大小，视训练集规模而定，也可以人为设置阈值</p>
                    </blockquote>
                  </li>
                  <li>
                    <p>训练时，使用<strong>交叉熵</strong>作为损失函数</p>
                  </li>
                  <li>
                    <p><strong>当训练完成时</strong>，就得到了 N-gram 神经语言模型，以及副产品<strong>词向量</strong></p>
                  </li>
                  <li>
                    <p>整个模型可以概括为如下公式：</p>
                    <div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=y=U\cdot\tanh(Wx&plus;p)&plus;q" target="_blank" rel="noopener"><img src="http://www.meng.uno/images/assets/公式_2018080695721.png" height=""></a></div>
                    <br>
                    <div align="center"><img src="http://www.meng.uno/images/assets/TIM截图20180805234123.png" height="200"></div>
                  </li>
                </ul>
                <blockquote>
                  <p>原文的模型还考虑了投影层与输出层有有边相连的情形，因而会多一个权重矩阵，但本质上是一致的：</p>
                </blockquote>
                <blockquote>
                  <blockquote>
                    <div align="center"><a href="http://www.codecogs.com/eqnedit.php?latex=y=U\cdot\tanh(W_1x&plus;p)&plus;W_2x&plus;q" target="_blank" rel="noopener"><img src="http://www.meng.uno/images/assets/公式_2018080695819.png" height=""></a></div><br>
                  </blockquote>
                </blockquote>
                <blockquote>
                  <blockquote>
                    <div align="center"><img src="http://www.meng.uno/images/assets/TIM截图20180805231056.png" height=""></div>
                  </blockquote>
                </blockquote>
                <h3 id="模型参数的规模与运算量">模型参数的规模与运算量</h3>
                <ul>
                  <li>
                    <p>模型的超参数：<code>m, n, h, N</code></p>
                    <ul>
                      <li><code>m</code> 为词向量的维度，通常在 <code>10^1 ~ 10^2</code></li>
                      <li><code>n</code> 为 n-gram 的规模，一般小于 5</li>
                      <li><code>h</code> 为隐藏的单元数，一般在 <code>10^2</code></li>
                      <li><code>N</code> 位词表的数量，一般在 <code>10^4 ~ 10^5</code>，甚至 <code>10^6</code></li>
                    </ul>
                  </li>
                  <li>
                    <p>网络参数包括两部分</p>
                    <ul>
                      <li>词向量 <code>C</code>: 一个 <code>N * m</code> 的矩阵——其中 <code>N</code> 为词表大小，<code>m</code> 为词向量的维度</li>
                      <li>网络参数 <code>W, U, p, q</code>：
                        <figure class="highlight plain">
                          <table>
                            <tr>
                              <td class="gutter">
                                <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                              </td>
                              <td class="code">
                                <pre><span class="line">- W: h * m(n-1) 的矩阵</span><br><span class="line">- p: h * 1      的矩阵</span><br><span class="line">- U: N * h    的矩阵</span><br><span class="line">- q: N * 1    的矩阵</span><br></pre>
                              </td>
                            </tr>
                          </table>
                        </figure>
                      </li>
                    </ul>
                  </li>
                  <li>
                    <p>模型的运算量</p>
                    <ul>
                      <li>主要集中在隐藏层和输出层的矩阵运算以及 SoftMax 的归一化计算</li>
                      <li>此后的相关研究中，主要是针对这一部分进行优化，其中就包括 <strong>Word2Vec</strong> 的工作</li>
                    </ul>
                  </li>
                </ul>
                <h3 id="相比-n-gram-模型-nplm-的优势">相比 N-gram 模型，NPLM 的优势</h3>
                <ul>
                  <li>单词之间的相似性可以通过词向量来体现
                    <blockquote>
                      <p>相比神经语言模型本身，作为其副产品的词向量反而是更大的惊喜</p>
                    </blockquote>
                  </li>
                  <li>自带平滑处理</li>
                </ul>
                <h3 id="nplm-中的-oov-问题">NPLM 中的 OOV 问题</h3>
                <ul>
                  <li>
                    <p>在处理语料阶段，与 N-gram 中的处理方式是一样的——将不满阈值的词全部替换为 UNK
                      <strong>神经网络</strong>中，一般有如下几种处理 UNK 的思路</p>
                  </li>
                  <li>
                    <p>为 UNK 分配一个随机初始化的 embedding，并<strong>参与训练</strong></p>
                    <blockquote>
                      <p>最终得到的 embedding 会有一定的语义信息，但具体好坏未知</p>
                    </blockquote>
                  </li>
                  <li>
                    <p>把 UNK 都初始化成 0 向量，<strong>不参与训练</strong></p>
                    <blockquote>
                      <p>UNK 共享相同的语义信息</p>
                    </blockquote>
                  </li>
                  <li>
                    <p>每次都把 UNK 初始化成一个新的随机向量，<strong>不参与训练</strong></p>
                    <blockquote>
                      <p>常用的方法——因为本身每个 UNK 都不同，随机更符合对 UNK 基于最大熵的估计</p>
                    </blockquote>
                    <blockquote>
                      <blockquote>
                        <p><a href="https://stackoverflow.com/questions/45113130/how-to-add-new-embeddings-for-unknown-words-in-tensorflow-training-pre-set-fo" target="_blank" rel="noopener">How to add new embeddings for unknown words in Tensorflow (training &amp; pre-set for testing)</a>                          - Stack Overflow</p>
                      </blockquote>
                    </blockquote>
                    <blockquote>
                      <blockquote>
                        <p><a href="https://stackoverflow.com/questions/45495190/initializing-out-of-vocabulary-oov-tokens" target="_blank" rel="noopener">Initializing Out of Vocabulary (OOV) tokens</a> - Stack Overflow</p>
                      </blockquote>
                    </blockquote>
                  </li>
                  <li>
                    <p>基于 Char-Level 的方法</p>
                  </li>
                </ul>
                <blockquote>
                  <p>PaperWeekly 第七期 – <a href="https://zhuanlan.zhihu.com/p/22700538?refer=paperweekly" target="_blank" rel="noopener">基于Char-level的NMT OOV解决方案</a></p>
                </blockquote>
                <p><br><br>本文链接： <a href="http://www.meng.uno/articles/d1bd92c6/">http://www.meng.uno/articles/d1bd92c6/</a> 欢迎转载！</p>

              </div>
              <footer class="article-footer">

                <!-- Go to www.addthis.com/dashboard to customize your tools -->

                <div id="wpac-rating" style="margin: 10px auto; text-align:center;"></div>
                <script type="text/javascript">
                  wpac_init = window.wpac_init || [];
                  wpac_init.push({
                    widget: 'Rating',
                    id: 9986
                  });
                  (function() {
                    if ('WIDGETPACK_LOADED' in window) return;
                    WIDGETPACK_LOADED = true;
                    var mc = document.createElement('script');
                    mc.type = 'text/javascript';
                    mc.async = true;
                    mc.src = 'https://embed.widgetpack.com/widget.js';
                    var s = document.getElementsByTagName('script')[0];
                    s.parentNode.insertBefore(mc, s.nextSibling);
                  })();
                </script>

                <div id="donation_div"></div>

                <script src="/js/vdonate.js"></script>
                <script>
                  var a = new Donate({
                    title: '如果觉得我的文章对您有用，请随意打赏。您的支持将鼓励我继续创作!', // 可选参数，打赏标题
                    btnText: '打赏支持', // 可选参数，打赏按钮文字
                    el: document.getElementById('donation_div'),
                    wechatImage: 'http://www.meng.uno/money/wechat.JPG',
                    alipayImage: 'http://www.meng.uno/money/alipay.JPG'
                  });
                </script>


                <div id="comment">
                  <!-- 来必力City版安装代码 -->
                  <div id="lv-container" data-id="city" data-uid="MTAyMC8zNDA2OC8xMDYwNg==">
                    <script type="text/javascript">
                      (function(d, s) {
                        var j, e = d.getElementsByTagName(s)[0];

                        if (typeof LivereTower === 'function') {
                          return;
                        }

                        j = d.createElement(s);
                        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
                        j.async = true;

                        e.parentNode.insertBefore(j, e);
                      })(document, 'script');
                    </script>
                    <noscript>为正常使用评论功能请激活JavaScript</noscript>
                  </div>
                  <!-- City版安装代码已完成 -->
                </div>

                <ul class="article-tag-list">
                  <li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/">AI</a></li>
                  <li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li>
                  <li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/自然语言处理/">自然语言处理</a></li>
                </ul>
              </footer>
            </div>

            <nav id="article-nav">

              <a href="/articles/66999e7d/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">上一篇</strong>
      <div class="article-nav-title">
        
          Java合并List
        
      </div>
    </a>


              <a href="/articles/7203e497/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">下一篇</strong>
      <div class="article-nav-title">CNN</div>
    </a>

            </nav>

          </article>

          <!-- Table of Contents -->

          <aside id="toc-sidebar">
            <div id="toc" class="toc-article">
              <strong class="toc-title">目录导航</strong>

              <ol class="nav">
                <li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">1.</span> <span class="nav-text">NLP 概述</span></a>
                  <ol class="nav-child">
                    <li class="nav-item nav-level-2"><a class="nav-link" href="#解决-nlp-问题的一般思路"><span class="nav-number">1.1.</span> <span class="nav-text">解决 NLP 问题的一般思路</span></a></li>
                    <li class="nav-item nav-level-2"><a class="nav-link" href="#nlp-的历史进程"><span class="nav-number">1.2.</span> <span class="nav-text">NLP 的历史进程</span></a></li>
                    <li class="nav-item nav-level-2"><a class="nav-link" href="#seq2seq-模型"><span class="nav-number">1.3.</span> <span class="nav-text">Seq2Seq 模型</span></a></li>
                    <li class="nav-item nav-level-2"><a class="nav-link" href="#评价机制"><span class="nav-number">1.4.</span> <span class="nav-text">评价机制</span></a>
                      <ol class="nav-child">
                        <li class="nav-item nav-level-3"><a class="nav-link" href="#困惑度-perplexity-ppx"><span class="nav-number">1.4.1.</span> <span class="nav-text">困惑度 (Perplexity, PPX)</span></a></li>
                        <li class="nav-item nav-level-3"><a class="nav-link" href="#undefined"><span class="nav-number">1.4.2.</span> <span class="nav-text">基本公式</span></a></li>
                        <li class="nav-item nav-level-3"><a class="nav-link" href="#bleu"><span class="nav-number">1.4.3.</span> <span class="nav-text">BLEU</span></a></li>
                        <li class="nav-item nav-level-3"><a class="nav-link" href="#rouge"><span class="nav-number">1.4.4.</span> <span class="nav-text">ROUGE</span></a></li>
                      </ol>
                    </li>
                  </ol>
                </li>
                <li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">2.</span> <span class="nav-text">语言模型</span></a>
                  <ol class="nav-child">
                    <li class="nav-item nav-level-2"><a class="nav-link" href="#xx-模型的含义"><span class="nav-number">2.1.</span> <span class="nav-text">XX 模型的含义</span></a></li>
                    <li class="nav-item nav-level-2"><a class="nav-link" href="#概率-统计语言模型-plm-slm"><span class="nav-number">2.2.</span> <span class="nav-text">概率/统计语言模型 (PLM, SLM)</span></a>
                      <ol class="nav-child">
                        <li class="nav-item nav-level-3"><a class="nav-link" href="#参数的规模"><span class="nav-number">2.2.1.</span> <span class="nav-text">参数的规模</span></a></li>
                        <li class="nav-item nav-level-3"><a class="nav-link" href="#可用的概率模型"><span class="nav-number">2.2.2.</span> <span class="nav-text">可用的概率模型</span></a></li>
                      </ol>
                    </li>
                    <li class="nav-item nav-level-2"><a class="nav-link" href="#n-gram-语言模型"><span class="nav-number">2.3.</span> <span class="nav-text">N-gram 语言模型</span></a>
                      <ol class="nav-child">
                        <li class="nav-item nav-level-3"><a class="nav-link" href="#可靠性与可区别性"><span class="nav-number">2.3.1.</span> <span class="nav-text">可靠性与可区别性</span></a></li>
                        <li class="nav-item nav-level-3"><a class="nav-link" href="#oov-问题"><span class="nav-number">2.3.2.</span> <span class="nav-text">OOV 问题</span></a></li>
                        <li class="nav-item nav-level-3"><a class="nav-link" href="#平滑处理-todo"><span class="nav-number">2.3.3.</span> <span class="nav-text">平滑处理 TODO</span></a></li>
                      </ol>
                    </li>
                    <li class="nav-item nav-level-2"><a class="nav-link" href="#神经概率语言模型-nplm"><span class="nav-number">2.4.</span> <span class="nav-text">神经概率语言模型 (NPLM)</span></a>
                      <ol class="nav-child">
                        <li class="nav-item nav-level-3"><a class="nav-link" href="#n-gram-神经语言模型"><span class="nav-number">2.4.1.</span> <span class="nav-text">N-gram 神经语言模型</span></a>
                          <ol class="nav-child">
                            <li class="nav-item nav-level-4"><a class="nav-link" href="#n-gram-神经语言模型的网络结构"><span class="nav-number">2.4.1.1.</span> <span class="nav-text">N-gram 神经语言模型的网络结构</span></a></li>
                          </ol>
                        </li>
                        <li class="nav-item nav-level-3"><a class="nav-link" href="#模型参数的规模与运算量"><span class="nav-number">2.4.2.</span> <span class="nav-text">模型参数的规模与运算量</span></a></li>
                        <li class="nav-item nav-level-3"><a class="nav-link" href="#相比-n-gram-模型-nplm-的优势"><span class="nav-number">2.4.3.</span> <span class="nav-text">相比 N-gram 模型，NPLM 的优势</span></a></li>
                        <li class="nav-item nav-level-3"><a class="nav-link" href="#nplm-中的-oov-问题"><span class="nav-number">2.4.4.</span> <span class="nav-text">NPLM 中的 OOV 问题</span></a></li>
                      </ol>
                    </li>
                  </ol>
                </li>
              </ol>

            </div>
          </aside>
        </section>

      </div>


      <footer id="footer">


        <div class="container">
          <div class="row">
            <p id="copyRightEn">&copy; 2018.02.08 - 2018.10.26 <a href="http://www.meng.uno/">匡盟盟</a>&nbsp;<i class="fas fa-cogs"></i> 保留所有权利！</p>

            <p class="busuanzi_uv">

              访客数 : <span id="busuanzi_value_site_uv"></span> | 访问量 : <span id="busuanzi_value_site_pv"></span>

            </p>


            <p id="hitokoto">:D 获取中...</p>
            <!-- 以下写法，选取一种即可 -->

            <!-- 现代写法，推荐 -->
            <!-- 兼容低版本浏览器 (包括 IE)，可移除 -->
            <script src="https://cdn.bootcss.com/bluebird/3.5.1/bluebird.core.min.js"></script>
            <script src="https://cdn.bootcss.com/fetch/2.0.3/fetch.min.js"></script>
            <!--End-->
            <script>
              fetch('https://v1.hitokoto.cn')
                .then(function(res) {
                  return res.json();
                })
                .then(function(data) {
                  var hitokoto = document.getElementById('hitokoto');
                  hitokoto.innerText = data.hitokoto;
                })
                .catch(function(err) {
                  console.error(err);
                })
            </script>

            <a href="http://webscan.360.cn/index/checkwebsite/url/www.meng.uno"><img border="0" height=27px width=74px src="/css/images/webscan.png"/></a>
            <!-- <img border="0" height=27px width=109px style="background-color:white;"src="/css/images/kaba.png"/> -->
            <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" height=27px style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a>
            <script type="text/javascript">
              var locationUrl = escape(document.location.href);
              document.write(unescape("%3Cscript") + " height='27px' width='74px' charset='utf-8' src='http://union.rising.com.cn//InfoManage/TrojanInspect.aspx?p1=XNk3xHG5v8uxFHYb4KaGpnyWjJlbHp7K&p2=RqCQt7iMKRw=&p3=XNk3xHG5v8vv3Z1xqd/V8w==&url=" + locationUrl + "' type='text/javascript'" + unescape("%3E%3C/script%3E"));
            </script>
          </div>

        </div>
      </footer>


      <!-- min height -->

      <script>
        var wrapdiv = document.getElementById("wrap");
        var contentdiv = document.getElementById("content");
        var allheader = document.getElementById("allheader");

        wrapdiv.style.minHeight = document.body.offsetHeight + "px";
        if (allheader != null) {
          contentdiv.style.minHeight = document.body.offsetHeight - allheader.offsetHeight - document.getElementById("footer").offsetHeight + "px";
        } else {
          contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("footer").offsetHeight + "px";
        }
      </script>

      <script>
        (function() {
          var src = (document.location.protocol == "http:") ? "http://js.passport.qihucdn.com/11.0.1.js?5d3bca9f7d6a95532f3ebb56e3c6bf11" : "https://jspassport.ssl.qhimg.com/11.0.1.js?5d3bca9f7d6a95532f3ebb56e3c6bf11";
          document.write('<script src="' + src + '" id="sozz"><\/script>');
        })();
      </script>
    </div>
    <!-- <nav id="mobile-nav">

  <a href="/" class="mobile-nav-link">Home</a>

  <a href="/archives" class="mobile-nav-link">Archives</a>

  <a href="/categories" class="mobile-nav-link">Categories</a>

  <a href="/tags" class="mobile-nav-link">Tags</a>

  <a href="/about" class="mobile-nav-link">About</a>

  <a href="/comments" class="mobile-nav-link">Comments</a>

</nav> -->
    <!-- mathjax config similar to math.stackexchange -->

    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({ tex2jax: { skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'] } });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() { var all = MathJax.Hub.getAllJax(), i; for(i=0; i
      < all.length; i +=1 ) { all[i].SourceElement().parentNode.className +=' has-jax' ; } }); </script>

        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
        </script>


        <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
        <script src="/fancybox/jquery.fancybox.pack.js"></script>


        <script src="/js/scripts.js"></script>




        <script src="/js/dialog.js"></script>


        <!-- Google Analytics -->
        <script type="text/javascript">
          (function(i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function() {
              (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
              m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
          })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

          ga('create', 'UA-113947925-1', 'auto');
          ga('send', 'pageview');
        </script>
        <!-- End Google Analytics -->


        <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
        </script>
  </div>

  <div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true" style="display: none;">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <h2 class="modal-title" id="myModalLabel">设置</h2>
        </div>
        <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
        <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">
        <div class="modal-body">
          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseOne" onclick="javascript:setFontSize();" aria-expanded="true" aria-controls="collapseOne">
              正文字号大小
            </a>
          </div>
          <div id="collapseOne" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingOne">
            <div class="panel-body">
              您已调整页面字体大小
            </div>
          </div>
          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseTwo" onclick="javascript:setBackground();" aria-expanded="true" aria-controls="collapseTwo">
              夜间护眼模式
            </a>
          </div>
          <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
            <div class="panel-body">
              夜间模式已经开启，再次单击按钮即可关闭
            </div>
          </div>

          <div>
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseThree" aria-expanded="true" aria-controls="collapseThree">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关 于&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
          </div>
          <div id="collapseThree" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingThree">
            <div class="panel-body">
              欢迎来到匡盟盟的博客！
            </div>
            <div class="panel-body">
              一个不满平凡的大龄码农
            </div>
            <div class="panel-body">
              © 2018 匡盟盟 All Rights Reserved.
            </div>
          </div>
        </div>


        <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">
        <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
        <div class="modal-footer">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>

  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>

  <a id="menu-switch"><i class="fa fa-bars fa-lg"></i></a>




  <!-- Go to www.addthis.com/dashboard to customize your tools -->
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5a9d5b43ece25231"></script>



</body>
<style>
  .test-div {
    width: 300px;
    height: 300px;
    margin: 20px auto;
    border: 1px solid #aaa;
    position: relative;
  }
</style>

<script src="/js/loading.js"></script>
<script>
  function loading7() {
    $('body').loading({
      loadingWidth: 240,
      title: '请稍等!',
      name: 'test',
      discription: '精彩马上就来...',
      direction: 'row',
      type: 'origin',
      originBg: '#71EA71',
      originDivWidth: 30,
      originDivHeight: 30,
      originWidth: 4,
      originHeight: 4,
      smallLoading: false,
      titleColor: '#388E7A',
      loadingBg: '#312923',
      loadingMaskBg: 'rgba(22,22,22,0.2)'
    });
    setTimeout(function() {
      removeLoading('test');
    }, 1000);
  }
</script>

</html>